# SQL Safety Guard System – Implementation Plan

**Memory Strategy:** Dynamic-MD (directory structure with Markdown logs)
**Last Modification:** 2025-12-17 - Phase 6 COMPLETED (All 3 tasks: 95 tests passing, 100% pass rate). Complete Spring Boot integration with zero-configuration starter experience. Task 6.1 (Auto-Configuration, 30 tests): SqlGuardAutoConfiguration with @ConditionalOnClass automatic bean creation (JSqlParserFacade + 10 RuleCheckers + orchestrator + filter + validator), META-INF/spring.factories auto-discovery, @AutoConfigureAfter ordering, interceptor registration deferred. Task 6.2 (Properties Binding, 47 tests): SqlGuardProperties (850+ lines) with @ConfigurationProperties, nested configs (Interceptors/Deduplication/Rules/Parser), JSR-303 validation, spring-configuration-metadata.json for IDE autocomplete, profile-specific configs (dev/prod), kebab/snake/camelCase mapping. Task 6.3 (Config Center Extension, 18 tests): ConfigCenterAdapter SPI, ConfigChangeEvent immutable design, ApolloConfigCenterAdapter with reflection-based event handling, thread-safe synchronized reload, extension documentation (200+ lines), Nacos support removed (Spring dependency conflicts). Key findings: config.* vs validator.rule.impl.*Config architecture, ViolationStrategy enum duplication across modules, @ConditionalOnClass + @ConditionalOnProperty robust activation, extension pattern zero core changes. Total Phase 6: 95 tests, 14 implementation classes, complete Javadoc, production-ready. Ready for Phase 7 (Examples & Documentation).
**Project Overview:** Build production-ready SQL Safety Guard System for MyBatis applications preventing catastrophic database incidents through dual-layer protection: static code scanning detecting dangerous patterns during development and runtime interception enforcing safety constraints during execution, supporting Java 8 baseline with multi-version compatibility (11/17/21), MyBatis 3.4.x/3.5.x and MyBatis-Plus 3.4.x/3.5.x integration, comprehensive Spring Boot auto-configuration with zero-config starter experience, Apollo/Nacos config center integration for hot-reload, phased deployment strategy (LOG→WARN→BLOCK) enabling risk-mitigated production rollout, target <5% performance overhead through parse-once optimization and deduplication filter, TDD methodology throughout ensuring zero regressions, Google Java Style enforcement via Checkstyle maintaining code quality consistency.

**Architecture Notes:**
- **Dual-Config Pattern:** System uses two separate config class hierarchies: (1) `com.footstone.sqlguard.config.*Config` for YAML deserialization (simple POJOs), (2) `com.footstone.sqlguard.validator.rule.impl.*Config` for runtime checker behavior (extends CheckerConfig). See `sql-guard-core/docs/Dual-Config-Pattern.md` for details. This pattern ensures YAML compatibility while providing rich domain objects for validation logic.

## Phase 1: Foundation & Core Models - Agent_Core_Engine_Foundation

### Task 1.1 – Project Structure & Multi-Module Build Configuration │ Agent_Core_Engine_Foundation

- **Objective:** Establish complete Maven multi-module project foundation with standardized structure, dependency management, quality enforcement, and multi-version Java compatibility for the entire SQL Safety Guard System.
- **Output:**
  - Parent POM with comprehensive dependency management for all core libraries (JSqlParser 4.x, JavaParser 3.x, DOM4J 2.x, MyBatis 3.4.6/3.5.13, MyBatis-Plus 3.4.0/3.5.3, SLF4J 1.7.x, Logback 1.2.x, SnakeYAML 1.33, JUnit 5, Mockito 4.x) and multi-version profiles (Java 8/11/17/21)
  - Nine module POMs with proper inheritance and inter-module dependencies
  - Standard Maven directory structure across all modules with com.footstone.sqlguard.* package hierarchy
  - Build verification demonstrating successful compilation and test infrastructure
- **Guidance:** This is the foundational task enabling all subsequent development. Use Maven 3.6+ best practices for parent POM structure. Configure all dependency versions in parent POM <dependencyManagement> to ensure consistency. Set Java 8 as baseline (source/target 1.8) with profiles for 11/17/21 testing. Integrate Google Java Style via Checkstyle plugin with enforcement in verify phase to prevent style violations early. The placeholder test class validates JUnit 5 + Mockito 4.x integration works correctly before real test development begins. All nine modules must compile successfully to ensure proper dependency resolution. Depends on: None (foundational task).

1. **Parent POM Setup:** Create parent `pom.xml` in project root with groupId `com.footstone`, artifactId `sql-safety-guard-parent`, packaging `pom`. Define <properties> for all dependency versions (JSqlParser 4.9.0, JavaParser 3.25.7, DOM4J 2.1.4, MyBatis 3.4.6/3.5.13, MyBatis-Plus 3.4.0/3.5.3, SLF4J 1.7.36, Logback 1.2.12, SnakeYAML 1.33, JUnit 5.10.1, Mockito 4.11.0). Configure <dependencyManagement> importing all libraries with versions from properties. Set maven.compiler.source and maven.compiler.target to 1.8, project.build.sourceEncoding to UTF-8.
2. **Multi-Version Profiles:** Define Maven profiles in parent POM for Java 11 (profile id `java11`), Java 17 (profile id `java17`), and Java 21 (profile id `java21`). Each profile overrides compiler source/target to respective version. Document profile activation in project README for CI/CD matrix builds.
3. **Module POM Creation:** Create child module directories and POMs for: sql-scanner-core (core scanning engine), sql-scanner-cli (CLI tool), sql-scanner-maven (Maven plugin), sql-scanner-gradle (Gradle plugin), sql-guard-core (validation engine), sql-guard-mybatis (MyBatis interceptor), sql-guard-mp (MyBatis-Plus interceptor), sql-guard-jdbc (JDBC layer interceptors), sql-guard-spring-boot-starter (Spring Boot auto-configuration). Each module POM specifies parent reference and declares direct dependencies (not versions, inherited from parent). Configure inter-module dependencies where needed (e.g., sql-guard-mybatis depends on sql-guard-core).
4. **Directory Structure:** For each of the nine modules, create standard Maven layout: src/main/java (production source), src/main/resources (configuration files), src/test/java (test source), src/test/resources (test resources). Establish base package structure: com.footstone.sqlguard.core (core models), com.footstone.sqlguard.scanner (scanning engine), com.footstone.sqlguard.interceptor (interceptors), com.footstone.sqlguard.config (configuration).
5. **Build Plugin Configuration:** In parent POM <build><pluginManagement>, configure maven-compiler-plugin version 3.11.0 (source/target 1.8, encoding UTF-8, showWarnings true), maven-surefire-plugin version 3.2.3 (JUnit 5 support), maven-source-plugin version 3.3.0 (attach sources on package), maven-javadoc-plugin version 3.6.3 (generate javadoc JAR). Configure checkstyle-maven-plugin version 3.3.1 with Google Java Style (google_checks.xml), bind to verify phase with failOnViolation true to enforce style compliance before build completion.
6. **Build Verification:** Execute `mvn clean compile` from project root to verify parent + all nine modules compile successfully without errors. Create placeholder test class `com.footstone.sqlguard.core.FoundationTest` in sql-guard-core module with simple JUnit 5 @Test annotated method using Mockito mock() to verify test infrastructure (JUnit Platform + Mockito framework) is properly configured. Run `mvn test` to confirm test execution works. Check Checkstyle reports to ensure Google Java Style enforcement is active.

### Task 1.2 – Core Data Models & Domain Types │ Agent_Core_Engine_Foundation

- **Objective:** Implement fundamental domain models (SqlContext, ValidationResult, enums, ViolationInfo) that form the contract between SQL parsing, validation, and interception layers, following TDD methodology to ensure correctness and immutability where required.
- **Output:**
  - SqlContext class with builder pattern for capturing complete SQL execution context (SQL string, parsed AST, command type, mapper ID, parameters, datasource, pagination info)
  - ValidationResult class with methods for violation aggregation and risk level determination
  - RiskLevel enum (SAFE/LOW/MEDIUM/HIGH/CRITICAL) with severity ordering
  - SqlCommandType enum (SELECT/UPDATE/DELETE/INSERT)
  - ViolationInfo value object for individual violation details
  - Comprehensive unit tests demonstrating all model behaviors and constraints
- **Guidance:** These models are referenced throughout the system by all validation checkers and interceptors. SqlContext uses builder pattern to accommodate varying contexts (XML Mapper vs JDBC vs QueryWrapper). Ensure immutability for parsedSql, type, and mapperId to prevent accidental modification during validation chain execution. ValidationResult must support multiple violations from different checkers and correctly aggregate to highest risk level. All classes must have comprehensive Javadoc explaining field meanings and usage patterns. Apply Google Java Style and fail-fast validation (throw IllegalArgumentException for invalid states). Depends on: Task 1.1 Output (project structure and build configuration).

1. **SqlContext TDD:** Write test class `SqlContextTest` covering: builder creation with all fields populated, builder with minimal fields (sql only), immutability verification for critical fields (parsedSql should be set once), null handling for optional fields (params, datasource, rowBounds can be null). Then implement `SqlContext` in `com.footstone.sqlguard.core.model` package with fields: String sql (required), Statement parsedSql (optional, set during validation), SqlCommandType type (required), String mapperId (required, format "namespace.methodId"), Map<String, Object> params (optional), String datasource (optional), RowBounds rowBounds (optional for MyBatis pagination detection). Implement static builder() method returning SqlContextBuilder with fluent API. Add field validation in build() throwing IllegalArgumentException if sql/type/mapperId are null.
2. **ValidationResult TDD:** Write test class `ValidationResultTest` covering: initial creation with passed=true, adding single violation changes passed to false, adding multiple violations aggregates to highest risk level (e.g., MEDIUM + CRITICAL = CRITICAL), empty violations list means passed, getRiskLevel() returns SAFE when passed. Then implement `ValidationResult` in core.model package with fields: boolean passed (default true), RiskLevel riskLevel (default SAFE), List<ViolationInfo> violations (ArrayList), Map<String, Object> details (LinkedHashMap for insertion order). Implement addViolation(RiskLevel, String message, String suggestion) method that creates ViolationInfo, adds to list, sets passed=false, updates riskLevel to max(current, new). Implement static pass() factory method.
3. **Enums TDD:** Write test class `EnumsTest` covering: RiskLevel ordering (SAFE < LOW < MEDIUM < HIGH < CRITICAL), RiskLevel.compareTo() works correctly, SqlCommandType values match expected (SELECT/UPDATE/DELETE/INSERT). Then implement `RiskLevel` enum in core.model with constants SAFE, LOW, MEDIUM, HIGH, CRITICAL (declaration order determines natural ordering). Implement Comparable<RiskLevel> with compareTo using ordinal(). Add getSeverity() returning ordinal. Implement `SqlCommandType` enum with SELECT, UPDATE, DELETE, INSERT values. Add fromString(String) static method for case-insensitive lookup.
4. **ViolationInfo TDD:** Write test class `ViolationInfoTest` covering: creation with all fields, equals() compares riskLevel+message (not suggestion), hashCode() consistency with equals, toString() includes all fields. Then implement `ViolationInfo` value object in core.model with fields: RiskLevel riskLevel (required), String message (required), String suggestion (optional). Make class final and fields final (immutable). Implement constructor with validation (riskLevel and message cannot be null). Override equals() using Objects.equals on riskLevel+message, override hashCode() using Objects.hash, override toString() returning formatted string "ViolationInfo{riskLevel=X, message='...', suggestion='...'}".
5. **Documentation & Validation:** Add Javadoc to all public classes and methods: SqlContext (explain builder pattern usage and field purposes), ValidationResult (explain violation aggregation logic), RiskLevel (explain severity ordering), SqlCommandType (explain SQL type categorization), ViolationInfo (explain immutability and value object pattern). Write additional unit tests for builder immutability: attempt to modify SqlContext after build() should not affect original, ValidationResult modifications don't leak to callers. Run `mvn test` to verify all tests pass. Run `mvn checkstyle:check` to ensure Google Java Style compliance. Verify fail-fast: SqlContext.builder().build() without required fields throws IllegalArgumentException with clear message.

### Task 1.3 – Configuration Model with YAML Support │ Agent_Core_Engine_Foundation

- **Objective:** Implement comprehensive configuration system supporting YAML file loading, nested rule configurations for all 7 validation rules, fail-fast validation, and default configuration merging to enable flexible runtime behavior control.
- **Output:**
  - SqlGuardConfig root class with all configuration sections (enabled, activeStrategy, interceptors, deduplication, rules)
  - Configuration classes for 7 rules: NoWhereClauseConfig, DummyConditionConfig, BlacklistFieldsConfig, WhitelistFieldsConfig, PaginationAbuseConfig, NoPaginationConfig, EstimatedRowsConfig
  - YamlConfigLoader with loadFromFile() and loadFromClasspath() methods
  - SqlGuardConfigDefaults providing sensible defaults matching design document section 5.1
  - Comprehensive validation ensuring configurations fail-fast on invalid values
- **Guidance:** Configuration system must support both file-based (deployment) and classpath-based (testing) loading. Use SnakeYAML for YAML parsing with proper type mapping for nested structures. Implement fail-fast validation in setters or post-construction validation method to catch misconfigurations early (maxOffset > 0, cacheSize > 0, valid strategy names). Default configuration should match design document to work out-of-box for common scenarios. Merging logic allows user config to override only specific fields while inheriting sensible defaults for unspecified fields. All config classes should be mutable POJOs for YAML binding but validate constraints. Depends on: Task 1.1 Output (project structure with SnakeYAML dependency).

1. **Root Config TDD:** Write test class `SqlGuardConfigTest` covering: default config creation, enabled flag toggle, activeStrategy setting (dev/test/prod), interceptors config structure (mybatis.enabled, mybatis-plus.enabled, jdbc.enabled + type), deduplication config (enabled, cacheSize, ttlMs values). Then implement `SqlGuardConfig` in `com.footstone.sqlguard.config` package with fields: boolean enabled (default true), String activeStrategy (default "prod"), InterceptorsConfig interceptors (nested object), DeduplicationConfig deduplication (nested object), RulesConfig rules (nested object containing all 7 rule configs). Implement nested static classes InterceptorsConfig (MyBatisConfig mybatis, MyBatisPlusConfig mybatisPlus, JdbcConfig jdbc), DeduplicationConfig (boolean enabled, int cacheSize, long ttlMs), RulesConfig (fields for each of 7 rule configs).
2. **Rule Configs TDD:** Write test classes for each rule config covering valid configurations and constraint violations. Implement config classes in config package: `NoWhereClauseConfig` (boolean enabled, RiskLevel riskLevel), `DummyConditionConfig` (enabled, riskLevel, List<String> patterns, List<String> customPatterns), `BlacklistFieldsConfig` (enabled, riskLevel, Set<String> fields), `WhitelistFieldsConfig` (enabled, riskLevel, Set<String> fields, Map<String, List<String>> byTable, boolean enforceForUnknownTables), `PaginationAbuseConfig` (enabled, riskLevel, nested LogicalPaginationConfig, PhysicalNoConditionConfig, PhysicalDeepPaginationConfig with maxOffset/maxPageNum, LargePageSizeConfig with maxPageSize, NoOrderByConfig), `NoPaginationConfig` (enabled, riskLevel, boolean enforceForAllQueries, List<String> whitelistMapperIds, List<String> whitelistTables, List<String> uniqueKeyFields), `EstimatedRowsConfig` (enabled, riskLevel, Map<SqlCommandType, Integer> thresholds). Each config class is mutable POJO for YAML deserialization.
3. **YAML Loader Implementation:** Add SnakeYAML 1.33 dependency to sql-guard-core module POM. Implement `YamlConfigLoader` class in config package with methods: `loadFromFile(Path path)` throws IOException for file-based loading, `loadFromClasspath(String resourcePath)` for classpath resource loading. Use SnakeYAML's Constructor with PropertyUtils for proper nested type mapping. Configure SnakeYAML to handle Map<String, List<String>> in WhitelistFieldsConfig.byTable correctly. Add error handling for FileNotFoundException, YAMLException (malformed YAML), and ClassCastException (type mismatches). Wrap exceptions in custom ConfigLoadException with descriptive messages indicating which field/section failed.
4. **Fail-Fast Validation:** Implement validation method in SqlGuardConfig: `validate()` throws IllegalArgumentException with clear messages. Validation rules: enabled must be boolean, activeStrategy must be one of [dev, test, prod], deduplication.cacheSize > 0, deduplication.ttlMs > 0, PaginationAbuseConfig.maxOffset > 0, PaginationAbuseConfig.maxPageSize > 0, pattern lists not empty if configured. Add @PostConstruct or manual validate() call after YAML deserialization. Write tests: valid YAML loads successfully, invalid YAML syntax throws exception with line/column info, invalid values (maxOffset = -1) throw IllegalArgumentException, type mismatches (string instead of int) throw ConfigLoadException, missing required nested sections use defaults.
5. **Defaults & Merging:** Implement `SqlGuardConfigDefaults` class providing static method `getDefault()` returning SqlGuardConfig with sensible defaults matching design section 5.1: enabled=true, activeStrategy="prod", mybatis.enabled=true, mybatisPlus.enabled=false, jdbc.enabled=true with type="auto", deduplication.enabled=true with cacheSize=1000 and ttlMs=100, all rules enabled with appropriate risk levels (NoWhereClauseConfig: CRITICAL, DummyConditionConfig: HIGH, BlacklistFieldsConfig: HIGH with default fields [deleted, del_flag, status], etc.). Implement merging logic in YamlConfigLoader: load user YAML, load defaults, overlay user values over defaults (non-null user values override defaults), return merged SqlGuardConfig. Write tests: partial user config merges with defaults correctly, user config overrides specific fields while inheriting others, empty YAML file results in complete default configuration.
6. **Comprehensive Testing:** Write integration test `YamlConfigLoaderIntegrationTest` with sample YAML files in src/test/resources: valid-complete.yml (all sections defined), valid-partial.yml (only some rules configured), invalid-syntax.yml (malformed YAML), invalid-values.yml (maxOffset=-1), invalid-types.yml (string where int expected), missing-required.yml (missing critical sections). Each test verifies expected behavior: successful load, ConfigLoadException with descriptive message, IllegalArgumentException for constraint violations, correct merging with defaults. Verify fail-fast: invalid config detected before any SQL validation occurs. Run `mvn test` ensuring all config tests pass.

### Task 1.4 – JSqlParser Integration Facade │ Agent_Core_Engine_Foundation

- **Objective:** Create unified facade for JSqlParser 4.x providing SQL parsing, AST extraction utilities, fail-fast error handling with configurable lenient mode, and LRU caching for parsed statements to optimize repeated SQL validation performance.
- **Output:**
  - JSqlParserFacade class with parse() method returning JSqlParser Statement AST
  - Utility methods: extractWhere(), extractTableName(), extractFields() for common SQL analysis operations
  - Fail-fast and lenient error handling modes
  - LRU cache for parsed SQL statements with configurable size and cache statistics
  - Comprehensive tests covering multiple database dialects and edge cases
- **Guidance:** JSqlParser is the core SQL parsing engine used throughout validation. Facade pattern isolates rest of system from JSqlParser API changes. Fail-fast mode (default) ensures invalid SQL is rejected immediately; lenient mode (for optional rules) logs warnings and continues. LRU cache is critical for performance when same SQL template is validated repeatedly (common with PreparedStatements). Cache key should be normalized SQL (trimmed, lowercase) to maximize hit rate. Utility methods reduce code duplication across rule checkers. Test with multiple database dialects since JSqlParser supports MySQL, PostgreSQL, Oracle, SQL Server syntax variations. Depends on: Task 1.1 Output (project structure with JSqlParser 4.x dependency).

1. **Basic Parsing TDD:** Write test class `JSqlParserFacadeTest` covering: parse valid SELECT statement returns Statement, parse valid UPDATE/DELETE/INSERT statements, parse invalid SQL syntax throws SqlParseException, parse null SQL throws IllegalArgumentException, parse empty/whitespace-only SQL throws SqlParseException. Then add JSqlParser 4.9.0 dependency to sql-guard-core module POM. Implement `JSqlParserFacade` class in `com.footstone.sqlguard.parser` package with constructor accepting `boolean lenientMode` (default false). Implement `parse(String sql)` method: validate sql not null/empty, call CCJSqlParserUtil.parse(sql) catching JSQLParserException, in fail-fast mode throw custom SqlParseException (extends RuntimeException) wrapping original exception and including original SQL in message, in lenient mode log warning via SLF4J and return null.
2. **Error Handling Strategy:** Implement custom `SqlParseException` extending RuntimeException in parser package with constructor accepting String message and Throwable cause. Exception message format: "Failed to parse SQL: [first 100 chars of SQL]... - Reason: [JSQLParserException message]". Add `boolean isLenientMode()` getter to JSqlParserFacade. Write tests: fail-fast mode throws SqlParseException with descriptive message containing SQL snippet, lenient mode returns null and logs warning at WARN level (verify with Logback test appender), SqlParseException message includes both SQL and parse error reason, exception includes original JSQLParserException as cause for debugging.
3. **Extraction Utilities TDD:** Write tests for utility methods: extractWhere(SELECT) returns WHERE Expression, extractWhere(UPDATE) returns WHERE, extractWhere(DELETE) returns WHERE, extractWhere(INSERT) returns null (no WHERE), extractTableName(SELECT) returns table name, extractTableName(multi-table JOIN) returns first/primary table, extractFields(Expression) returns Set containing all field names from WHERE. Then implement utility methods in JSqlParserFacade: `extractWhere(Statement)` using instanceof checks and casting, `extractTableName(Statement)` traversing FromItem to get table name, `extractFields(Expression)` implementing custom FieldExtractorVisitor (extends ExpressionVisitorAdapter) that visits Column nodes and collects getColumnName() into Set<String>. Add null-safe handling: return null/empty set for null inputs. Write edge case tests: complex WHERE with AND/OR/NOT operators, nested subqueries, table aliases in field references.
4. **LRU Cache Implementation:** Implement LRU cache using LinkedHashMap with accessOrder=true and size bound. Add constructor parameter `int cacheSize` (default 1000). Implement `parseCached(String sql)` method: normalize SQL (trim, lowercase), check cache with get(normalizedSql), if hit increment hit counter and return cached Statement, if miss call parse(sql), cache result with put(normalizedSql, stmt), if cache exceeds size remove eldest entry, increment miss counter. Add `getCacheStatistics()` returning CacheStats object with hitCount, missCount, size, hitRate. Implement `clearCache()` method. Write tests: cache hit returns same Statement instance, cache miss calls parse and caches result, cache size limit enforced (eldest evicted when exceeded), cache statistics accurate, clearCache() empties cache.
5. **Multi-Database Dialect Testing:** Write integration test `JSqlParserMultiDialectTest` with SQL samples from different databases in src/test/resources: MySQL syntax (LIMIT, backtick identifiers, UNSIGNED), PostgreSQL syntax (LIMIT/OFFSET, ::cast, dollar quotes), Oracle syntax (ROWNUM, dual table, (+) outer join), SQL Server syntax (TOP, square bracket identifiers, NOLOCK hint). For each dialect: parse valid simple SELECT/UPDATE/DELETE/INSERT, parse complex SQL with subqueries and joins, verify extractWhere/extractTableName/extractFields work correctly. Test edge cases: empty SQL, null SQL, whitespace-only SQL, SQL comments (-- and /* */), dynamic SQL with ? placeholders, very long SQL (10000+ chars). Verify fail-fast exceptions for truly invalid syntax. Run comprehensive tests ensuring JSqlParser handles expected SQL variations.

### Task 1.5 – Logging Infrastructure Setup │ Agent_Core_Engine_Foundation

- **Objective:** Configure SLF4J and Logback logging framework across core modules providing consistent log formatting, appropriate log levels for development and testing, and verification that logging infrastructure works correctly before core development begins.
- **Output:**
  - SLF4J and Logback dependencies properly configured in parent POM and core modules
  - Production logging configuration (logback.xml) with structured console output
  - Test logging configuration (logback-test.xml) with reduced noise for test execution
  - Verification test demonstrating logging works at different levels
- **Guidance:** SLF4J provides logging API abstraction while Logback implements actual logging. Configure dependencies in parent POM <dependencyManagement> for version consistency, then add actual dependencies to sql-guard-core and sql-scanner-core modules (where logging will be used). Production config (logback.xml) should output structured logs with timestamp, level, logger name, and message for operational visibility. Test config (logback-test.xml) should reduce noise (root at WARN) while enabling DEBUG for our code to facilitate test debugging. Verification test confirms Logback test configuration overrides production config during test execution. Depends on: Task 1.1 Output (project structure and dependency management).

- **Dependency Configuration:** In parent POM <dependencyManagement>, add SLF4J API version 1.7.36 (groupId org.slf4j, artifactId slf4j-api) and Logback Classic version 1.2.12 (groupId ch.qos.logback, artifactId logback-classic, note: Logback Classic transitively includes logback-core). In sql-guard-core/pom.xml and sql-scanner-core/pom.xml, add SLF4J API and Logback Classic dependencies without version tags (inherited from parent <dependencyManagement>). Logback Classic includes SLF4J binding, so no additional binding dependency needed.
- **Production Logging Configuration:** Create file src/main/resources/logback.xml in sql-guard-core module with <configuration> root element. Define <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"> with <encoder> pattern: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n" (includes timestamp, thread name, log level padded to 5 chars, logger name truncated to 36 chars, message, newline). Configure <logger name="com.footstone.sqlguard" level="DEBUG"/> for development visibility. Set <root level="INFO"><appender-ref ref="CONSOLE"/></root> to reduce third-party library noise. Copy this logback.xml to sql-scanner-core/src/main/resources as well for consistency.
- **Test Logging Configuration:** Create file src/test/resources/logback-test.xml in sql-guard-core module (Logback prioritizes logback-test.xml during test execution, overriding logback.xml). Define console appender with simpler pattern: "%d{HH:mm:ss.SSS} %-5level %logger{20} - %msg%n" (shorter timestamp, truncated logger for readability). Configure <logger name="com.footstone.sqlguard" level="DEBUG"/> to enable our debug logs during testing. Set <root level="WARN"> to suppress INFO logs from test frameworks (JUnit, Mockito) and third-party libraries, keeping test output focused on our code. Copy to sql-scanner-core/src/test/resources.
- **Logging Verification Test:** Create test class `LoggingInfrastructureTest` in sql-guard-core/src/test/java/com/footstone/sqlguard/core with JUnit 5 @Test method `testLoggingWorks()`. Get SLF4J Logger via LoggerFactory.getLogger(LoggingInfrastructureTest.class). Log messages at different levels: logger.trace("Trace message"), logger.debug("Debug message"), logger.info("Info message"), logger.warn("Warn message"), logger.error("Error message"). Run test with `mvn test` and verify console output shows debug/info/warn/error messages (trace not shown since root level WARN in logback-test.xml, but com.footstone.sqlguard at DEBUG shows debug), verify logback-test.xml is applied (shorter timestamp format visible), verify no duplicate log entries (single appender). Check log output format matches expected pattern with timestamp, level, logger name, message.

## Phase 2: Validation Engine - Agent_Core_Engine_Validation (13 tasks - Task 2.8 split into 4 focused checkers)

**Status:** 12/13 tasks completed (Tasks 2.1-2.12 ✅). Task 2.13 ready for execution.

**Config Architecture Note:** Tasks 2.1-2.12 created config classes in `validator/rule/impl` package extending CheckerConfig. Corresponding YAML-binding config classes exist in `config` package (Dual-Config Pattern). Task 2.13 assembly must use validator package configs for checker construction.

### Task 2.1 – Rule Checker Framework & Interfaces │ Agent_Core_Engine_Validation

- **Objective:** Establish foundational framework for Chain of Responsibility pattern rule checking system with RuleChecker interface, AbstractRuleChecker base class providing shared utilities, and RuleCheckerOrchestrator coordinating validation across all enabled checkers.
- **Output:**
  - RuleChecker interface defining check contract for all validation rules
  - CheckerConfig base class for common configuration (enabled flag)
  - AbstractRuleChecker base class with utility methods (extractWhere, extractTableName, FieldExtractorVisitor, isDummyCondition, isConstant)
  - RuleCheckerOrchestrator managing checker execution and violation aggregation
  - Integration tests verifying orchestration, enabled/disabled toggling, violation aggregation
- **Guidance:** This framework is used by all subsequent rule checkers (Tasks 2.2-2.12). RuleChecker interface provides uniform contract allowing polymorphic checker execution. AbstractRuleChecker reduces code duplication by implementing common SQL analysis operations used across multiple checkers. FieldExtractorVisitor uses JSqlParser's visitor pattern to traverse Expression AST collecting field names. RuleCheckerOrchestrator implements Chain of Responsibility pattern iterating through checkers, allowing each to add violations independently. Final risk level is highest among all violations to ensure most severe issue is surfaced. Depends on: None within phase (depends on Phase 1 Task 1.4 for JSqlParser facade).

1. **RuleChecker Interface TDD:** Write test class `RuleCheckerTest` covering: checker with no violations leaves ValidationResult passed, checker adding violation changes passed to false, disabled checker is skipped (isEnabled returns false), verify check method signature accepts SqlContext and ValidationResult. Then implement `RuleChecker` interface in `com.footstone.sqlguard.validator.rule` package with methods: `void check(SqlContext context, ValidationResult result)` (performs validation, may add violations to result), `boolean isEnabled()` (returns true if checker should execute). Define `CheckerConfig` base class with boolean enabled field (default true) and getter isEnabled().
2. **AbstractRuleChecker Utilities TDD:** Write test class `AbstractRuleCheckerTest` covering: extractWhere from SELECT/UPDATE/DELETE returns Expression or null for INSERT, extractTableName from simple SELECT returns table name, extractTableName from JOIN returns primary table, FieldExtractorVisitor extracts all field names from complex WHERE (AND/OR/nested), isDummyCondition detects "1=1" and constant comparisons, isConstant identifies literals vs column references. Then implement `AbstractRuleChecker` abstract class implementing RuleChecker in validator.rule package with utility methods: `protected Expression extractWhere(Statement)` using instanceof casting, `protected String extractTableName(Statement)` traversing FromItem, `protected Set<String> extractFields(Expression)` using FieldExtractorVisitor, `protected boolean isDummyCondition(Expression)` checking for dummy patterns and constant equality, `protected boolean isConstant(Expression)` detecting Value nodes. Implement inner class `FieldExtractorVisitor` extending ExpressionVisitorAdapter overriding visit(Column) to collect column names into Set.
3. **RuleCheckerOrchestrator TDD:** Write test class `RuleCheckerOrchestratorTest` covering: orchestrator with no checkers returns passed ValidationResult, single enabled checker adds violation correctly, multiple checkers add violations independently, disabled checker is skipped, final risk level is max of all violations (MEDIUM + CRITICAL = CRITICAL), orchestrator preserves checker execution order. Then implement `RuleCheckerOrchestrator` class in validator.rule package with constructor accepting `List<RuleChecker> checkers`. Implement `void orchestrate(SqlContext context, ValidationResult result)` method: iterate through checkers list, for each checker call isEnabled(), if enabled call check(context, result), continue through all enabled checkers regardless of violations (don't short-circuit, collect all issues). Note: final risk level aggregation handled by ValidationResult.addViolation() from Task 1.2.
4. **Integration Testing:** Write integration test `RuleCheckerIntegrationTest` creating mock RuleChecker implementations (MockChecker1 adds LOW violation, MockChecker2 adds HIGH violation, MockChecker3 disabled). Test orchestration: create orchestrator with all three checkers, call orchestrate with test SqlContext, verify result contains violations from checker1 and checker2 only (checker3 skipped), verify final risk level is HIGH (max of LOW and HIGH), verify checker execution order preserved. Test enabled/disabled toggling: disable checker1, re-run orchestration, verify only checker2 violation present. Test empty checker list returns passed result. Run `mvn test` verifying all rule framework tests pass.

### Task 2.2 – NoWhereClauseChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting SQL statements (SELECT/UPDATE/DELETE) completely missing WHERE clause, preventing catastrophic full-table operations that could delete/update entire datasets or return millions of rows causing memory exhaustion.
- **Output:**
  - NoWhereClauseChecker class extending AbstractRuleChecker
  - Comprehensive tests covering all SQL command types and edge cases
  - Configuration enabled/disabled toggle verification
- **Guidance:** This is the most critical check (CRITICAL risk level) as missing WHERE clause in UPDATE/DELETE causes irreversible data loss, while in SELECT causes memory overflow. Checker analyzes parsed Statement AST using JSqlParser to detect null WHERE expressions. INSERT statements don't have WHERE clauses so are deliberately skipped. Edge case: SQL with dummy conditions like "WHERE 1=1" has WHERE clause present (passes this checker) but flagged by DummyConditionChecker. Configuration follows CheckerConfig pattern with enabled flag. Depends on: Task 2.1 Output (AbstractRuleChecker and framework).

- **Basic TDD:** Write test class `NoWhereClauseCheckerTest` with test methods: `testDeleteWithoutWhere_shouldViolate()` (DELETE FROM user → CRITICAL violation), `testUpdateWithoutWhere_shouldViolate()` (UPDATE user SET status=1 → CRITICAL violation), `testSelectWithoutWhere_shouldViolate()` (SELECT * FROM user → CRITICAL violation), `testSelectWithWhere_shouldPass()` (SELECT * FROM user WHERE id=1 → pass), `testInsertStatement_shouldSkip()` (INSERT INTO user VALUES(...) → pass, not applicable). Implement `NoWhereClauseChecker` class in validator.rule.impl package extending AbstractRuleChecker with NoWhereClauseConfig (extends CheckerConfig). Implement check(SqlContext, ValidationResult): call extractWhere(context.getParsedSql()) from AbstractRuleChecker, if WHERE is null and statement is SELECT/UPDATE/DELETE, call result.addViolation(RiskLevel.CRITICAL, "SQL语句缺少WHERE条件,可能导致全表操作", "请添加WHERE条件限制操作范围"). Skip check if statement instanceof Insert.
- **Edge Case Testing:** Write additional test methods: `testWhereWithDummyCondition_shouldPass()` (SELECT * FROM user WHERE 1=1 → pass, has WHERE clause even if dummy), `testComplexWhere_shouldPass()` (SELECT * FROM user WHERE status='active' AND create_time > ? → pass), `testDisabledChecker_shouldSkip()` (create checker with enabled=false, verify no violations added). Run tests ensuring all pass. Verify configuration: create NoWhereClauseConfig with enabled=false, inject into checker, verify isEnabled() returns false and check() is not executed by orchestrator.

### Task 2.3 – DummyConditionChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting invalid/dummy WHERE conditions like "1=1", "true", "'a'='a'" that developers add for dynamic SQL convenience but effectively make condition meaningless, resulting in full-table scans despite apparent WHERE clause presence.
- **Output:**
  - DummyConditionChecker class with pattern-based and AST-based dummy detection
  - DummyConditionConfig supporting default patterns and custom pattern extensions
  - Comprehensive pattern tests including case-insensitive matching and embedded patterns
- **Guidance:** Dummy conditions are HIGH risk as they bypass NoWhereClauseChecker but still cause full-table scans. Detection uses dual approach: (1) string pattern matching for known dummy patterns (configurable), (2) AST traversal detecting constant equality (both sides of EqualsTo are constants). Pattern matching handles variations ("1=1", "1 = 1", "'1'='1'"). AST traversal catches programmatically generated constant comparisons not matching string patterns. Configuration allows custom patterns for organization-specific dummy conditions. Depends on: Task 2.1 Output (AbstractRuleChecker with isDummyCondition and isConstant helpers).

- **Pattern-Based Detection TDD:** Write test class `DummyConditionCheckerTest` with pattern test methods: `testOneEqualsOne_shouldViolate()` (WHERE 1=1), `testOneEqualsOneWithSpaces_shouldViolate()` (WHERE 1 = 1), `testStringConstantEquals_shouldViolate()` (WHERE '1'='1', WHERE 'a'='a'), `testTrue_shouldViolate()` (WHERE true), `testConstantComparison_shouldViolate()` (WHERE 2=2, WHERE 100=100), `testFieldComparison_shouldPass()` (WHERE user_id=1), `testPlaceholder_shouldPass()` (WHERE id=?), `testEmbeddedDummy_shouldViolate()` (WHERE status='active' AND 1=1). Implement `DummyConditionChecker` extending AbstractRuleChecker with `DummyConditionConfig` (extends CheckerConfig, adds List<String> patterns with defaults ["1=1", "1 = 1", "'1'='1'", "true", "'a'='a'"], List<String> customPatterns). In check(): extract WHERE expression, if null return (no WHERE to check), normalize WHERE to string (toLowerCase, replaceAll("\\s+", "")), check if normalized contains any pattern from patterns+customPatterns lists, also call isDummyCondition(where) from AbstractRuleChecker for AST-based constant equality detection. If either detection method triggers, add HIGH violation "检测到无效条件(如 1=1),请移除" with suggestion "使用<where>标签或真实业务条件".
- **Comprehensive Pattern Testing:** Add test methods: `testAllDefaultPatterns_shouldDetect()` (verify all patterns in default list detected), `testCaseInsensitiveMatching_shouldDetect()` (WHERE 1=1, where 1=1, WhErE 1=1 all violate), `testPatternInAndOr_shouldDetect()` (WHERE id>0 OR 1=1), `testCustomPattern_shouldDetect()` (add custom pattern "always_true", test WHERE always_true), `testEmptyPattern_shouldPass()` (DummyConditionConfig with empty patterns should not false-positive). Run comprehensive tests ensuring pattern matching and AST-based detection both work correctly.

### Task 2.4 – BlacklistFieldChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting WHERE conditions using only blacklisted fields (deleted, del_flag, status, is_deleted, etc.) which are typically state flags with low cardinality causing excessive row matches and near-full-table scans.
- **Output:**
  - BlacklistFieldChecker class with configurable blacklist field set
  - BlacklistFieldsConfig supporting field list and wildcard patterns
  - Tests covering blacklist-only, mixed conditions, empty blacklist scenarios
- **Guidance:** Blacklist fields have HIGH risk as they appear to have WHERE clause (pass NoWhereClauseChecker) with real business fields (pass DummyConditionChecker) but still match most table rows. Common blacklist fields: deleted, del_flag, status, is_deleted, enabled, type, create_*, update_*. Checker uses FieldExtractorVisitor from AbstractRuleChecker to extract all field names from WHERE expression, then checks if ALL fields are blacklisted. If any non-blacklist field present, condition is acceptable (mixed conditions allow sufficient selectivity). Wildcard patterns ("create_*") enable flexible blacklist definitions. Depends on: Task 2.1 Output (AbstractRuleChecker with FieldExtractorVisitor and extractFields).

- **Blacklist Detection TDD:** Write test class `BlacklistFieldCheckerTest` with test methods: `testDeletedOnly_shouldViolate()` (WHERE deleted=0), `testStatusOnly_shouldViolate()` (WHERE status='active'), `testMultipleBlacklistFields_shouldViolate()` (WHERE deleted=0 AND enabled=1), `testMixedConditions_shouldPass()` (WHERE id=1 AND deleted=0 - id is not blacklist), `testNonBlacklistOnly_shouldPass()` (WHERE user_id=? AND order_id=?), `testNoWhereClause_shouldPass()` (checker skips, handled by NoWhereClauseChecker). Implement `BlacklistFieldChecker` extending AbstractRuleChecker with `BlacklistFieldsConfig` (extends CheckerConfig, adds Set<String> fields with defaults [deleted, del_flag, status, is_deleted, enabled, type]). In check(): extract WHERE using extractWhere(), if null return (skip), call extractFields(where) to get Set<String> of field names, check if fields.stream().allMatch(f -> isBlacklisted(f, config.getFields())), if true add HIGH violation "WHERE条件只包含黑名单字段" + fields + ",条件过于宽泛" with suggestion "添加主键或业务唯一键字段(如id, user_id)".
- **Edge Case Testing:** Add test methods: `testWildcardPattern_shouldMatch()` (configure blacklist with "create_*", test WHERE create_time > ? and WHERE create_by=? both violate), `testCaseInsensitive_shouldMatch()` (WHERE DELETED=0 and WHERE deleted=0 both violate), `testEmptyBlacklist_shouldPassAll()` (config with empty fields set should not violate any SQL), `testBlacklistPlusDummy_shouldBothViolate()` (WHERE deleted=0 AND 1=1 violates both BlacklistFieldChecker and DummyConditionChecker). Implement isBlacklisted() helper method supporting wildcard matching using regex or simple * pattern. Run tests verifying blacklist detection accuracy.

### Task 2.5 – WhitelistFieldChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker enforcing table-specific mandatory WHERE fields (whitelist) to ensure queries include primary keys, tenant IDs, or other high-selectivity fields, providing additional safety layer for critical tables.
- **Output:**
  - WhitelistFieldChecker class with table-specific whitelist configuration
  - WhitelistFieldsConfig supporting byTable map and enforceForUnknownTables flag
  - Tests covering table-specific rules, multi-table scenarios, whitelist pass/fail cases
- **Guidance:** Whitelist checking is MEDIUM risk (less severe than blacklist-only) providing opt-in enforcement for specific tables. Configuration uses Map<String, List<String>> byTable where key is table name and value is list of required fields (any one sufficient). Example: user table requires [id, user_id], order table requires [id, order_id, user_id]. Checker extracts table name and WHERE fields, verifies at least one required field present. Tables not in whitelist map are skipped unless enforceForUnknownTables=true. Useful for multi-tenant systems (enforce tenant_id), GDPR compliance (enforce user_id for personal data), or critical business tables. Depends on: Task 2.1 Output (AbstractRuleChecker with extractTableName and extractFields).

- **Table-Specific Whitelist TDD:** Write test class `WhitelistFieldCheckerTest` with test methods: `testUserTableWithId_shouldPass()` (configure user table whitelist [id, user_id], test SELECT * FROM user WHERE id=? → pass), `testUserTableWithoutRequiredField_shouldViolate()` (SELECT * FROM user WHERE status=? → violate, no id or user_id), `testOrderTableNoWhitelist_shouldPass()` (SELECT * FROM order WHERE status=? → pass, order table not in whitelist), `testMultipleRequiredFieldsAny_shouldPass()` (user table requires [id, user_id], WHERE user_id=? satisfies requirement). Implement `WhitelistFieldChecker` extending AbstractRuleChecker with `WhitelistFieldsConfig` (extends CheckerConfig, adds Set<String> fields for global whitelist optional, Map<String, List<String>> byTable for table-specific whitelist required, boolean enforceForUnknownTables default false). In check(): extract table name using extractTableName(), lookup requiredFields = config.getByTable().get(tableName), if requiredFields null and enforceForUnknownTables false return (skip), extract WHERE fields using extractFields(), check if fields.stream().anyMatch(requiredFields::contains), if false add MEDIUM violation "表" + tableName + "的WHERE条件必须包含以下字段之一:" + requiredFields.
- **Edge Case Testing:** Add test methods: `testJoinMultipleTables_shouldUsePrimaryTable()` (SELECT * FROM user JOIN order ON user.id=order.user_id WHERE order.status=? → extract primary table "user", check against user whitelist), `testTableWithMultipleRequiredFields_anyOneSatisfies()` (user table requires [id, user_id, email], WHERE email=? passes), `testTableNotInWhitelist_shouldPass()` (config table not in byTable map, query passes), `testEmptyRequiredFields_shouldPass()` (table in byTable map with empty list, all queries pass), `testEnforceForUnknownTables_shouldViolate()` (config.enforceForUnknownTables=true, unknown table without required fields violates). Run tests ensuring table-specific whitelist enforcement works correctly.

### Task 2.6 – Pagination Detection Infrastructure │ Agent_Core_Engine_Validation

- **Objective:** Build shared pagination detection infrastructure distinguishing between LOGICAL (dangerous in-memory pagination), PHYSICAL (SQL-level LIMIT pagination), and NONE types, with plugin detection for MyBatis PageHelper and MyBatis-Plus PaginationInnerInterceptor to enable accurate pagination abuse checking.
- **Output:**
  - PaginationType enum (LOGICAL, PHYSICAL, NONE) categorizing pagination approaches
  - PaginationPluginDetector class detecting MyBatis and MyBatis-Plus pagination plugins
  - detectPaginationType() method implementing design 3.3.5 detection logic
  - Comprehensive tests covering all pagination scenario combinations
- **Guidance:** Pagination detection is foundational for Tasks 2.7-2.12 pagination checkers. LOGICAL pagination (RowBounds without plugin) loads entire result set into memory then skips rows in-memory causing OOM. PHYSICAL pagination (LIMIT in SQL or plugin-assisted) performs database-level filtering. Detection logic checks SQL for LIMIT clause, context for RowBounds/IPage parameters, and Spring context for pagination plugin beans. Plugin detection handles both PageHelper (MyBatis) and PaginationInnerInterceptor (MyBatis-Plus). Design section 3.3.5 provides complete detection logic decision tree. Depends on: Task 2.1 Output (RuleChecker framework).

1. **PaginationType Enum TDD:** Write test class `PaginationDetectionTest` with test method `testPaginationTypeEnum()` verifying enum has three constants: LOGICAL (dangerous), PHYSICAL (safe), NONE (no pagination). Implement `PaginationType` enum in `com.footstone.sqlguard.validator.pagination` package with constants LOGICAL, PHYSICAL, NONE. Add Javadoc explaining each type: LOGICAL - RowBounds/IPage without pagination plugin, loads entire result set into memory then skips in-memory (OOM risk); PHYSICAL - LIMIT clause in SQL or pagination plugin enabled, database performs row filtering (safe); NONE - no pagination detected.
2. **Plugin Detection TDD:** Write test class `PaginationPluginDetectorTest` with test methods: `testNoPaginationPlugin_shouldReturnFalse()`, `testPageHelper_shouldReturnTrue()` (MyBatis interceptor list contains PageHelper), `testMpPaginationInnerInterceptor_shouldReturnTrue()` (MybatisPlusInterceptor contains PaginationInnerInterceptor). Implement `PaginationPluginDetector` class with constructor accepting optional `List<Interceptor> mybatisInterceptors` (nullable) and optional `MybatisPlusInterceptor mybatisPlusInterceptor` (nullable). Implement `boolean hasPaginationPlugin()` method: if mybatisPlusInterceptor not null, call getInterceptors() and stream().anyMatch(i -> i instanceof PaginationInnerInterceptor); if mybatisInterceptors not null, stream().anyMatch(i -> i.getClass().getName().contains("PageInterceptor")); return true if either detection succeeds, false otherwise.
3. **Pagination Type Detection TDD:** Write test class `PaginationTypeDetectionTest` with comprehensive test methods: `testRowBoundsWithoutPlugin_shouldBeLogical()` (SqlContext with RowBounds, no plugin configured), `testRowBoundsWithPageHelper_shouldBePhysical()` (RowBounds + plugin), `testIPageWithMpPlugin_shouldBePhysical()` (IPage parameter + PaginationInnerInterceptor), `testLimitInSql_shouldBePhysical()` (SQL contains LIMIT clause), `testPlainQuery_shouldBeNone()` (no LIMIT, no RowBounds, no IPage). Implement `PaginationType detectPaginationType(SqlContext context)` method in PaginationPluginDetector: extract Statement from context.getParsedSql(), check hasLimit = (stmt instanceof Select && ((Select)stmt).getLimit() != null), check hasPageParam = (context.getRowBounds() != null && context.getRowBounds() != RowBounds.DEFAULT) || hasIPageParameter(context.getParams()), call hasPlugin = hasPaginationPlugin(). Apply logic from design 3.3.5: if (hasPageParam && !hasLimit && !hasPlugin) return LOGICAL; if (hasLimit || (hasPageParam && hasPlugin)) return PHYSICAL; else return NONE. Implement helper hasIPageParameter() checking if any param value instanceof IPage.
4. **Comprehensive Scenario Testing:** Write integration test `PaginationScenarioIntegrationTest` with all combinations: test RowBounds(offset=0, limit=10) without plugin configured (expect LOGICAL), test RowBounds with PageHelper interceptor in list (expect PHYSICAL), test IPage parameter with MybatisPlusInterceptor containing PaginationInnerInterceptor (expect PHYSICAL), test SQL "SELECT * FROM user LIMIT 10" (expect PHYSICAL), test SQL "SELECT * FROM user LIMIT 10 OFFSET 5" (expect PHYSICAL), test plain SQL "SELECT * FROM user WHERE id=?" with no pagination params (expect NONE), test RowBounds.DEFAULT (infinite bounds, should be NONE not LOGICAL). Verify detection accuracy 100% across all combinations. Run `mvn test` ensuring all pagination detection tests pass.

### Task 2.7 – Logical Pagination Checker │ Agent_Core_Engine_Validation

- **Objective:** Implement CRITICAL-level checker detecting logical pagination (RowBounds/IPage without pagination plugin), the most dangerous pagination pattern causing entire result sets to load into memory before in-memory row skipping, frequently causing production OOM crashes.
- **Output:**
  - LogicalPaginationChecker class using PaginationDetection infrastructure
  - CRITICAL violation with actionable suggestion to configure pagination plugin
  - Integration tests with actual RowBounds instances and violation detail verification
- **Guidance:** Logical pagination is CRITICAL risk as it bypasses database-level filtering, loading potentially millions of rows into JVM memory. MyBatis RowBounds without PageHelper plugin executes full query, then skips offset rows and limits result in-memory. MyBatis-Plus IPage without PaginationInnerInterceptor has same behavior. Detection leverages Task 2.6 PaginationType infrastructure. Violation message must be urgent and actionable, directing developers to immediate fix (configure plugin). Violation details should include pagination parameters (offset, limit) for debugging. Depends on: Task 2.6 Output (PaginationDetection infrastructure).

- **Logical Pagination Detection TDD:** Write test class `LogicalPaginationCheckerTest` with test methods: `testRowBoundsWithoutPlugin_shouldViolate()` (create SqlContext with RowBounds(100, 20), no plugin, expect CRITICAL violation), `testRowBoundsWithPageHelper_shouldPass()` (RowBounds + PageHelper plugin configured, expect no violation as PHYSICAL pagination), `testNoRowBounds_shouldPass()` (plain query without RowBounds), `testRowBoundsDefault_shouldPass()` (RowBounds.DEFAULT is infinite bounds, not pagination). Implement `LogicalPaginationChecker` class in validator.pagination.impl package extending AbstractRuleChecker with LogicalPaginationConfig (extends CheckerConfig). In check(SqlContext, ValidationResult): call paginationDetector.detectPaginationType(context), if type == PaginationType.LOGICAL, add CRITICAL violation "检测到逻辑分页!将加载全表数据到内存,可能导致OOM" with suggestion "立即配置分页插件:MyBatis-Plus PaginationInnerInterceptor或PageHelper". Extract RowBounds from context.getRowBounds(), add to violation details map: details.put("offset", rowBounds.getOffset()), details.put("limit", rowBounds.getLimit()).
- **Integration Testing:** Write integration test `LogicalPaginationIntegrationTest` with actual RowBounds instances: test various offset/limit combinations (offset=0 limit=10, offset=100 limit=50, offset=10000 limit=100), verify each violates when plugin not configured. Verify violation detail extraction: assert result.getDetails().get("offset") equals expected offset, assert result.getDetails().get("limit") equals expected limit. Test configuration enabled/disabled toggle: create LogicalPaginationConfig with enabled=false, verify checker.isEnabled() returns false and no violations added by orchestrator. Run `mvn test` ensuring logical pagination detection is accurate.

### Task 2.8 – Physical Pagination - No-Condition Check │ Agent_Core_Engine_Validation

- **Objective:** Implement highest-priority CRITICAL-level physical pagination checker detecting unconditioned LIMIT queries (e.g., "SELECT * FROM user LIMIT 100") which still scan entire table despite pagination, with early-return mechanism preventing lower-priority pagination checks when violated.
- **Output:**
  - NoConditionPaginationChecker class with early-return violation handling
  - CRITICAL violation for unconditioned or dummy-conditioned physical pagination
  - Integration tests verifying early-return prevents subsequent pagination checkers
- **Guidance:** No-condition physical pagination is CRITICAL as developers assume LIMIT prevents issues, but database still performs full table scan when WHERE missing, just limits returned rows. This checker has highest priority among physical pagination checks (Tasks 2.8-2.11), implementing early-return to prevent misleading additional violations (deep offset, missing ORDER BY don't matter if query scans entire table anyway). Reuses isDummyCondition() from AbstractRuleChecker to detect "WHERE 1=1" patterns. LIMIT details included in violation report for debugging. Depends on: Task 2.6 Output (PaginationDetection for PHYSICAL type detection).

1. **No-Condition Detection TDD:** Write test class `NoConditionPaginationCheckerTest` with test methods: `testPhysicalPaginationNoWhere_shouldViolate()` (SQL "SELECT * FROM user LIMIT 10" with PHYSICAL type), `testPhysicalPaginationDummyWhere_shouldViolate()` (SQL "SELECT * FROM user WHERE 1=1 LIMIT 10"), `testPhysicalPaginationValidWhere_shouldPass()` (SQL "SELECT * FROM user WHERE id > ? LIMIT 10"), `testLogicalPagination_shouldSkip()` (LOGICAL type should not trigger this checker), `testNoPagination_shouldSkip()` (NONE type should not trigger). Implement `NoConditionPaginationChecker` class in validator.pagination.impl package extending AbstractRuleChecker. In check(): call detectPaginationType(context), if type != PHYSICAL return early (skip), extract WHERE = extractWhere(context.getParsedSql()), check if WHERE == null || isDummyCondition(WHERE), if true extract LIMIT details from SELECT statement and add CRITICAL violation "无条件物理分页,仍会全表扫描" with suggestion "添加业务WHERE条件限制查询范围".
2. **Early Return Implementation:** Implement early-return mechanism in check() method: after detecting no-condition physical pagination violation, set special flag in ValidationResult.details indicating early-return ("earlyReturn", true). Document in Javadoc that this checker should run before other physical pagination checkers (Tasks 2.9-2.11) to prevent misleading violations. Include LIMIT details in violation: extract limit.getRowCount() and limit.getOffset() (if present), add to violation details for debugging context.
3. **Integration Testing:** Write integration test `NoConditionPaginationIntegrationTest` verifying early-return behavior: create orchestrator with NoConditionPaginationChecker (Task 2.8) + DeepPaginationChecker (Task 2.9) + MissingOrderByChecker (Task 2.11), execute SQL "SELECT * FROM user LIMIT 10000" (no WHERE, deep offset), verify only NoConditionPaginationChecker violation present (early-return prevents deep offset check). Test PHYSICAL pagination with no WHERE (violate), test PHYSICAL with dummy WHERE "1=1" (violate), test PHYSICAL with valid WHERE "id > 0" (pass). Verify CRITICAL risk level. Run tests ensuring early-return mechanism works correctly.

### Task 2.9 – Physical Pagination - Deep Offset Check │ Agent_Core_Engine_Validation

- **Objective:** Implement MEDIUM-level checker detecting deep pagination (high OFFSET values in LIMIT queries) causing database to scan and skip large row counts before returning results, degrading performance significantly as offset increases.
- **Output:**
  - DeepPaginationChecker class with offset calculation supporting multiple LIMIT syntaxes
  - PaginationAbuseConfig.maxOffset threshold configuration (default 10000)
  - Boundary condition tests verifying threshold enforcement accuracy
- **Guidance:** Deep pagination is MEDIUM risk (less severe than no-condition) as query is properly filtered by WHERE but requires database to scan offset+limit rows, discarding first offset rows. Common when users navigate to high page numbers. Example: OFFSET 100000 LIMIT 20 scans 100020 rows, returns 20. Performance degrades linearly with offset. Solution is cursor-based pagination (WHERE id > lastId). Checker handles both LIMIT syntaxes: "LIMIT n OFFSET m" and "LIMIT m,n" (MySQL). Threshold configurable via PaginationAbuseConfig.maxOffset (default 10000). Depends on: Task 2.6 Output (PHYSICAL type detection), Task 2.8 must run first (early-return skips this checker if no-condition).

1. **Deep Offset Detection TDD:** Write test class `DeepPaginationCheckerTest` with test methods: `testOffsetBelowThreshold_shouldPass()` (LIMIT 20 OFFSET 9999 with maxOffset=10000), `testOffsetAboveThreshold_shouldViolate()` (LIMIT 20 OFFSET 10001 with maxOffset=10000), `testOffsetEqualsThreshold_shouldPass()` (LIMIT 20 OFFSET 10000 with maxOffset=10000), `testNoConditionPagination_shouldSkipThisChecker()` (if Task 2.8 early-returned). Implement `DeepPaginationChecker` class extending AbstractRuleChecker with PaginationAbuseConfig containing maxOffset field (default 10000). In check(): call detectPaginationType(), if type != PHYSICAL return, check if ValidationResult.details contains "earlyReturn" (Task 2.8 triggered, skip), extract Limit from SELECT statement, calculate offset.
2. **Offset Calculation:** Implement offset calculation supporting multiple LIMIT syntaxes: if limit.getOffset() != null, offset = limit.getOffset().getValue() (explicit OFFSET syntax "LIMIT n OFFSET m"); else if limit.getRowCount() and limit.getOffsetJdbcParameter() exist, use MySQL syntax "LIMIT offset,rowCount" where getOffsetJdbcParameter() provides offset; else offset = 0 (no offset, just LIMIT n). Compare calculated offset against config.getMaxOffset(), if offset > maxOffset add MEDIUM violation "深分页offset=" + offset + ",需扫描并跳过" + offset + "行数据,性能较差" with suggestion "建议使用游标分页(WHERE id > lastId)避免深度offset".
3. **Boundary Testing:** Write boundary condition tests: `testOffsetMaxMinusOne_shouldPass()` (offset = maxOffset - 1), `testOffsetMaxPlusOne_shouldViolate()` (offset = maxOffset + 1), `testLimitOffsetSyntax_shouldCalculateCorrectly()` (LIMIT 20 OFFSET 5000), `testLimitCommaSyntax_shouldCalculateCorrectly()` (LIMIT 5000,20 MySQL syntax), `testOnlyLimitNoOffset_shouldPassWithZeroOffset()` (LIMIT 100). Test configuration toggle: disabled checker should not add violations. Verify MEDIUM risk level. Run `mvn test` ensuring offset calculation and threshold checking work correctly.

### Task 2.10 – Physical Pagination - Large PageSize Check │ Agent_Core_Engine_Validation

- **Objective:** Implement MEDIUM-level checker detecting excessively large pageSize values in LIMIT queries (e.g., LIMIT 10000) causing single query to return massive datasets potentially overwhelming application memory or network bandwidth.
- **Output:**
  - LargePageSizeChecker class extracting page size from LIMIT clause
  - PaginationAbuseConfig.maxPageSize threshold configuration (default 1000)
  - Tests covering both LIMIT syntaxes and boundary conditions
- **Guidance:** Large pageSize is MEDIUM risk as properly filtered query (has WHERE, reasonable offset) still returns too many rows per request. Common when developers set pagination but use unreasonably high page sizes. Example: LIMIT 5000 returns 5000 rows consuming significant memory and bandwidth. Checker extracts pageSize from LIMIT clause handling both syntaxes: "LIMIT n" extracts n as pageSize, "LIMIT m,n" extracts n as pageSize (m is offset). Threshold configurable via PaginationAbuseConfig.maxPageSize (default 1000 rows). Independent check from deep offset (Task 2.9), both can trigger on same SQL. Depends on: Task 2.6 Output (PHYSICAL type detection).

1. **PageSize Extraction TDD:** Write test class `LargePageSizeCheckerTest` with test methods: `testPageSizeBelowThreshold_shouldPass()` (LIMIT 999 with maxPageSize=1000), `testPageSizeAboveThreshold_shouldViolate()` (LIMIT 1001 with maxPageSize=1000), `testPageSizeEqualsThreshold_shouldPass()` (LIMIT 1000 with maxPageSize=1000). Implement `LargePageSizeChecker` class extending AbstractRuleChecker using PaginationAbuseConfig.maxPageSize field (default 1000). In check(): detectPaginationType(), if != PHYSICAL return, extract Limit from SELECT, calculate pageSize.
2. **PageSize Calculation:** Implement pageSize extraction supporting both LIMIT syntaxes: if limit.getRowCount() != null, pageSize = limit.getRowCount().getValue() (works for both "LIMIT n" and "LIMIT m,n" syntaxes as getRowCount() returns the row count portion); else pageSize = 0 (shouldn't happen if LIMIT exists). Compare pageSize against config.getMaxPageSize(), if pageSize > maxPageSize add MEDIUM violation "pageSize=" + pageSize + "过大,单次查询数据量过多" with suggestion "建议降低pageSize到" + maxPageSize + "以内,避免单次返回过多数据".
3. **Testing:** Write tests: `testPageSizeMaxMinusOne_shouldPass()` (999 vs 1000), `testPageSizeMaxPlusOne_shouldViolate()` (1001 vs 1000), `testLimitOnlySyntax_shouldExtractCorrectly()` (LIMIT 500), `testLimitCommaSyntax_shouldExtractRowCount()` (LIMIT 100,500 extracts 500 as pageSize). Test configuration toggle. Verify MEDIUM risk level. Run `mvn test` ensuring pageSize extraction and threshold checking work.

### Task 2.11 – Physical Pagination - Missing ORDER BY Check │ Agent_Core_Engine_Validation

- **Objective:** Implement LOW-level checker detecting physical pagination queries lacking ORDER BY clause, causing unstable result ordering across pages (same query may return different row orders on different executions, pagination becomes non-deterministic).
- **Output:**
  - MissingOrderByChecker class verifying ORDER BY presence in paginated SELECT
  - LOW violation indicating result instability issue
  - Simple tests for ORDER BY presence/absence with configuration toggle
- **Guidance:** Missing ORDER BY is LOW risk (least severe pagination issue) as query works but results unpredictable. Database default ordering is not guaranteed stable across executions or version changes. Without ORDER BY, paginating "page 2" may show rows from "page 1" on subsequent request or vice versa. Critical for user-facing pagination where consistency matters. Simple check: if PHYSICAL pagination detected and SELECT.getOrderByElements() is null or empty, violate. Configuration allows disabling if organization accepts non-deterministic pagination. Depends on: Task 2.6 Output (PHYSICAL type detection).

- **ORDER BY Detection TDD:** Write test class `MissingOrderByCheckerTest` with test methods: `testPaginationWithOrderBy_shouldPass()` (SELECT * FROM user WHERE id>0 ORDER BY id LIMIT 10), `testPaginationWithoutOrderBy_shouldViolate()` (SELECT * FROM user WHERE id>0 LIMIT 10), `testNoPagination_shouldSkip()` (plain query without LIMIT). Implement `MissingOrderByChecker` class extending AbstractRuleChecker with MissingOrderByConfig (extends CheckerConfig). In check(): detectPaginationType(), if != PHYSICAL return, cast statement to SELECT, call select.getOrderByElements(), if orderByElements == null || orderByElements.isEmpty() add LOW violation "分页查询缺少ORDER BY,结果顺序不稳定" with suggestion "添加ORDER BY子句确保分页结果顺序稳定".
- **Testing:** Write tests: `testMultipleOrderByColumns_shouldPass()` (ORDER BY create_time DESC, id ASC), `testSingleOrderBy_shouldPass()` (ORDER BY id), `testNoOrderBy_shouldViolate()`, `testDisabledChecker_shouldSkip()`. Verify LOW risk level. Test configuration toggle. Run `mvn test` ensuring ORDER BY detection works.

### Task 2.12 – NoPaginationChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement comprehensive checker detecting SELECT queries completely lacking pagination limits (no LIMIT, no RowBounds, no IPage), with risk stratification (CRITICAL for no WHERE, HIGH for blacklist-only WHERE, MEDIUM for others), whitelist exemptions for known-safe queries, and unique key detection.
- **Output:**
  - NoPaginationChecker class with hasPaginationLimit(), assessNoPaginationRisk(), isWhitelisted(), hasUniqueKeyCondition() methods
  - NoPaginationConfig with whitelistMapperIds, whitelistTables, uniqueKeyFields, enforceForAllQueries
  - Comprehensive tests covering all risk levels and whitelist exemptions
- **Guidance:** No pagination is variable risk depending on WHERE clause: CRITICAL if no WHERE (returns entire table), HIGH if blacklist-only WHERE (returns most rows), MEDIUM if enforceForAllQueries enabled (preventive measure). Whitelist provides escape hatch for legitimate full-table queries (config tables, getById methods, count queries). Unique key detection exempts single-row queries (WHERE id=123). Risk stratification ensures most dangerous scenarios flagged highest. Whitelist supports wildcards (*.getById, *.count*) for pattern matching. Depends on: Task 2.6 Output (pagination detection to verify no pagination), Task 2.4 for blacklist field detection logic.

1. **Pagination Detection TDD:** Write test class `NoPaginationCheckerTest` with test method `testHasPaginationLimit()` covering: SQL with LIMIT clause (true), SqlContext with RowBounds + pagination plugin (true), SqlContext with IPage + plugin (true), plain query with none of above (false). Implement `hasPaginationLimit(Select select, SqlContext context)` method in NoPaginationChecker: check select.getLimit() != null, check context.getRowBounds() != null && RowBounds.DEFAULT != context.getRowBounds() && pluginDetector.hasPaginationPlugin(), check hasIPageParameter(context.getParams()) && pluginDetector.hasPaginationPlugin(), return true if any condition met.
2. **Risk Stratification TDD:** Write test method `testAssessNoPaginationRisk()` covering three risk levels: no WHERE clause (CRITICAL "SELECT查询无条件且无分页限制,可能返回全表数据导致内存溢出"), blacklist-only WHERE (HIGH "SELECT查询条件只有黑名单字段{fields}且无分页,可能返回大量数据"), normal WHERE with enforceForAllQueries=true (MEDIUM "SELECT查询缺少分页限制,建议添加LIMIT或使用分页"). Implement `assessNoPaginationRisk(Select, SqlContext, ValidationResult)`: extract WHERE, if WHERE == null || isDummyCondition(WHERE) add CRITICAL violation; else extract fields, if allBlacklisted(fields) add HIGH violation; else if config.isEnforceForAllQueries() add MEDIUM violation.
3. **Whitelist Matching TDD:** Write test method `testIsWhitelisted()` covering: mapperId matching wildcard pattern "*.getById" (true), table name in whitelistTables (true), WHERE contains unique key field with equals (true), none of above (false). Implement `isWhitelisted(SqlContext)`: check mapperId against config.getWhitelistMapperIds() using wildcard matching, check extractTableName() against config.getWhitelistTables(), call hasUniqueKeyCondition(), return true if any match.
4. **Unique Key Detection TDD:** Write test method `testHasUniqueKeyCondition()` covering: WHERE id=? (true), WHERE id=123 (true), WHERE user_id=? with user_id in uniqueKeyFields config (true), WHERE status=? (false). Implement `hasUniqueKeyCondition(SqlContext)`: extract WHERE expression, extract fields, check if any field in ["id"] + config.getUniqueKeyFields(), if found check if isEqualsCondition(where, field) using helper traversing Expression tree looking for EqualsTo with field on left side, return true if unique key with equals condition found.
5. **Integration Testing:** Write comprehensive integration test covering all scenarios: no WHERE + no pagination (CRITICAL), blacklist-only WHERE + no pagination (HIGH), normal WHERE + no pagination + enforceForAllQueries (MEDIUM), whitelisted by mapperId pattern (pass), whitelisted by table name (pass), whitelisted by unique key WHERE id=? (pass), RowBounds + plugin present (pass, has pagination), LIMIT clause present (pass, has pagination). Verify interaction with LogicalPaginationChecker: RowBounds without plugin should trigger LogicalPaginationChecker not NoPaginationChecker. Run `mvn test` ensuring all risk levels and exemptions work correctly.

### Task 2.13 – DefaultSqlSafetyValidator Assembly │ Agent_Core_Engine_Validation

- **Objective:** Assemble complete validation engine coordinating all rule checkers (Tasks 2.2-2.12), implementing parse-once SQL parsing with JSqlParser facade, SQL deduplication filter preventing redundant validation, and end-to-end integration with performance benchmarking achieving <5% overhead target.
- **Output:**
  - DefaultSqlSafetyValidator class implementing SqlSafetyValidator interface
  - SqlDeduplicationFilter with ThreadLocal LRU cache and configurable TTL
  - Comprehensive integration tests with multi-rule violations and parse failure scenarios
  - JMH performance benchmark demonstrating <5% overhead target achievement
- **Guidance:** This is final assembly task integrating all validation components into production-ready engine. SqlSafetyValidator interface defines public contract used by interceptors (Phase 4). Deduplication filter prevents same SQL being validated multiple times when multiple interception layers enabled (MyBatis + JDBC). Parse-once optimization parses SQL once via JSqlParserFacade, stores in SqlContext.parsedSql, all checkers reuse parsed AST. RuleCheckerOrchestrator from Task 2.1 manages checker execution. Performance critical: validation must add <5% overhead to SQL execution (measured via JMH). **Config Usage Note:** Checker constructors require config classes from `com.footstone.sqlguard.validator.rule.impl` package (runtime configs extending CheckerConfig), NOT from `com.footstone.sqlguard.config` package (YAML POJOs). See Dual-Config Pattern doc for details. Depends on: Task 2.1 (orchestrator), Tasks 2.2-2.12 (all checkers), Phase 1 Task 1.4 (JSqlParser facade).

1. **Interface Implementation TDD:** Write test class `DefaultSqlSafetyValidatorTest` with test method `testValidateInterface()` verifying SqlSafetyValidator contract: validate(SqlContext) returns ValidationResult, result contains violations from enabled checkers, result.passed = false when violations present. Implement `SqlSafetyValidator` interface in com.footstone.sqlguard.validator package with single method `ValidationResult validate(SqlContext context)`. Implement `DefaultSqlSafetyValidator` class in same package with constructor accepting JSqlParserFacade facade and List<RuleChecker> checkers. Store as final fields. In validate(): call deduplicationFilter.shouldCheck(), if false return ValidationResult.pass(), proceed with validation.
2. **Deduplication Filter TDD:** Write test class `SqlDeduplicationFilterTest` with test methods: `testFirstCheck_shouldAllow()`, `testSameS SQLWithinTTL_shouldSkip()` (same SQL checked twice within 100ms TTL, second returns false), `testSameSQLAfterTTL_shouldAllow()` (same SQL after TTL expires, returns true), `testDifferentSQL_shouldAllow()`, `testClearThreadCache_shouldClearCache()`. Implement `SqlDeduplicationFilter` class with ThreadLocal<LRUCache<String, Long>> field initialized with LRU cache of configurable size (default 1000). Implement `boolean shouldCheck(String sql)`: compute MD5 hash of sql as key (or use sql directly if short), get cache from ThreadLocal, check cache.get(key), if value exists and (System.currentTimeMillis() - value) < config.getTtlMs(), return false (skip, recently checked), else put(key, currentTimeMillis) and return true. Implement static `clearThreadCache()` calling ThreadLocal.remove() for cleanup.
3. **Parse-Once Integration TDD:** Write test class `ParseOnceIntegrationTest` verifying: parsedSql null in context triggers facade.parse() call, parsedSql set in context after parse, all checkers receive same parsedSql instance (no re-parsing), parse failure with fail-fast config throws SqlParseException, parse failure with lenient config logs warning and returns pass. Implement parse-once logic in validate(): check if context.getParsedSql() == null, if null call Statement stmt = facade.parse(context.getSql()), call context.setParsedSql(stmt), if facade.parse() throws SqlParseException call handleParseFailure(context, exception): if failFast throw exception, else log.warn() and return ValidationResult.pass(). After parse completes, proceed to checker orchestration.
4. **Orchestrator Integration:** Integrate RuleCheckerOrchestrator from Task 2.1: create ValidationResult result = new ValidationResult(), call orchestrator.orchestrate(context, result), return result. Orchestrator handles checker iteration, enabled/disabled filtering, violation aggregation. Ensure all checkers (Tasks 2.2-2.12: NoWhereClauseChecker, DummyConditionChecker, BlacklistFieldChecker, WhitelistFieldChecker, LogicalPaginationChecker, NoConditionPaginationChecker, DeepPaginationChecker, LargePageSizeChecker, MissingOrderByChecker, NoPaginationChecker) injected in constructor List<RuleChecker>.
5. **End-to-End Integration & Performance Testing:** Write integration test `SqlSafetyValidatorIntegrationTest` with realistic SQL samples: test SQL violating multiple rules (no WHERE + no pagination + missing ORDER BY, verify all violations reported with correct risk levels aggregated to highest), test SQL with no violations (proper WHERE + pagination + ORDER BY, verify passed=true), test parse failure (invalid SQL syntax, verify fail-fast throws exception or lenient returns pass), test deduplication (validate same SQL twice, second call skips validation, verify cache works), test all checkers enabled (verify all 10 checkers execute). Write JMH micro-benchmark `SqlValidationBenchmark`: establish baseline (parse SQL + extract WHERE without validation), measure validation overhead (full validate() call with all checkers), calculate overhead percentage, verify <5% overhead target from design section 9.1. Run `mvn test` and `mvn test -Pbenchmark` ensuring all integration tests pass and performance target met.

## Phase 3: Static Code Scanner - Agent_Static_Scanner

### Task 3.1 – Scanner Core Framework & Orchestration │ Agent_Static_Scanner

- **Objective:** Establish complete static analysis framework providing core data models (SqlEntry, ScanReport, ScanContext), parser interfaces (SqlParser, WrapperScanner), and orchestration engine (SqlScanner) that coordinates XML/annotation/wrapper scanning to produce comprehensive scan reports for dangerous SQL detection.
- **Output:**
  - SqlEntry class capturing SQL location metadata (source type, filePath, mapperId, sqlType, rawSql, lineNumber, dynamic flag, sqlVariants list for dynamic SQL)
  - ScanReport class aggregating scan results (SqlEntry list, WrapperUsage list, statistics summary)
  - ScanContext class encapsulating scan configuration (projectPath, SqlGuardConfig)
  - SqlParser interface defining parse contract for XML and annotation parsers
  - WrapperScanner interface defining scan contract for QueryWrapper detection
  - WrapperUsage class tracking MyBatis-Plus wrapper usage locations requiring runtime validation
  - SqlScanner orchestration class coordinating all parsers and report generation
  - Comprehensive unit tests validating data models, interfaces, and orchestration logic
- **Guidance:** This framework is foundational for all static scanning tasks (Tasks 3.2-3.7). SqlEntry supports both static SQL (XML/annotations) and dynamic SQL (MyBatis variants) through sqlVariants list. ScanReport provides unified structure for console and HTML report generation (Task 3.6). SqlScanner implements orchestration pattern accepting all parsers via constructor injection, enabling extensibility for future parser types. Parser interfaces define uniform contracts allowing polymorphic scanner execution. WrapperUsage captures QueryWrapper locations for runtime interception coordination, as static analysis cannot determine dynamic conditions. Follow TDD methodology with comprehensive tests before implementation. Depends on: None (foundational task).

1. **Data Model TDD:** Write test class `SqlEntryTest` covering: creation with all fields, source type validation (XML/ANNOTATION/WRAPPER), dynamic flag toggling, sqlVariants list manipulation, equals/hashCode based on filePath+lineNumber. Write test class `ScanReportTest` covering: adding SqlEntry items, adding WrapperUsage items, statistics calculation (total counts, violation counts by risk level), empty report handling. Write test class `ScanContextTest` covering: construction with projectPath and config, null handling, immutability verification. Then implement `SqlEntry` class in `com.footstone.sqlguard.scanner.model` package with fields: SourceType source (enum: XML, ANNOTATION, WRAPPER), String filePath, String mapperId, SqlCommandType sqlType, String rawSql, int lineNumber, boolean dynamic, List<String> sqlVariants (ArrayList). Implement `ScanReport` class with fields: List<SqlEntry> entries, List<WrapperUsage> wrapperUsages, Map<String, Integer> statistics. Implement `ScanContext` class with fields: Path projectPath, SqlGuardConfig config. Add validation: filePath and rawSql cannot be null/empty, lineNumber > 0.

2. **Parser Interface TDD:** Write test class `SqlParserInterfaceTest` with mock implementations verifying: parse(File) returns List<SqlEntry>, parse handles file not found, parse handles malformed XML/Java gracefully. Write test class `WrapperScannerInterfaceTest` with mock implementations verifying: scan(File) returns List<WrapperUsage>, scan handles directory traversal, scan handles parse errors. Then define `SqlParser` interface in `com.footstone.sqlguard.scanner.parser` package with method: `List<SqlEntry> parse(File file) throws IOException, ParseException`. Define `WrapperScanner` interface with method: `List<WrapperUsage> scan(File projectRoot) throws IOException`. Implement `WrapperUsage` class in scanner.model with fields: String filePath, String methodName, int lineNumber, String wrapperType (QueryWrapper/LambdaQueryWrapper/UpdateWrapper/LambdaUpdateWrapper), boolean needsRuntimeCheck (default true indicating static analysis insufficient).

3. **Orchestration TDD:** Write test class `SqlScannerTest` covering: scan with all parsers returns complete ScanReport, scan aggregates entries from XML and annotation parsers, scan aggregates wrapper usages from wrapper scanner, scan calculates statistics (total SQL count, dynamic SQL count, wrapper count), scan handles empty project (no SQL files), scan handles parser exceptions gracefully. Then implement `SqlScanner` class in `com.footstone.sqlguard.scanner` package with constructor accepting: `XmlMapperParser xmlParser`, `AnnotationParser annotationParser`, `QueryWrapperScanner wrapperScanner`, `SqlRiskEvaluator evaluator` (all injected dependencies). Implement `scan(ScanContext context)` method from design 6.2: discover all relevant files (*.xml under src/main/resources for MyBatis mappers, *.java under src/main/java for annotations/wrappers), delegate XML files to xmlParser.parse(), delegate Java files to annotationParser.parse() for annotation extraction, delegate project root to wrapperScanner.scan() for wrapper detection, collect all SqlEntry results into ScanReport.entries list, collect all WrapperUsage into ScanReport.wrapperUsages list, calculate statistics: total count, violation count by risk level (after evaluator.evaluate() on each entry), wrapper usage count, return populated ScanReport.

4. **Integration Testing:** Write integration test `SqlScannerIntegrationTest` with mock parser implementations: create MockXmlMapperParser returning predefined SqlEntry list, create MockAnnotationParser returning predefined SqlEntry list, create MockWrapperScanner returning predefined WrapperUsage list, create MockSqlRiskEvaluator assigning risk levels. Test orchestration: create SqlScanner with all mock parsers, create ScanContext with test project path, call scan(), verify ScanReport contains entries from all parsers, verify statistics accurate (counts match mock data), verify orchestrator handled all parser results correctly. Test error handling: mock parser throwing IOException, verify SqlScanner handles gracefully without crashing, verify error logged. Run `mvn test` ensuring all framework tests pass.

### Task 3.2 – XML Mapper Parser Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 32 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_2_XML_Mapper_Parser_Implementation.md`

- **Objective:** Implement comprehensive MyBatis XML Mapper parser extracting SQL statements from mapper XML files, detecting dynamic tags (if/where/foreach/choose), generating SQL variants for dynamic scenarios, and producing SqlEntry instances with accurate line numbers and mapperId references for static analysis.
- **Output:**
  - XmlMapperParser class implementing SqlParser interface from Task 3.1
  - DOM4J-based XML parsing extracting namespace and SQL statement tags (select/update/delete/insert)
  - Dynamic tag detection identifying MyBatis control flow tags (if, where, foreach, choose/when/otherwise, set, trim, bind)
  - SQL variant generation for dynamic SQL producing representative execution scenarios
  - Comprehensive tests with sample MyBatis XML files covering static and dynamic SQL patterns
- **Guidance:** XML Mappers are primary SQL source in MyBatis applications requiring accurate parsing with line number preservation for violation reporting. DOM4J 2.x provides SAX-based parsing with line number access via Element.getData(). MapperId format is "namespace.statementId" matching MyBatis runtime convention. Dynamic tags require special handling: static portions extracted as rawSql, variants generated for different execution paths (Task 3.5 generates detailed variants). This parser feeds SqlEntry instances to validation engine allowing pre-deployment SQL safety checks. Follow TDD with comprehensive XML test fixtures covering nested tags, CDATA sections, multi-line SQL, comments. Depends on: Task 3.1 Output (SqlParser interface and SqlEntry class).

1. **Basic XML Parsing TDD:** Write test class `XmlMapperParserTest` with test methods: `testSimpleSelect_shouldCreateSqlEntry()` (parse simple SELECT statement, verify SqlEntry created with correct mapperId, SQL, line number), `testMultipleStatements_shouldCreateMultipleEntries()` (parse XML with select/update/delete/insert, verify all extracted), `testNamespaceExtraction_shouldPrefixMapperId()` (verify namespace attribute used as mapperId prefix), `testLineNumberExtraction_shouldBeAccurate()` (verify line numbers match XML file positions). Add DOM4J 2.1.4 dependency to sql-scanner-core module POM. Implement `XmlMapperParser` class in `com.footstone.sqlguard.scanner.parser.impl` package implementing SqlParser interface. Implement `parse(File file)` method: read file with DOM4J SAXReader, get Document root element, extract namespace attribute for mapperId prefix, call selectNodes("//select|//update|//delete|//insert") to get all SQL statement elements, iterate through elements extracting: id attribute, tag name for SqlCommandType, text content for rawSql (trimmed), line number from element.getData(), create SqlEntry(source=XML, filePath=file.getAbsolutePath(), mapperId=namespace+"."+id, sqlType=commandType, rawSql=sql, lineNumber=lineNum), add to result list, return List<SqlEntry>.

2. **Dynamic Tag Detection TDD:** Write test class `DynamicTagDetectionTest` with test methods: `testIfTag_shouldSetDynamicFlag()` (XML with <if> tag should mark SqlEntry.dynamic=true), `testWhereTag_shouldSetDynamicFlag()` (XML with <where> tag should mark dynamic), `testForeachTag_shouldSetDynamicFlag()` (XML with <foreach> should mark dynamic), `testChooseWhenTag_shouldSetDynamicFlag()` (XML with <choose><when> should mark dynamic), `testStaticSQL_shouldNotBeDynamic()` (XML without dynamic tags should have dynamic=false), `testNestedDynamicTags_shouldDetect()` (nested if inside where should detect). Implement `hasDynamicTags(Element element)` method in XmlMapperParser: recursively check element and descendants for dynamic tag names using Set<String> dynamicTagNames = [\"if\", \"where\", \"foreach\", \"choose\", \"when\", \"otherwise\", \"set\", \"trim\", \"bind\"], call element.selectNodes(\".//\" + tagName) for each dynamic tag, return true if any found. Call hasDynamicTags() during parse() and set SqlEntry.dynamic flag accordingly.

3. **Variant Generation TDD:** Write test class `VariantGenerationTest` with test methods: `testIfTagVariants_shouldGenerateTwoScenarios()` (if tag generates variant with condition true and condition false), `testForeachVariants_shouldGenerateRepresentative()` (foreach generates empty/single/multiple item variants), `testChooseVariants_shouldGeneratePerBranch()` (choose generates one variant per when branch plus otherwise). Implement `generateVariants(Element element)` method from design 6.3: if element has <if> child, generate 2 variants (include content, exclude content), if element has <foreach> child, generate 3 variants (empty collection removes clause, single item no separator, multiple items with separators), if element has <choose> child, generate variant per <when> branch plus <otherwise> branch. For simple cases return List<String> sqlVariants with representative SQL strings. Call generateVariants() during parse() and populate SqlEntry.sqlVariants list. Keep generation simple (representative scenarios, not exhaustive combinations).

4. **Comprehensive Testing:** Write integration test `XmlMapperParserIntegrationTest` with sample XML files in src/test/resources/mappers: simple-static.xml (plain SQL without dynamic tags), if-condition.xml (SQL with <if test="...">), foreach-loop.xml (SQL with <foreach collection="list">), where-tag.xml (SQL with <where> wrapper), nested-dynamic.xml (nested if inside where inside foreach), complex-real-world.xml (realistic MyBatis mapper with multiple statements and dynamic tags). For each test file: parse with XmlMapperParser, verify correct number of SqlEntry instances created, verify line numbers accurate (match actual XML positions), verify mapperId generation correct (namespace.id format), verify dynamic flag set correctly, verify sqlVariants populated for dynamic SQL. Test edge cases: CDATA sections (SQL wrapped in <![CDATA[...]]>), XML comments (should be ignored), multi-line SQL (preserve line breaks), special characters in SQL (quotes, <, >, &). Run `mvn test` ensuring all XML parsing tests pass.

### Task 3.3 – Java Annotation Parser Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 18 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_3_Annotation_Parser_Implementation.md`

- **Objective:** Implement MyBatis annotation-based SQL parser extracting SQL from @Select, @Update, @Delete, @Insert annotations in Java mapper interfaces, handling multiple annotation syntaxes (value="" vs array {"sql"}), generating SqlEntry instances with accurate source locations for static analysis of annotation-defined SQL statements.
- **Output:**
  - AnnotationParser class implementing SqlParser interface from Task 3.1
  - JavaParser 3.x-based Java source parsing traversing method declarations
  - Annotation detection for MyBatis SQL annotations (@Select/@Update/@Delete/@Insert)
  - SQL extraction handling value parameter variations and multi-line strings
  - MapperId generation using className.methodName convention
  - Edge case handling for escaped quotes, concatenated strings, non-SQL annotations
  - Comprehensive tests with sample Java mapper interfaces covering annotation variations
- **Guidance:** Annotation-based mappers are increasingly common in modern MyBatis applications as alternative to XML, requiring robust parsing for complete SQL coverage. JavaParser 3.x provides complete Java AST allowing precise annotation extraction with source positions. SQL in annotations typically uses value="" parameter but MyBatis supports array syntax {"line1", "line2"} for multi-line SQL requiring concatenation during extraction. Line number from annotation.getBegin() provides violation reporting context. This parser complements XmlMapperParser (Task 3.2) enabling comprehensive static analysis across both SQL definition approaches. Follow TDD with diverse annotation test fixtures. Depends on: Task 3.1 Output (SqlParser interface and SqlEntry class).

- **Annotation Parsing TDD:** Write test class `AnnotationParserTest` with test methods: `testSelectAnnotation_shouldExtractSql()` (parse @Select(\"SELECT * FROM user WHERE id=?\") returns SqlEntry), `testUpdateAnnotation_shouldExtractSql()` (parse @Update), `testDeleteAnnotation_shouldExtractSql()` (parse @Delete), `testInsertAnnotation_shouldExtractSql()` (parse @Insert), `testMultipleAnnotatedMethods_shouldExtractAll()` (interface with 5 annotated methods returns 5 SqlEntry), `testNonSqlAnnotation_shouldSkip()` (@Param, @ResultMap annotations ignored). Add JavaParser 3.25.7 dependency to sql-scanner-core module POM. Implement `AnnotationParser` class in `com.footstone.sqlguard.scanner.parser.impl` package implementing SqlParser interface. Implement `parse(File file)` method from design 6.4: parse Java file with `CompilationUnit cu = StaticJavaParser.parse(file)`, extract class name via cu.findFirst(ClassOrInterfaceDeclaration.class).get().getNameAsString() for mapperId prefix, call cu.findAll(MethodDeclaration.class) to get all methods, iterate through methods calling method.getAnnotations(), for each annotation check if annotation.getNameAsString() matches \"Select\"|\"Update\"|\"Delete\"|\"Insert\" (case-sensitive MyBatis annotation names), extract SQL from annotation value parameter, determine SqlCommandType from annotation name, get line number from annotation.getBegin().get().line, create SqlEntry(source=ANNOTATION, filePath=file.getAbsolutePath(), mapperId=className+\".\"+method.getNameAsString(), sqlType=commandType, rawSql=extractedSql, lineNumber=lineNum, dynamic=false), add to result list.

- **SQL Extraction Logic:** Implement `extractSqlFromAnnotation(AnnotationExpr annotation)` helper method handling multiple syntaxes: check if annotation has single member (value="...") vs named member (value="..."), handle both NormalAnnotationExpr and SingleMemberAnnotationExpr from JavaParser, extract value as StringLiteralExpr for simple case, extract value as ArrayInitializerExpr for array syntax {"line1", "line2"}, concatenate array elements with space separator for multi-line SQL, remove quotes from string literals, handle escaped quotes (\" → "), trim whitespace, return extracted SQL string. Handle annotations with additional parameters (@Select(value="...", timeout=30)) by extracting only value parameter. Log warning if value parameter missing or not string/array type.

- **Edge Case Testing:** Write comprehensive tests: `testMultiLineSqlString_shouldConcatenate()` (@Select(value={"SELECT * FROM user", "WHERE id=?"}) concatenates to single SQL), `testEscapedQuotes_shouldHandle()` (@Select(\"SELECT * FROM user WHERE name='O\\'Brien'\") preserves quotes), `testAnnotationWithOtherParams_shouldExtractValue()` (@Select(value="...", timeout=30, fetchSize=100) extracts only value), `testNonSqlAnnotation_shouldSkip()` (@Param(\"id\"), @ResultMap(\"userMap\") do not create SqlEntry), `testLineNumberAccuracy_shouldMatch()` (verify annotation.getBegin().line matches actual Java file line), `testStringConcatenation_shouldHandle()` (@Select(\"SELECT * \" + \"FROM user\") extracts concatenated SQL if possible, or logs warning if too complex). Test with src/test/resources/mappers sample Java files: SimpleMapper.java (basic @Select/@Update/@Delete/@Insert), ComplexMapper.java (multi-line SQL arrays, escaped quotes, additional parameters), MixedMapper.java (SQL and non-SQL annotations mixed). Run `mvn test` ensuring all annotation parsing tests pass.

### Task 3.4 – QueryWrapper Static Scanner Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 39 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_4_QueryWrapper_Scanner_Implementation.md`

- **Objective:** Implement MyBatis-Plus QueryWrapper usage scanner detecting QueryWrapper, LambdaQueryWrapper, UpdateWrapper, and LambdaUpdateWrapper instantiations in Java source code, marking usage locations for runtime interception since static analysis cannot determine dynamic query conditions, producing WrapperUsage entries for scan reports.
- **Output:**
  - QueryWrapperScanner class implementing WrapperScanner interface from Task 3.1
  - Recursive Java file discovery using Files.walk() traversing src/main/java
  - JavaParser-based wrapper instantiation detection via ObjectCreationExpr AST nodes
  - WrapperUsage entry creation with filePath, methodName, lineNumber, wrapperType, needsRuntimeCheck=true
  - Performance optimization for large codebases (1000+ Java files)
  - Filtering logic excluding test files and generated code
  - False positive prevention for non-wrapper object creations
- **Guidance:** MyBatis-Plus QueryWrapper provides fluent API for dynamic query construction making static SQL extraction impossible (conditions determined at runtime). Static scanner's role is only to mark usage locations, signaling runtime interceptor (Task 4.2) must validate actual SQL execution. Design 6.5 specifies "只标记使用位置" (only mark usage locations) - deliberately avoiding complex condition analysis. WrapperUsage.needsRuntimeCheck flag indicates these locations require runtime validation layer. Scanner must handle large codebases efficiently (stream-based processing, parallel parsing if needed) while avoiding false positives (verify wrapper types are from MyBatis-Plus com.baomidou.mybatisplus.core.conditions package). Depends on: Task 3.1 Output (WrapperScanner interface and WrapperUsage class).

- **Wrapper Detection TDD:** Write test class `QueryWrapperScannerTest` with test methods: `testQueryWrapperDetection_shouldCreateUsage()` (Java file with `new QueryWrapper<User>()` creates WrapperUsage), `testLambdaQueryWrapperDetection_shouldCreateUsage()` (detect `new LambdaQueryWrapper<>()`), `testUpdateWrapperDetection_shouldCreateUsage()` (detect `new UpdateWrapper<>()`), `testLambdaUpdateWrapperDetection_shouldCreateUsage()` (detect `new LambdaUpdateWrapper<>()`), `testNonWrapperObjectCreation_shouldSkip()` (new ArrayList(), new User() should not create WrapperUsage), `testMultipleWrappersInFile_shouldDetectAll()` (file with 3 wrapper creations creates 3 WrapperUsage). Implement `QueryWrapperScanner` class in `com.footstone.sqlguard.scanner.wrapper` package implementing WrapperScanner interface. Implement `scan(File projectRoot)` method: recursively find all .java files using Files.walk(projectRoot.toPath()).filter(p -> p.toString().endsWith(\".java\") && p.toString().contains(\"src/main/java\")), parse each Java file with JavaParser CompilationUnit cu = StaticJavaParser.parse(file), call cu.findAll(ObjectCreationExpr.class) to find all `new X()` expressions, for each ObjectCreationExpr check if type name matches wrapper patterns using Set<String> wrapperTypes = [\"QueryWrapper\", \"LambdaQueryWrapper\", \"UpdateWrapper\", \"LambdaUpdateWrapper\"], extract enclosing method name using expr.findAncestor(MethodDeclaration.class).map(m -> m.getNameAsString()).orElse(\"unknown\"), get line number from expr.getBegin().get().line, create WrapperUsage(filePath=file.getAbsolutePath(), methodName=enclosingMethod, lineNumber=lineNum, wrapperType=typeName, needsRuntimeCheck=true), collect all WrapperUsage into List, return result.

- **Implementation Details:** Implement wrapper type matching with package verification to prevent false positives: check if ObjectCreationExpr.getType().resolve().getQualifiedName() starts with \"com.baomidou.mybatisplus.core.conditions\" (requires JavaParser symbol resolution). If symbol resolution fails (missing dependencies), fall back to simple type name matching with warning log. Extract enclosing method using AST traversal: expr.findAncestor(MethodDeclaration.class) for method-level wrappers, use class-level \"<init>\" or \"<static>\" for wrappers in constructors/static blocks. Skip detailed condition analysis (per design: no need to extract eq(), like(), orderBy() calls - runtime interceptor handles actual SQL validation). Set needsRuntimeCheck=true for all WrapperUsage entries indicating static analysis insufficient.

- **Performance Testing:** Write performance test `QueryWrapperScannerPerformanceTest` simulating large projects: generate 1000 Java files with varying wrapper usage (some with wrappers, most without), execute scan() and measure execution time (should complete in reasonable time <10 seconds for 1000 files), verify memory usage remains bounded (no memory leaks from JavaParser AST retention), test parallel processing optimization if needed (Stream.parallel() on file list). Write filtering test `ScanFilteringTest`: create directory structure with src/main/java (include), src/test/java (exclude), target/generated-sources (exclude), verify scanner only processes src/main/java files, verify no false positives from test files or generated code. Test false positive prevention: create Java files with non-wrapper object creations (new ArrayList<>(), new HashMap<>(), custom domain objects), verify scanner does not create WrapperUsage for these, verify wrapper type matching is precise (QueryWrapper detected, QueryWrapperTest not detected). Run `mvn test` ensuring wrapper scanner performance and accuracy.

### Task 3.5 – Dynamic SQL Scenario Generator │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 37 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_5_Dynamic_SQL_Variant_Generator.md`

- **Objective:** Implement comprehensive MyBatis dynamic SQL variant generator producing representative SQL execution scenarios for if/foreach/where/choose/when/otherwise tags, enabling static validation of dynamic SQL by generating concrete SQL strings covering different runtime execution paths without combinatorial explosion.
- **Output:**
  - Tag-specific variant generation methods (handleIfTag, handleForeachTag, handleWhereTag, handleChooseWhenTag)
  - If-tag variant generation: 2 scenarios (condition true/false)
  - Foreach-tag variant generation: 3 representative scenarios (empty/single/multiple items)
  - Where-tag variant generation: smart WHERE clause insertion with AND/OR removal
  - Choose-when variant generation: one variant per branch (when branches + otherwise)
  - Nested tag handling with recursive combination generation
  - Variant description annotations ("with condition X", "without condition Y")
  - Comprehensive integration tests with complex nested dynamic SQL patterns
- **Guidance:** Dynamic SQL in MyBatis XML mappers requires variant generation to enable static validation of all possible execution paths. Goal is representative coverage (not exhaustive) - generate enough variants to catch dangerous patterns without exploding variant count. For if tags: 2 variants cover include/exclude scenarios. For foreach: 3 variants (empty/single/multiple) represent typical collection sizes. For choose: one variant per branch ensures all branches validated. Nested tags require recursive handling generating combinations (limit combinatorial growth with max variant count per SQL). Generated variants must be syntactically valid SQL (where tag properly adds WHERE keyword and removes leading AND/OR). This task enhances Task 3.2 XML parser by populating SqlEntry.sqlVariants list. Depends on: Task 3.2 Output (XmlMapperParser and DOM4J Element manipulation).

1. **If-Tag Variant Generation TDD:** Write test class `IfTagVariantGeneratorTest` with test methods: `testSimpleIf_shouldGenerateTwoVariants()` (SQL with <if test=\"id != null\">AND id=#{id}</if> generates variant with condition included and variant with condition excluded), `testMultipleIf_shouldGenerateCombinations()` (SQL with 2 independent if tags generates 4 variants covering all combinations), `testNestedIf_shouldHandleRecursively()` (if inside if generates correct nested variants). Implement `handleIfTag(Element element)` method in variant generator component: detect <if> tags in element tree, for each if tag generate 2 scenarios (include content = condition true, exclude content = condition false), for nested if tags generate combinations recursively, limit total variant count to reasonable number (e.g., max 10 variants per SQL to prevent combinatorial explosion), add meaningful variant descriptions like \"with id condition\", \"without id condition\", return List<String> containing variant SQL strings with if tag content either included or removed.

2. **Foreach-Tag Variant Generation TDD:** Write test class `ForeachTagVariantGeneratorTest` with test methods: `testForeachEmpty_shouldRemoveClause()` (SQL with <foreach collection=\"ids\" item=\"id\" separator=\",\">#{id}</foreach> in WHERE id IN (...) generates variant with entire IN clause removed for empty collection), `testForeachSingle_shouldNoSeparator()` (single item variant: WHERE id IN (?) without separator), `testForeachMultiple_shouldUseSeparator()` (multiple item variant: WHERE id IN (?, ?, ?) with separators). Implement `handleForeachTag(Element element)` method: detect <foreach> tags, extract collection attribute, item attribute, separator attribute, generate 3 representative variants: (1) empty collection - remove entire foreach content and surrounding clause (e.g., remove \"AND id IN ()\" entirely), (2) single item - replace foreach with single item placeholder (no separator), (3) multiple items - replace foreach with 3 item placeholders separated by separator (e.g., \"?, ?, ?\"), use placeholder values for item references (#{item} → ?), add variant descriptions like \"foreach empty\", \"foreach single item\", \"foreach 3 items\".

3. **Where-Tag Variant Generation TDD:** Write test class `WhereTagVariantGeneratorTest` with test methods: `testWhereWithContent_shouldAddWhere()` (SQL with <where>AND id=#{id}</where> generates variant \"WHERE id=#{id}\" with WHERE keyword added and leading AND removed), `testWhereWithoutContent_shouldRemove()` (where tag with all dynamic content excluded generates variant without WHERE clause), `testWhereMultipleConditions_shouldHandleAndOr()` (where tag with multiple AND/OR conditions correctly removes only leading AND/OR, preserves internal ones). Implement `handleWhereTag(Element element)` method: detect <where> tags, generate variants based on dynamic content inside: if content present after processing nested dynamic tags (if/foreach), add WHERE keyword at start, remove leading AND/OR/AND\\s+/OR\\s+ from first condition using regex, preserve internal AND/OR operators, if content completely excluded (all if conditions false), remove entire where tag including WHERE keyword, ensure generated SQL is syntactically valid (no dangling WHERE, no double AND/OR).

4. **Choose-When Variant Generation TDD:** Write test class `ChooseWhenVariantGeneratorTest` with test methods: `testChooseMultipleWhen_shouldGeneratePerBranch()` (SQL with <choose><when test=\"type=1\">...</when><when test=\"type=2\">...</when><otherwise>...</otherwise></choose> generates 3 variants, one per branch), `testChooseNoOtherwise_shouldHandleMissing()` (choose without otherwise generates variant for each when only), `testChooseSingleBranch_shouldIncludeExclusively()` (each variant includes only one branch content, not multiple). Implement `handleChooseWhenTag(Element element)` method: detect <choose> tags, find all <when> child elements and optional <otherwise> element, generate one variant per when branch: include that when's content, exclude all other when and otherwise content, generate additional variant for otherwise branch if present: include otherwise content, exclude all when content, ensure only one branch included per variant (MyBatis switch-case semantics), add variant descriptions like \"choose when type=1\", \"choose otherwise\".

5. **Comprehensive Integration Testing:** Write integration test `DynamicSqlVariantGeneratorIntegrationTest` with complex XML test fixtures: complex-nested.xml (if inside where inside foreach with multiple nesting levels), real-world-mapper.xml (realistic MyBatis mapper with dynamic where, multiple if conditions, foreach in IN clause, choose-when for different query modes), edge-cases.xml (empty where tag, foreach with no items, choose with only otherwise, nested choose). For each test file: parse with enhanced XmlMapperParser including variant generation, verify SqlEntry.sqlVariants list populated correctly, verify variant count reasonable (not exponential explosion), verify all generated variants are syntactically valid SQL (can be parsed by JSqlParser without errors), verify variant descriptions meaningful for debugging, test variant SQL against validation engine to ensure dangerous patterns detected across execution paths. Write performance test: complex dynamic SQL with 5+ nested dynamic tags generates variants in reasonable time (<1 second) without memory explosion. Run `mvn test` ensuring all variant generation tests pass.

### Task 3.6 – Scan Report Generator (Console + HTML) │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 57 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_6_Report_Generator_Implementation.md`

- **Objective:** Implement dual-format report generation system producing actionable scan reports in console (ANSI-colored text for terminal display) and HTML (styled web page with sortable tables) formats, processing ScanReport data structures from Task 3.1 to group violations by severity, format output with file:line references, SQL snippets, violation messages, and suggestions.
- **Output:**
  - ReportProcessor class aggregating and preparing report data structures
  - ConsoleReportGenerator producing ANSI-colored terminal output matching design 6.8 format
  - HtmlReportGenerator producing styled HTML with sortable violation tables
  - Violation grouping by risk level (CRITICAL/HIGH/MEDIUM) with severity sorting
  - Statistics summary (total SQL count, violation counts by level, wrapper usage count)
  - Formatted violation entries with file:line, mapper ID, SQL snippet, message, suggestion
  - Collapsible SQL preview sections and syntax highlighting in HTML
  - Comprehensive tests for formatting accuracy, HTML validity, special character handling
- **Guidance:** Report generation is final step in static scanning workflow, presenting actionable findings to developers. Console format is default for CLI usage providing immediate feedback with ANSI colors (red=CRITICAL, yellow=HIGH, blue=MEDIUM) for visual severity distinction. HTML format enables detailed analysis with sortable tables, collapsible sections, and persistent reports for CI/CD integration or team review. ReportProcessor separates data preparation (grouping, sorting, statistics) from rendering (console vs HTML) following Single Responsibility Principle. Violation entries must include precise file:line references enabling IDE navigation. SQL snippets should be truncated if excessive (max 100 chars in console, expandable in HTML). Follow design 6.8 console format specification. Depends on: Task 3.1 Output (ScanReport data structures).

1. **Report Processing TDD:** Write test class `ReportProcessorTest` with test methods: `testGroupByRiskLevel_shouldGroupCorrectly()` (ScanReport with violations at CRITICAL/HIGH/MEDIUM creates grouped map), `testSortBySeverity_shouldOrderCriticalFirst()` (violations sorted CRITICAL > HIGH > MEDIUM > LOW), `testExtractStatistics_shouldCalculateCorrectly()` (total SQL count, violation count by level, wrapper usage count accurate), `testPrepareFormattedData_shouldCreateRenderStructure()` (prepares data structures optimized for console and HTML renderers). Implement `ReportProcessor` class in `com.footstone.sqlguard.scanner.report` package with method `process(ScanReport report)` returning ProcessedReport: group violations by RiskLevel using Map<RiskLevel, List<ViolationEntry>> where ViolationEntry contains filePath, lineNumber, mapperId, sqlSnippet (truncated to 100 chars), message, suggestion, sort groups by severity (CRITICAL first, LOW last), calculate statistics: int totalSqlCount = report.entries.size(), Map<RiskLevel, Integer> violationCountByLevel, int wrapperUsageCount = report.wrapperUsages.size(), int totalViolations = violationCountByLevel.values().stream().sum(), prepare formatted data structures for renderers.

2. **Console Report Generation TDD:** Write test class `ConsoleReportGeneratorTest` with test methods: `testConsoleOutputFormat_shouldMatchDesign()` (output matches design 6.8 format with header, statistics, grouped violations), `testAnsiColors_shouldApplyCorrectly()` (CRITICAL uses red ANSI code \\033[31m, HIGH uses yellow \\033[33m, MEDIUM uses blue \\033[34m), `testViolationEntry_shouldFormatCorrectly()` (entry format: \"[file:line] mapperId - message\"), `testSqlSnippet_shouldTruncate()` (SQL > 100 chars truncated with \"...\"), `testSummaryStatistics_shouldDisplay()` (header shows total SQL count, violation count by level, wrapper count). Implement `ConsoleReportGenerator` class in scanner.report with method `printToConsole(ScanReport report)` from design 6.8: create formatted text output with ANSI colors for severity levels (define constants: RED = \"\\033[31m\", YELLOW = \"\\033[33m\", BLUE = \"\\033[34m\", RESET = \"\\033[0m\"), print summary statistics header: \"SQL Safety Scan Report\\n====================\\nTotal SQL: X | Violations: Y (CRITICAL: a, HIGH: b, MEDIUM: c) | Wrapper Usages: Z\", for each risk level group in severity order: print section header with color \"\\n[CRITICAL]\" in red, for each violation in group: format entry as \"[filePath:lineNumber] mapperId\\n  SQL: [snippet...]\\n  Message: [message]\\n  Suggestion: [suggestion]\", implement printToConsole() calling System.out.println() for formatted output.

3. **HTML Report Generation TDD:** Write test class `HtmlReportGeneratorTest` with test methods: `testHtmlStructure_shouldBeValid()` (generated HTML parses with HTML parser without errors), `testSortableTable_shouldIncludeColumns()` (table has columns: Risk Level, File, Mapper, Message with sortable headers), `testCollapsibleSqlSections_shouldWork()` (SQL preview sections expandable via JavaScript), `testStatisticsDashboard_shouldDisplay()` (top dashboard shows total counts with visual indicators), `testSpecialCharacters_shouldEscape()` (SQL with <, >, &, quotes properly HTML-escaped), `testEmptyReport_shouldHandleGracefully()` (report with no violations shows \"No violations found\" message). Implement `HtmlReportGenerator` class in scanner.report with method `writeToFile(ScanReport report, Path outputPath)` from design: create HTML structure with <!DOCTYPE html><html><head> including CSS styling for modern table design, color-coded risk levels (red/yellow/blue backgrounds), responsive layout, create statistics dashboard at top with boxes showing: Total SQL Count, Total Violations (with risk level breakdown), Wrapper Usages, generate <table> with sortable columns: Risk Level, File:Line, Mapper ID, Message, SQL Preview (collapsible), Suggestion, use JavaScript for table sorting (include simple sort function), add collapsible SQL sections using <details><summary> HTML5 elements or JavaScript toggle, apply syntax highlighting for SQL (optional, use simple <code> tags with monospace font if full highlighting too complex), escape special characters in SQL using StringEscapeUtils.escapeHtml4() from Apache Commons Text, write generated HTML to outputPath using Files.write().

4. **Comprehensive Testing:** Write integration test `ReportGeneratorIntegrationTest` with sample ScanReport containing: 5 CRITICAL violations, 10 HIGH violations, 3 MEDIUM violations, 50 total SQL entries, 5 wrapper usages, long SQL statements (>200 chars), SQL with special characters (quotes, <script> tags, &), empty report (0 violations). For each test report: generate console output, verify output formatting correct (use regex to validate structure), verify ANSI colors applied (check for color codes in output string), verify statistics accurate, verify violation entries complete. Generate HTML output, parse with JSoup HTML parser to verify valid structure, verify table contains correct row count, verify special characters escaped (no XSS vulnerabilities from SQL injection into HTML), verify CSS styling present, test with large reports (1000+ violations) ensuring HTML file size reasonable and browser-renderable, verify readability and usability (manually inspect generated HTML). Run `mvn test` ensuring all report generation tests pass.

### Task 3.7 – CLI Tool Implementation │ Agent_Static_Scanner

- **Objective:** Implement production-ready command-line interface tool providing user-friendly SQL scanning with argument parsing (picocli), input validation, configuration loading, scan orchestration, dual-format report output, CI/CD integration support via exit codes, and comprehensive error handling for robust deployment in development and continuous integration environments.
- **Output:**
  - SqlScannerCli class with @Command annotation and picocli argument definitions
  - Command-line options: --project-path (required), --config-file (optional), --output-format (html/console), --output-file (HTML path), --fail-on-critical (CI/CD flag), --quiet (suppress output)
  - Input validation with fail-fast error messages for invalid arguments
  - Configuration loading from YAML file or defaults
  - Scan orchestration instantiating all parsers and executing scan
  - Report output in specified format (console stdout or HTML file)
  - CI/CD integration with exit codes (0=success/warnings, 1=critical violations or errors)
  - Progress logging and error handling with meaningful messages
  - Comprehensive tests for argument parsing, validation, orchestration, exit codes
- **Guidance:** CLI tool is primary user interface for static scanning in development workflows and CI/CD pipelines, requiring production-quality error handling and user experience. Picocli provides POSIX-style argument parsing with built-in help generation and validation. Fail-fast validation prevents confusing errors during scan execution. Configuration loading reuses SqlGuardConfig from Phase 1 (Task 1.3) with YAML support. Scan orchestration assembles all components: XmlMapperParser (Task 3.2), AnnotationParser (Task 3.3), QueryWrapperScanner (Task 3.4), report generators (Task 3.6). Exit code conventions: 0 for success or non-critical warnings (allows CI to continue), 1 for critical violations or errors (fails CI build). --quiet flag enables headless CI usage. Follow design 6.6 CLI specification. Depends on: Task 3.1 Output (SqlScanner orchestration), Task 3.6 Output (report generators).

1. **CLI Argument Parsing TDD:** Write test class `SqlScannerCliTest` with test methods: `testRequiredProjectPath_shouldParse()` (args with --project-path=/path parses successfully), `testOptionalConfigFile_shouldParse()` (--config-file=config.yml parsed), `testOutputFormat_shouldParseValues()` (--output-format=html and --output-format=console both valid), `testOutputFile_shouldParse()` (--output-file=report.html parsed), `testFailOnCritical_shouldParseBoolean()` (--fail-on-critical sets boolean flag), `testMissingRequired_shouldFail()` (args without --project-path fails with error), `testInvalidFormat_shouldFail()` (--output-format=xml fails with validation error), `testHelpFlag_shouldDisplayUsage()` (--help displays command usage and exits). Add picocli 4.7.x dependency to sql-scanner-cli module POM. Implement `SqlScannerCli` class in `com.footstone.sqlguard.cli` package with @Command annotation: @Command(name = \"sql-scanner\", description = \"Static SQL safety scanner for MyBatis applications\", mixinStandardHelpOptions = true). Define @Option fields from design 6.6: @Option(names = {\"--project-path\", \"-p\"}, required = true, description = \"Project root directory\") Path projectPath, @Option(names = {\"--config-file\", \"-c\"}, description = \"Configuration file path\") Path configFile, @Option(names = {\"--output-format\", \"-f\"}, defaultValue = \"console\", description = \"Output format: console or html\") String outputFormat, @Option(names = {\"--output-file\", \"-o\"}, description = \"Output file path for HTML format\") Path outputFile, @Option(names = {\"--fail-on-critical\"}, defaultValue = \"false\", description = \"Exit with code 1 if CRITICAL violations found\") boolean failOnCritical, @Option(names = {\"--quiet\", \"-q\"}, defaultValue = \"false\", description = \"Suppress non-error output for CI\") boolean quiet. Implement main(String[] args) method: int exitCode = new CommandLine(new SqlScannerCli()).execute(args); System.exit(exitCode).

2. **Input Validation TDD:** Write test class `InputValidationTest` with test methods: `testProjectPathNotExists_shouldFail()` (non-existent path fails with clear message), `testProjectPathNotDirectory_shouldFail()` (file instead of directory fails), `testConfigFileNotExists_shouldFail()` (non-existent config file fails), `testOutputFormatInvalid_shouldFail()` (invalid format value fails), `testOutputFileNotWritable_shouldFail()` (read-only output path fails), `testHtmlFormatWithoutOutputFile_shouldFail()` (--output-format=html requires --output-file). Implement validation logic in CLI class or dedicated Validator: annotate projectPath with @Option and add custom validator checking Files.exists(projectPath) && Files.isDirectory(projectPath), throw ParameterException with message \"Project path does not exist or is not a directory: \" + projectPath if validation fails, similarly validate configFile if provided (Files.exists(configFile)), validate outputFormat enum values using @Option(completionCandidates = [\"console\", \"html\"]), validate outputFile path is writable by checking parent directory exists and is writable, add cross-field validation: if outputFormat.equals(\"html\") && outputFile == null, throw ParameterException(\"HTML format requires --output-file\"), provide clear error messages for all validation failures with suggested fixes, implement fail-fast approach (validate all inputs before scanning), exit with code 1 on validation errors.

3. **Scan Orchestration TDD:** Write test class `ScanOrchestrationTest` with test methods: `testScanExecution_shouldLoadConfig()` (loads configuration from file or defaults), `testScanExecution_shouldInstantiateParsers()` (creates XmlMapperParser, AnnotationParser, QueryWrapperScanner), `testScanExecution_shouldExecuteScan()` (calls SqlScanner.scan() and produces ScanReport), `testScanError_shouldHandleGracefully()` (parser exception during scan logs error and exits with code 1), `testProgressLogging_shouldLogSteps()` (unless --quiet, logs \"Scanning project...\", \"Found X SQL statements\", \"Scan complete\"). Implement scan execution in CLI class as @Command Callable<Integer>: load configuration via YamlConfigLoader.loadFromFile(configFile) if configFile provided, else use SqlGuardConfigDefaults.getDefault() from Phase 1 Task 1.3, create ScanContext with projectPath and loaded config, instantiate all parsers: XmlMapperParser xmlParser = new XmlMapperParser(), AnnotationParser annotationParser = new AnnotationParser(), QueryWrapperScanner wrapperScanner = new QueryWrapperScanner(), create SqlRiskEvaluator with config, instantiate SqlScanner scanner = new SqlScanner(xmlParser, annotationParser, wrapperScanner, evaluator), execute ScanReport report = scanner.scan(context), handle exceptions gracefully: catch IOException, ParseException, ConfigLoadException during execution, log error message with ex.getMessage(), log stack trace if verbose mode enabled, return exit code 1 on errors, log progress to console using SLF4J logger: log.info(\"Scanning project: {}\", projectPath), log.info(\"Found {} SQL statements\", report.entries.size()), suppress logging if quiet flag set (configure Logback level to ERROR).

4. **Report Output & CI Integration TDD:** Write test class `ReportOutputTest` with test methods: `testConsoleOutput_shouldPrintToStdout()` (--output-format=console prints report to console), `testHtmlOutput_shouldWriteFile()` (--output-format=html writes report to --output-file), `testFailOnCritical_withCritical_shouldExitOne()` (CRITICAL violations + --fail-on-critical returns exit code 1), `testFailOnCritical_withoutCritical_shouldExitZero()` (no CRITICAL violations returns exit code 0 even with HIGH/MEDIUM), `testQuietMode_shouldSuppressOutput()` (--quiet suppresses progress logs, only errors printed), `testExitCodes_shouldMatchCiConvention()` (verify 0=success/warnings, 1=critical/errors). Implement report output and exit codes in CLI: after scan completes, check outputFormat value, if \"console\" call ConsoleReportGenerator.printToConsole(report) from Task 3.6, if \"html\" call HtmlReportGenerator.writeToFile(report, outputFile) from Task 3.6, implement --fail-on-critical logic: extract critical violation count from report statistics, if failOnCritical && criticalCount > 0, log.error(\"{} CRITICAL violations found, failing build\", criticalCount) and return exit code 1, else return exit code 0 (even if HIGH/MEDIUM violations present, allowing CI to continue with warnings), add --quiet flag support: configure Logback programmatically to set root logger level to ERROR when quiet=true, ensuring only error messages printed, verify integration with CI tools: return codes parseable by Jenkins, GitLab CI, GitHub Actions (standard Unix convention: 0=success, non-zero=failure), test with shell: `./sql-scanner --project-path=/path; echo $?` verifies exit code. Run comprehensive tests ensuring all CLI functionality works correctly.

## Phase 4: Runtime Interception System - Agent_Runtime_Interceptor

### Task 4.1 – MyBatis Interceptor Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement production-ready MyBatis plugin intercepting Executor.update and Executor.query methods to validate SQL at runtime after dynamic SQL resolution, extracting final SQL from BoundSql, detecting RowBounds for logical pagination, and enforcing configured violation strategies (BLOCK/WARN/LOG) supporting both MyBatis 3.4.x and 3.5.x versions.
- **Output:**
  - SqlSafetyInterceptor class with @Intercepts annotations targeting Executor methods
  - intercept() method extracting MappedStatement, BoundSql, parameters, and RowBounds
  - SqlContext population with runtime SQL execution context
  - Violation handling implementing BLOCK (throws SQLException), WARN (logs + continues), LOG (logs only) strategies
  - Multi-version compatibility handling MyBatis 3.4.6 and 3.5.13 API differences
  - Integration tests with real SqlSessionFactory validating interception accuracy
  - Thread-safety verification under concurrent SQL execution
- **Guidance:** MyBatis interceptor is first runtime defense layer validating SQL after dynamic tag resolution but before database execution, catching dangerous patterns missed by static analysis (runtime-determined conditions). BoundSql provides final SQL with dynamic tags processed, enabling accurate validation. RowBounds detection is critical for identifying logical pagination (Task 2.7 checker). MapperId from MappedStatement links runtime violations to source code locations. Strategy pattern allows environment-specific enforcement: LOG in dev (observation), WARN in test (alerting), BLOCK in prod (prevention). Multi-version support required due to API changes between MyBatis 3.4.x and 3.5.x (Executor method signatures, parameter handling). Thread-safety essential as interceptor shared across SqlSession instances. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **MyBatis Interceptor TDD:** Write test class `SqlSafetyInterceptorTest` with test methods: `testQueryInterception_shouldValidate()` (SELECT query intercepted before execution), `testUpdateInterception_shouldValidate()` (UPDATE/DELETE intercepted), `testRowBoundsDetection_shouldExtract()` (RowBounds parameter detected for pagination), `testDynamicSqlResolution_shouldGetBoundSql()` (BoundSql contains resolved SQL with dynamic tags processed), `testBLOCKStrategy_shouldThrowException()` (validation failure with BLOCK strategy throws SQLException), `testWARNStrategy_shouldLogAndContinue()` (validation failure with WARN logs error and proceeds), `testLOGStrategy_shouldOnlyLog()` (LOG strategy only logs, no exception). Add MyBatis 3.4.6 and 3.5.13 dependencies to sql-guard-mybatis module POM with profiles for testing both versions. Implement `SqlSafetyInterceptor` class in `com.footstone.sqlguard.interceptor.mybatis` package annotated with @Intercepts targeting Executor methods: @Intercepts({@Signature(type = Executor.class, method = \"update\", args = {MappedStatement.class, Object.class}), @Signature(type = Executor.class, method = \"query\", args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class})}). Implement Interceptor interface with intercept(Invocation invocation) method from design 4.2.

2. **Intercept Method Implementation:** Implement intercept() method extracting execution context: get Invocation.getArgs() array, extract MappedStatement ms = (MappedStatement) args[0], extract parameter Object param = args[1], for query method extract RowBounds rowBounds = (RowBounds) args[2], obtain BoundSql boundSql = ms.getBoundSql(param) to get final SQL after MyBatis dynamic SQL processing, extract SQL string via boundSql.getSql(), extract SqlCommandType from ms.getSqlCommandType(), extract mapperId from ms.getId(), extract parameters from boundSql.getParameterMappings() and boundSql.getParameterObject(), build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).params(extractedParams).rowBounds(rowBounds).build(). Handle MyBatis version differences: use reflection to check BoundSql method availability, provide fallback for API changes between 3.4.x and 3.5.x.

3. **Validation and Strategy Handling:** Inject DefaultSqlSafetyValidator via constructor. Call ValidationResult result = validator.validate(context) after SqlContext creation. Implement strategy pattern: read configured strategy from SqlGuardConfig (injected via constructor or Spring), if result.passed is false execute strategy: BLOCK strategy throws new SQLException(\"SQL Safety Violation: \" + result.getRiskLevel() + \" - \" + formatViolations(result.getViolations()), \"42000\") with SQLState indicating constraint violation, WARN strategy logs log.error(\"SQL Safety Violation (WARN): {}\", formatViolations(result.getViolations())) and proceeds with invocation.proceed(), LOG strategy logs log.warn(\"SQL Safety Violation (LOG): {}\", formatViolations(result.getViolations())) and proceeds. If result.passed is true, proceed normally with invocation.proceed(). Implement formatViolations() helper creating multi-line violation report with risk level, messages, suggestions for logging/exception details.

4. **Multi-Version Compatibility Testing:** Write compatibility test `MyBatisVersionCompatibilityTest` with Maven profiles: mybatis-3.4 profile (MyBatis 3.4.6 dependency), mybatis-3.5 profile (MyBatis 3.5.13 dependency). For each profile: create test SqlSessionFactory with interceptor configured, execute sample SQL with dynamic tags (if conditions, foreach), verify BoundSql extraction works correctly, verify parameter extraction handles differences, test RowBounds detection works in both versions. Use reflection-based API detection to handle incompatible method signatures: detect method availability at runtime, use version-specific code paths, log warnings if deprecated methods used. Run `mvn test -Pmybatis-3.4` and `mvn test -Pmybatis-3.5` ensuring all tests pass on both versions.

5. **Integration and Thread-Safety Testing:** Write integration test `SqlSafetyInterceptorIntegrationTest` with real MyBatis configuration: create H2 in-memory database, create MyBatis mapper XML with sample SQL (including dangerous patterns: no WHERE, dummy conditions), configure SqlSessionFactory with SqlSafetyInterceptor, execute queries and updates via mapper methods, verify interception triggers validation, verify violations detected correctly, test BLOCK strategy prevents execution (SQLException thrown, database unchanged), test WARN/LOG strategies allow execution (database modified, violations logged). Write thread-safety test `InterceptorConcurrencyTest`: execute 100 concurrent SQL operations via SqlSession instances sharing same interceptor instance, verify no race conditions in validator or deduplication cache, verify all violations detected across threads, verify no false positives/negatives under concurrency. Run `mvn test` ensuring all integration and thread-safety tests pass.

### Task 4.2 – MyBatis-Plus InnerInterceptor Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement MyBatis-Plus InnerInterceptor integrating with MyBatis-Plus interceptor chain to validate SQL at runtime, detecting IPage pagination parameters for physical pagination validation, capturing QueryWrapper/LambdaQueryWrapper generated SQL flagged by static scanner, and coordinating with PaginationInnerInterceptor without conflicts.
- **Output:**
  - MpSqlSafetyInnerInterceptor class implementing InnerInterceptor interface
  - beforeQuery() and beforeUpdate() methods intercepting SQL execution
  - IPage parameter detection for MyBatis-Plus pagination validation
  - QueryWrapper SQL capture coordinating with static scanner WrapperUsage markers
  - Integration with PaginationInnerInterceptor ensuring both work together
  - Deduplication preventing double-checking when MyBatis and MyBatis-Plus interceptors both enabled
  - Compatibility with MyBatis-Plus optimistic lock and tenant plugins
  - Integration tests with IPage pagination and QueryWrapper/LambdaQueryWrapper usage
- **Guidance:** MyBatis-Plus InnerInterceptor integrates into MybatisPlusInterceptor chain providing modular interception architecture. IPage parameter detection enables physical pagination validation (Task 2.6 infrastructure) complementing MyBatis RowBounds. QueryWrapper/LambdaQueryWrapper generate SQL dynamically at runtime (static scanner from Task 3.4 only marks usage locations), requiring runtime validation to catch dangerous patterns in fluent API-built queries. Coordination with PaginationInnerInterceptor critical: both must coexist without conflicts (PaginationInnerInterceptor modifies SQL for pagination, SqlSafetyInnerInterceptor validates final SQL). Deduplication filter (Task 2.13) prevents double validation when multiple interceptor layers enabled. Compatibility with MP ecosystem plugins (optimistic lock, multi-tenant) ensures production viability. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **InnerInterceptor TDD:** Write test class `MpSqlSafetyInnerInterceptorTest` with test methods: `testBeforeQuery_shouldValidate()` (beforeQuery() intercepts SELECT execution), `testBeforeUpdate_shouldValidate()` (beforeUpdate() intercepts UPDATE/DELETE), `testIPageDetection_shouldExtract()` (IPage parameter detected from method parameters), `testQueryWrapperSqlCapture_shouldValidate()` (QueryWrapper generated SQL captured and validated), `testLambdaQueryWrapperSqlCapture_shouldValidate()` (LambdaQueryWrapper SQL validated), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work as expected). Add MyBatis-Plus 3.4.0 and 3.5.3 dependencies to sql-guard-mp module POM. Implement `MpSqlSafetyInnerInterceptor` class in `com.footstone.sqlguard.interceptor.mp` package implementing InnerInterceptor interface from MyBatis-Plus (com.baomidou.mybatisplus.extension.plugins.inner.InnerInterceptor). Implement beforeQuery() and beforeUpdate() methods from design 4.3.

2. **beforeQuery/beforeUpdate Implementation:** Implement beforeQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) method: extract SQL from boundSql.getSql(), extract SqlCommandType from ms.getSqlCommandType(), extract mapperId from ms.getId(), extract RowBounds parameter for pagination detection, detect IPage parameter via hasIPageParameter(parameter) helper method: check if parameter instanceof IPage (direct IPage parameter), or if parameter instanceof Map check Map.values() for IPage instances (IPage in parameter map common in MyBatis-Plus), extract IPage details (current page, size) and add to SqlContext, build SqlContext with all extracted information. Implement beforeUpdate(Executor executor, MappedStatement ms, Object parameter) similarly extracting context from UPDATE/DELETE execution. Call validator.validate(context) and handle violations with strategy pattern (same as Task 4.1: BLOCK throws SQLException, WARN/LOG log violations).

3. **IPage and QueryWrapper Detection:** Implement IPage detection helper: `boolean hasIPageParameter(Object parameter)` checking parameter type and Map contents. Implement QueryWrapper SQL capture: MyBatis-Plus generates SQL from QueryWrapper/LambdaQueryWrapper at runtime, BoundSql contains final generated SQL, validate this SQL to catch dangerous fluent API patterns (e.g., empty wrapper equivalent to no WHERE, wrapper with only blacklist fields). No special QueryWrapper detection needed in interceptor - just validate BoundSql SQL like any other query. Static scanner (Task 3.4) already marked QueryWrapper usage locations; runtime interceptor validates actual generated SQL execution. Add wrapper detection to SqlContext for correlation: check if parameter contains QueryWrapper instance, set flag in SqlContext details for debugging/reporting.

4. **Integration with PaginationInnerInterceptor:** Write integration test `MpInterceptorCoordinationTest` with both PaginationInnerInterceptor and MpSqlSafetyInnerInterceptor configured in MybatisPlusInterceptor: create MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(), add PaginationInnerInterceptor first (interceptor.addInnerInterceptor(new PaginationInnerInterceptor())), add MpSqlSafetyInnerInterceptor second (interceptor.addInnerInterceptor(new MpSqlSafetyInnerInterceptor(validator))), configure in SqlSessionFactory. Test scenarios: IPage query with pagination (verify PaginationInnerInterceptor adds LIMIT clause, then MpSqlSafetyInnerInterceptor validates final SQL with LIMIT), dangerous SQL with IPage pagination (verify safety interceptor still detects no WHERE despite LIMIT added), verify both interceptors execute in correct order, verify no SQL double-validation (deduplication filter prevents).

5. **Edge Case and Plugin Compatibility Testing:** Write test `MpPluginCompatibilityTest` ensuring compatibility with MyBatis-Plus ecosystem plugins: test with optimistic lock plugin (OptimisticLockerInnerInterceptor) enabled, verify version field updates intercepted and validated correctly, test with multi-tenant plugin (TenantLineInnerInterceptor) enabled, verify tenant_id injection doesn't interfere with validation, test with illegal SQL plugin (IllegalSQLInnerInterceptor) enabled alongside safety interceptor, verify both plugins coexist without conflicts. Write deduplication test `MyBatisPlusDeduplicationTest`: enable both MyBatis SqlSafetyInterceptor (Task 4.1) and MyBatis-Plus MpSqlSafetyInnerInterceptor simultaneously, execute SQL, verify deduplication filter (Task 2.13) prevents double validation, verify only one validation execution per SQL despite two interceptor layers. Run `mvn test` ensuring all MP integration tests pass.

### Task 4.3 – JDBC Druid Filter Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement Druid connection pool filter intercepting SQL at JDBC layer via FilterAdapter extension, validating PreparedStatement and Statement executions, extracting datasource context from ConnectionProxy, and integrating with Druid's monitoring and filter chain while maintaining minimal performance overhead.
- **Output:**
  - DruidSqlSafetyFilter class extending FilterAdapter from Druid
  - Method overrides: createPreparedStatementProxy(), statement_executeQuery(), statement_executeUpdate()
  - validateSql() method creating SqlContext from JDBC-level information
  - SQL type detection from SQL string prefix (SELECT/UPDATE/DELETE/INSERT)
  - Datasource name extraction from ConnectionProxy for multi-datasource environments
  - Filter registration configuration for DruidDataSource
  - Filter ordering ensuring safety validation runs before StatFilter
  - Integration tests with Druid datasource and connection pooling
  - Compatibility verification with Druid StatFilter, WallFilter, encrypted datasources
- **Guidance:** Druid filter provides JDBC-layer interception catching SQL not passing through MyBatis/MyBatis-Plus layers (direct JDBC usage, JdbcTemplate, other ORM frameworks). FilterAdapter is Druid's filter extension point for custom SQL processing. createPreparedStatementProxy() intercepts PreparedStatement creation capturing SQL at prepare time, statement_executeQuery/Update() intercept Statement executions capturing SQL at execute time. ConnectionProxy provides datasource metadata enabling multi-datasource violation tracking. Filter ordering critical: safety validation must run before StatFilter (Druid's SQL statistics collection) to ensure violations logged with correct context, but after ProtocolFilter (driver communication). Integration with Druid monitoring allows violation metrics in Druid dashboard. Encrypted datasource support ensures compatibility with security-enhanced environments. Performance overhead must be minimal (<5% target) as Druid filters execute on every SQL. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **Druid Filter TDD:** Write test class `DruidSqlSafetyFilterTest` with test methods: `testPreparedStatementInterception_shouldValidate()` (PreparedStatement SQL validated), `testStatementInterception_shouldValidate()` (Statement SQL validated), `testDatasourceExtraction_shouldGetName()` (datasource name extracted from ConnectionProxy), `testSqlTypeDetection_shouldIdentifyCommand()` (SELECT/UPDATE/DELETE/INSERT detected from SQL prefix), `testFilterOrdering_shouldRunBeforeStat()` (safety filter executes before StatFilter in chain), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work). Add Druid 1.2.x dependency to sql-guard-jdbc module POM. Implement `DruidSqlSafetyFilter` class in `com.footstone.sqlguard.interceptor.druid` package extending FilterAdapter from com.alibaba.druid.filter.FilterAdapter. Override createPreparedStatementProxy(), statement_executeQuery(), statement_executeUpdate() methods from design 4.4.1.

2. **validateSql Method Implementation:** Implement `validateSql(String sql, ConnectionProxy connection)` helper method: detect SqlCommandType from SQL prefix using regex matching (\"^\\s*SELECT\" → SELECT, \"^\\s*UPDATE\" → UPDATE, \"^\\s*DELETE\" → DELETE, \"^\\s*INSERT\" → INSERT, case-insensitive), extract datasource name from connection.getDirectDataSource().getName() (Druid ConnectionProxy provides datasource metadata), create mapperId as \"jdbc-druid:\" + datasourceName for JDBC-layer SQL tracking, build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).datasource(datasourceName).build(), call validator.validate(context), handle violations with strategy pattern (BLOCK throws SQLException, WARN/LOG log violations and return). Return result to caller for proceed/block decision.

3. **Filter Method Overrides:** Override `createPreparedStatementProxy(PreparedStatementProxy statement, String sql)` from FilterAdapter: call validateSql(sql, statement.getConnectionProxy()) before creating proxy, if BLOCK strategy and violation detected throw SQLException preventing PreparedStatement creation, otherwise proceed with super.createPreparedStatementProxy(). Override `statement_executeQuery(StatementProxy statement, String sql)` intercepting Statement.executeQuery(): call validateSql(sql, statement.getConnectionProxy()) before execution, handle BLOCK strategy by throwing SQLException, proceed with super.statement_executeQuery() for WARN/LOG. Override `statement_executeUpdate(StatementProxy statement, String sql)` similarly for UPDATE/DELETE/INSERT statements. Note: prepared statement execution (PreparedStatement.execute()) validated at prepare time via createPreparedStatementProxy, so no need to re-validate at execute time (deduplication filter handles this if needed).

4. **Filter Registration and Configuration:** Implement filter registration: create DruidSqlSafetyFilterConfiguration class with method registerFilter(DruidDataSource dataSource): call dataSource.getProxyFilters().add(new DruidSqlSafetyFilter(validator)) adding filter to chain, set filter order via filter.setOrder() ensuring execution before StatFilter (Druid's default filter order: ProtocolFilter=1, StatFilter=2, safety filter should be order=2 or earlier), configure filter in Spring Boot via @Bean method returning DruidSqlSafetyFilter with @Order annotation. Write configuration test `FilterRegistrationTest`: create DruidDataSource, register filter, verify filter added to proxy filters list, verify filter order correct, verify filter executes in chain during SQL execution.

5. **Druid Integration and Performance Testing:** Write integration test `DruidIntegrationTest` with real Druid datasource: create DruidDataSource with H2 database, configure DruidSqlSafetyFilter, execute SQL via JDBC Connection.prepareStatement() and Statement.execute(), verify filter intercepts both PreparedStatement and Statement, verify violations detected and strategy applied, test connection pooling: execute SQL from multiple borrowed connections, verify filter works across pool lifecycle (connection borrow/return), verify no memory leaks or filter state corruption. Write compatibility test `DruidPluginCompatibilityTest`: configure StatFilter + WallFilter + DruidSqlSafetyFilter together, verify all filters coexist without conflicts, verify StatFilter statistics include safety violations, test with encrypted datasource (Druid's ConfigFilter for password decryption), verify filter works with encryption enabled. Write performance test `DruidFilterPerformanceTest`: measure overhead with JMH micro-benchmark, execute 10000 SQL statements with and without filter enabled, calculate overhead percentage, verify <5% target, test under concurrent load (100 threads executing SQL), verify performance degradation acceptable. Run `mvn test` ensuring all Druid tests pass.

### Task 4.4 – JDBC HikariCP Proxy Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement HikariCP ProxyFactory providing Connection dynamic proxy for SQL interception at JDBC layer, capturing PreparedStatement and Statement SQL via nested invocation handlers, validating before actual statement creation/execution, and integrating seamlessly with HikariCP's high-performance connection pooling without disrupting leak detection or pool lifecycle.
- **Output:**
  - HikariSqlSafetyProxyFactory class implementing ProxyFactory interface
  - getProxyConnection() method returning dynamic proxy for Connection
  - ConnectionInvocationHandler intercepting prepareStatement(), prepareCall(), createStatement()
  - StatementInvocationHandler intercepting execute(), executeQuery(), executeUpdate()
  - SQL validation before PreparedStatement/Statement creation and execution
  - HikariConfig integration via setProxyFactory() configuration
  - Proxy compatibility with HikariCP connection leak detection
  - Integration tests with HikariDataSource, batch operations, performance verification
- **Guidance:** HikariCP provides ProxyFactory interface for custom connection proxying enabling SQL interception without filter API (unlike Druid). Dynamic proxy pattern (JDK Proxy or Javassist) wraps Connection objects returned from pool, intercepting method calls. ConnectionInvocationHandler intercepts prepareStatement(sql) capturing SQL at prepare time, createStatement() requiring nested Statement proxy for execute(sql) capture. StatementInvocationHandler wraps PreparedStatement/Statement intercepting actual execution methods. Two-layer proxying required: Connection proxy intercepts statement creation, Statement proxy intercepts execution. HikariCP's leak detection tracks connection usage via ProxyConnection wrapper - custom proxy must preserve this tracking (delegate close() correctly). Batch operations require special handling (addBatch() + executeBatch() pattern). Performance critical as HikariCP targets microsecond-level connection overhead - proxy must add minimal latency. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **ProxyFactory TDD:** Write test class `HikariSqlSafetyProxyFactoryTest` with test methods: `testGetProxyConnection_shouldReturnProxy()` (getProxyConnection() returns dynamic proxy), `testPrepareStatementInterception_shouldValidate()` (Connection.prepareStatement(sql) triggers validation), `testCreateStatementInterception_shouldProxyStatement()` (Connection.createStatement() returns proxied Statement), `testStatementExecuteInterception_shouldValidate()` (Statement.execute(sql) triggers validation), `testProxyDelegation_shouldPreserveConnectionBehavior()` (proxy delegates to real connection correctly), `testLeakDetection_shouldNotBreak()` (HikariCP leak detection works with proxy). Add HikariCP 5.x dependency to sql-guard-jdbc module POM. Implement `HikariSqlSafetyProxyFactory` class in `com.footstone.sqlguard.interceptor.hikari` package implementing ProxyFactory interface from com.zaxxer.hikari.pool.ProxyFactory. Implement getProxyConnection(String delegateClassName, Connection connection) method from design 4.4.2.

2. **ConnectionInvocationHandler Implementation:** Implement `ConnectionInvocationHandler` inner class implementing InvocationHandler: store real Connection delegate and SqlSafetyValidator reference, implement invoke(Object proxy, Method method, Object[] args): intercept prepareStatement(String sql) and prepareCall(String sql) methods checking method name, extract SQL from args[0], call validateSql(sql, delegate) helper validating SQL and applying strategy (BLOCK throws SQLException, WARN/LOG proceed), if validation passes create actual PreparedStatement via delegate.prepareStatement(sql), wrap PreparedStatement in StatementInvocationHandler proxy, return proxied PreparedStatement. Intercept createStatement() similarly: no SQL at creation time, return Statement wrapped in proxy for execute(sql) capture. Delegate all other Connection methods to real connection: return method.invoke(delegate, args) for non-intercepted methods. Handle close() correctly: delegate.close() to preserve HikariCP connection return to pool and leak detection.

3. **StatementInvocationHandler Implementation:** Implement `StatementInvocationHandler` inner class for PreparedStatement/Statement proxying: store real Statement/PreparedStatement delegate and Connection reference (for datasource context), implement invoke(Object proxy, Method method, Object[] args): intercept execute(String sql), executeQuery(String sql), executeUpdate(String sql) methods for Statement (SQL passed as parameter), extract SQL from args[0], validate before execution, proceed with delegate.execute(sql) if validation passes. For PreparedStatement intercept execute(), executeQuery(), executeUpdate() with no SQL parameter (SQL already validated at prepareStatement time), just delegate without re-validation (deduplication filter handles this). Handle batch operations: intercept addBatch(String sql) for Statement (validate each batch SQL), intercept addBatch() for PreparedStatement (no SQL parameter, already validated), intercept executeBatch() (delegate directly, individual SQLs already validated).

4. **HikariCP Configuration and Integration:** Implement HikariConfig integration: create configuration method configureHikariCPSafety(HikariConfig config, SqlSafetyValidator validator): call config.setProxyFactory(new HikariSqlSafetyProxyFactory(validator)) registering custom proxy factory, HikariCP will use this factory for all connection proxying. Write configuration test `HikariConfigurationTest`: create HikariConfig, set ProxyFactory, create HikariDataSource, verify connections returned from pool are proxied, verify prepareStatement() interception works, verify createStatement() returns proxied Statement. Write integration test `HikariIntegrationTest` with real HikariDataSource: execute SQL via prepareStatement() and Statement, verify validation triggers, test batch operations (PreparedStatement.addBatch() + executeBatch()), verify leak detection works (intentionally leak connection, verify HikariCP detects leak despite proxy).

5. **Performance and Edge Case Testing:** Write performance test `HikariProxyPerformanceTest`: measure connection acquisition overhead with and without proxy using JMH, execute getConnection() 100000 times, verify overhead <1% (HikariCP targets microsecond latency, proxy must not degrade significantly), measure SQL execution overhead (prepareStatement + execute 10000 times), verify <5% total overhead. Write edge case test `HikariEdgeCasesTest`: test Connection.close() called multiple times (idempotent), test PreparedStatement reuse (prepare once, execute multiple times with different parameters), verify parameter binding doesn't trigger re-validation, test CallableStatement (stored procedure calls), verify intercepts and validates procedure SQL, test with HikariCP metrics enabled, verify proxy doesn't interfere with connection pool metrics. Run `mvn test` ensuring all HikariCP proxy tests pass.

### Task 4.5 – JDBC P6Spy Listener Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement universal JDBC interception via P6Spy proxy driver providing fallback SQL validation for any JDBC-compliant connection pool (C3P0, DBCP, Tomcat JDBC) or direct JDBC usage, leveraging P6Spy's JdbcEventListener for onBeforeAnyExecute callback with parameter-substituted SQL, configuring via spy.properties module registration, and documenting as framework-agnostic solution with acceptable performance trade-offs.
- **Output:**
  - P6SpySqlSafetyListener class extending JdbcEventListener
  - onBeforeAnyExecute() method intercepting all SQL executions
  - SQL extraction from StatementInformation.getSqlWithValues() with parameter substitution
  - P6SpySqlSafetyModule for listener registration via SPI
  - spy.properties configuration file registering custom module
  - SqlSafetyValidator initialization via service loader or static factory
  - Integration tests with P6Spy-wrapped datasources and multiple JDBC drivers
  - Compatibility verification with C3P0, DBCP, Tomcat JDBC, raw JDBC
  - Performance impact documentation and overhead measurement
  - Setup guide for P6Spy deployment in production
- **Guidance:** P6Spy provides universal JDBC interception by implementing JDBC Driver interface as proxy driver, wrapping any underlying driver (MySQL, PostgreSQL, Oracle, H2). All JDBC calls pass through P6Spy's JdbcEventListener callbacks regardless of connection pool or ORM framework, making it ideal fallback when pool-specific solutions (Druid filter, HikariCP proxy) unavailable. StatementInformation.getSqlWithValues() provides SQL with actual parameter values substituted (unlike BoundSql with placeholders), useful for validation but with SQL injection risk in logs (sanitize for logging). Module registration via SPI (META-INF/services) allows P6Spy to discover and load custom listener. Performance overhead higher than native solutions (proxy driver adds layer, parameter substitution processing) but acceptable for safety-critical environments - document trade-offs. Setup complexity lower than native integration (just swap driver class and add spy.properties) making it attractive for quick deployment. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **P6Spy Listener TDD:** Write test class `P6SpySqlSafetyListenerTest` with test methods: `testOnBeforeAnyExecute_shouldValidate()` (onBeforeAnyExecute callback triggers validation), `testSqlWithValuesExtraction_shouldGetSubstituted()` (StatementInformation provides parameter-substituted SQL), `testPreparedStatementExecution_shouldIntercept()` (PreparedStatement.execute() intercepted), `testStatementExecution_shouldIntercept()` (Statement.execute() intercepted), `testBatchExecution_shouldIntercept()` (executeBatch() intercepted), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work). Add P6Spy 3.9.x dependency to sql-guard-jdbc module POM. Implement `P6SpySqlSafetyListener` class in `com.footstone.sqlguard.interceptor.p6spy` package extending JdbcEventListener from com.p6spy.engine.event.JdbcEventListener. Implement onBeforeAnyExecute(StatementInformation statementInformation) method from design 4.4.3.

2. **onBeforeAnyExecute Implementation:** Implement callback method: extract SQL via String sql = statementInformation.getSqlWithValues() (P6Spy provides SQL with parameters substituted like \"SELECT * FROM user WHERE id=123\"), detect SqlCommandType from SQL prefix (same as Task 4.3: regex matching SELECT/UPDATE/DELETE/INSERT), create mapperId as \"jdbc-p6spy\" + optional datasource identifier if available from connection metadata, build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).build(), call validator.validate(context), handle violations with strategy pattern (BLOCK throws SQLException preventing execution, WARN/LOG log and proceed). Note: P6Spy wraps exceptions - SQLException thrown in listener propagates to caller correctly halting execution.

3. **Module Registration and Configuration:** Implement `P6SpySqlSafetyModule` class extending JdbcEventListener in same package: override constructor calling super() to register listener, implement static initialization acquiring SqlSafetyValidator instance (use ServiceLoader, Spring ApplicationContext lookup, or static factory pattern), store validator reference for listener usage. Create spy.properties file in src/main/resources with content: modulelist=com.footstone.sqlguard.interceptor.p6spy.P6SpySqlSafetyModule (P6Spy loads modules listed here via reflection), optionally add appender=com.p6spy.engine.spy.appender.Slf4JLogger for SLF4J integration, configure driverlist with actual JDBC drivers (e.g., driverlist=com.mysql.cj.jdbc.Driver for MySQL), document URL modification (jdbc:mysql:// → jdbc:p6spy:mysql://) and driver class change (com.mysql.cj.jdbc.Driver → com.p6spy.engine.spy.P6SpyDriver) required for P6Spy activation.

4. **Integration and Compatibility Testing:** Write integration test `P6SpyIntegrationTest` with multiple datasource types: test with bare JDBC (DriverManager.getConnection(\"jdbc:p6spy:h2:mem:test\")), verify SQL intercepted, test with C3P0 (ComboPooledDataSource with P6Spy driver configured), verify connection pooling works with P6Spy, test with DBCP (BasicDataSource with P6Spy), verify compatibility, test with Tomcat JDBC Pool (DataSource with P6Spy), verify interception works. Write multi-driver test `P6SpyMultiDriverTest`: configure P6Spy with MySQL driver (mysql-connector-java dependency), execute SQL, verify interception, configure with PostgreSQL driver (postgresql dependency), execute SQL, verify interception, configure with H2 (in-memory for testing), verify works. All tests should verify: SQL validation executes, violations detected correctly, BLOCK strategy prevents execution, WARN/LOG strategies allow execution.

5. **Performance Documentation and Setup Guide:** Write performance test `P6SpyPerformanceTest` measuring overhead: execute 10000 SQL statements with P6Spy enabled vs raw JDBC, calculate overhead percentage, document findings (expected 10-20% overhead due to proxy driver layer and parameter substitution), compare to native solutions (Druid ~5%, HikariCP ~3%, P6Spy ~15%), note overhead acceptable for safety-critical scenarios but recommend native solutions for performance-sensitive applications. Create setup guide documentation in docs/integration/p6spy-setup.md: document driver class change (original driver → com.p6spy.engine.spy.P6SpyDriver), document URL modification (jdbc:mysql:// → jdbc:p6spy:mysql://), provide spy.properties template with SqlSafetyModule configuration, document deployment scenarios: quick deployment without code changes (just configuration), fallback for unsupported connection pools (C3P0, DBCP when no native integration available), legacy application integration (minimal code impact). Test guide accuracy by following steps exactly on sample project. Run `mvn test` ensuring all P6Spy integration tests pass.

## Phase 5: Build Tool Plugins - Agent_Build_Tools

### Task 5.1 – Maven Plugin Implementation │ Agent_Build_Tools

- **Objective:** Implement production-ready Maven plugin wrapping static scanner as build lifecycle integration, providing Maven-native SQL safety scanning with goal execution, parameter injection from POM configuration, CI/CD failure control via failOnCritical flag, and seamless integration with Maven site generation for report publishing.
- **Output:**
  - SqlScannerMojo class extending AbstractMojo with @Mojo annotation
  - Maven @Parameter fields for configuration (projectPath, configFile, outputFormat, outputFile, failOnCritical)
  - execute() method delegating to SqlScanner core with Maven context integration
  - MojoFailureException throwing for CRITICAL violations in CI/CD pipelines
  - Plugin metadata (plugin.xml descriptor) with lifecycle binding to verify phase
  - Integration tests using maven-plugin-testing-harness validating plugin execution
  - User documentation with POM configuration examples and maven-site-plugin integration
- **Guidance:** Maven plugin provides declarative build integration enabling SQL safety scanning as standard verification step in Maven lifecycle. AbstractMojo provides Maven plugin framework with parameter injection, logging, and execution context. @Mojo annotation declares plugin goal (name="scan") and default lifecycle binding (defaultPhase = LifecyclePhase.VERIFY runs during `mvn verify`). @Parameter injection from POM <configuration> section enables project-specific settings without command-line arguments. MojoFailureException with failOnCritical flag allows CI/CD control: fail build on CRITICAL violations, continue on warnings. SqlScanner reuse from Task 3.7 avoids code duplication - plugin is thin wrapper providing Maven integration. maven-plugin-testing-harness enables plugin testing with mock MavenProject and parameter injection. Plugin metadata generation via maven-plugin-plugin creates descriptor for Maven discovery. Depends on: Task 3.7 Output (SqlScanner core implementation and CLI).

1. **Maven Mojo TDD:** Write test class `SqlScannerMojoTest` with test methods: `testExecute_shouldRunScan()` (execute() triggers scanner), `testProjectPathInjection_shouldUseBasedir()` (projectPath defaults to ${project.basedir}), `testConfigFileParameter_shouldLoad()` (configFile parameter loads YAML), `testOutputFormat_shouldRespect()` (outputFormat=html generates HTML), `testFailOnCritical_shouldThrowException()` (CRITICAL violations + failOnCritical=true throws MojoFailureException), `testFailOnCritical_false_shouldNotThrow()` (failOnCritical=false continues despite violations). Add maven-plugin-api and maven-plugin-annotations dependencies to sql-scanner-maven module POM. Implement `SqlScannerMojo` class in `com.footstone.sqlguard.maven` package extending AbstractMojo from org.apache.maven.plugin.AbstractMojo. Add @Mojo annotation: @Mojo(name = "scan", defaultPhase = LifecyclePhase.VERIFY, threadSafe = true). Define @Parameter fields from design 6.7: @Parameter(defaultValue = "${project.basedir}", readonly = true, required = true) File projectPath, @Parameter(property = "sqlguard.configFile") File configFile, @Parameter(property = "sqlguard.outputFormat", defaultValue = "console") String outputFormat, @Parameter(property = "sqlguard.outputFile") File outputFile, @Parameter(property = "sqlguard.failOnCritical", defaultValue = "false") boolean failOnCritical, @Parameter(defaultValue = "${project}", readonly = true, required = true) MavenProject project.

2. **execute() Method Implementation:** Implement execute() method delegating to SqlScanner core: validate parameters (projectPath exists and is directory, configFile exists if provided, outputFormat valid enum), log scan start via getLog().info("Scanning project: " + projectPath), load configuration via YamlConfigLoader or use defaults (reuse Task 1.3 logic), create ScanContext with projectPath and config, instantiate SqlScanner with all parsers (XmlMapperParser, AnnotationParser, QueryWrapperScanner from Task 3.1), execute ScanReport report = scanner.scan(context), handle exceptions: catch IOException, ParseException wrapping in MojoExecutionException with descriptive message, log scan results via getLog().info("Found " + report.getTotalSqlCount() + " SQL statements"). Generate output: if outputFormat equals "console" call ConsoleReportGenerator.printToConsole(report), if "html" call HtmlReportGenerator.writeToFile(report, outputFile), handle failOnCritical: extract critical violation count from report statistics, if failOnCritical && criticalCount > 0 throw new MojoFailureException("SQL Safety Scan failed: " + criticalCount + " CRITICAL violations found"), otherwise complete successfully allowing build to continue.

3. **Plugin Metadata Configuration:** Configure maven-plugin-plugin in sql-scanner-maven POM to generate plugin descriptor: add maven-plugin-plugin version 3.10.2 to <build><plugins>, configure goalPrefix as "sqlguard" enabling `mvn sqlguard:scan` invocation, plugin descriptor META-INF/maven/plugin.xml generated automatically from @Mojo and @Parameter annotations during package phase. Document plugin goals and parameters: create src/site/apt/usage.apt.vm documenting goal name, parameters (projectPath, configFile, outputFormat, outputFile, failOnCritical), default values, examples. Configure default phase binding: @Mojo defaultPhase = LifecyclePhase.VERIFY binds to verify phase, executes during `mvn verify` without explicit goal invocation. Test plugin descriptor generation: run `mvn clean package`, verify target/classes/META-INF/maven/plugin.xml created with correct goal and parameter metadata.

4. **Integration Testing:** Write integration test using maven-plugin-testing-harness: add maven-plugin-testing-harness dependency (test scope), create test class `SqlScannerMojoIntegrationTest` extending AbstractMojoTestCase. Implement test methods: create test project POM in src/test/resources/test-project/pom.xml with plugin configuration, use lookupMojo("scan", testPom) to instantiate mojo with parameter injection, set additional parameters programmatically if needed, call mojo.execute() and verify scan executes, verify output generated (check console output or HTML file existence), test failOnCritical behavior: configure dangerous SQL in test project, enable failOnCritical, verify MojoFailureException thrown, test parameter injection: verify projectPath from POM, verify configFile loaded, verify outputFormat respected. Create test SQL files in test project: sample MyBatis XMLs with violations, verify scanner detects them. Run `mvn test` ensuring integration tests pass.

5. **User Documentation and Publishing:** Create user documentation in README.md: document plugin usage with example POM configuration showing <plugin> section with groupId com.footstone, artifactId sql-scanner-maven-plugin, version ${project.version}, <configuration> with all parameters, <executions> binding to verify phase. Provide multiple configuration examples: basic usage (defaults), custom config file, HTML output, failOnCritical for CI/CD. Document maven-site-plugin integration: configure maven-site-plugin to include SQL scan report in project site, add <reporting><plugins> section with sql-scanner-maven-plugin, generate site with `mvn site`, verify report appears in project reports. Test plugin on real Maven project: apply plugin to sample project, run `mvn verify`, verify scan executes during build, verify violations detected, verify failOnCritical controls build success/failure. Document command-line property overrides: `mvn sqlguard:scan -Dsqlguard.failOnCritical=true` for ad-hoc execution.

### Task 5.2 – Gradle Plugin Implementation │ Agent_Build_Tools

- **Objective:** Implement production-ready Gradle plugin providing SQL safety scanning as Gradle task with DSL configuration, task input/output caching for incremental builds, multi-version Gradle compatibility (6.x/7.x/8.x), and publication to Gradle Plugin Portal for community distribution.
- **Output:**
  - SqlScannerPlugin class implementing Plugin<Project> from Gradle API
  - SqlScannerExtension DSL class for configuration block (sqlScanner { ... })
  - SqlScannerTask extending DefaultTask with @TaskAction scanning execution
  - Task inputs/outputs configuration for Gradle caching and UP-TO-DATE detection
  - failOnCritical flag throwing GradleException for CI/CD integration
  - Integration tests using Gradle TestKit with multi-version compatibility
  - Plugin publishing configuration for Gradle Plugin Portal (plugin id: com.footstone.sqlguard.scanner)
  - User documentation with Groovy and Kotlin DSL examples
- **Guidance:** Gradle plugin provides imperative and declarative build integration with Gradle's rich task system. Plugin<Project> interface provides apply() entry point for plugin registration. Extension object (SqlScannerExtension) provides type-safe DSL configuration via Gradle's extension mechanism (project.extensions.create). Task (SqlScannerTask) implements scanning logic with @TaskAction annotation triggering execution. Input/output configuration critical for Gradle's incremental build: @InputDirectory for projectPath, @InputFile for configFile, @OutputFile for HTML report enables caching and UP-TO-DATE detection across builds. GradleException with failOnCritical matches Maven's MojoFailureException semantics. Gradle TestKit provides functional testing running actual Gradle builds with plugin applied. Multi-version testing ensures compatibility across Gradle 6.x (minimum supported), 7.x (current), 8.x (latest). Plugin Portal publication enables `plugins { id 'com.footstone.sqlguard.scanner' }` usage. Depends on: Task 3.7 Output (SqlScanner core).

1. **Gradle Plugin TDD:** Write test class `SqlScannerPluginTest` with test methods: `testApply_shouldRegisterExtension()` (plugin apply registers sqlScanner extension), `testApply_shouldCreateTask()` (plugin creates sqlScan task), `testExtensionDefaults_shouldSetCorrectly()` (extension default values match design), `testTaskExecution_shouldRunScan()` (task executes scanner), `testTaskCaching_shouldDetectUpToDate()` (unchanged inputs result in UP-TO-DATE), `testFailOnCritical_shouldThrowException()` (CRITICAL violations + failOnCritical=true throws GradleException). Add Gradle API dependency (compileOnly scope, provided by Gradle runtime) to sql-scanner-gradle module. Implement `SqlScannerPlugin` class in `com.footstone.sqlguard.gradle` package implementing Plugin<Project> from org.gradle.api.Plugin. Implement apply(Project project) method creating extension and task.

2. **Plugin apply() Method:** Implement apply(Project project): create extension via SqlScannerExtension extension = project.getExtensions().create("sqlScanner", SqlScannerExtension.class, project) providing DSL configuration block, create task via TaskProvider<SqlScannerTask> scanTask = project.getTasks().register("sqlScan", SqlScannerTask.class, task -> { task.setGroup("verification"); task.setDescription("Scans SQL for safety violations"); }) registering task lazily for configuration avoidance, wire extension to task: task.getProjectPath().convention(extension.getProjectPath()), task.getConfigFile().convention(extension.getConfigFile()), task.getOutputFormat().convention(extension.getOutputFormat()), etc., configure task dependencies: task depends on compileJava if Java plugin applied (ensures compiled code scanned), task added to check task dependencies for automatic execution during `gradle check`.

3. **Extension and Task Implementation:** Implement `SqlScannerExtension` class with Gradle properties: Property<File> projectPath = project.getObjects().property(File.class).convention(project.getProjectDir()), Property<File> configFile, Property<String> outputFormat.convention("console"), Property<File> outputFile, Property<Boolean> failOnCritical.convention(false). Implement `SqlScannerTask` extending DefaultTask: declare @InputDirectory Property<File> projectPath, @InputFile @Optional Property<File> configFile, @Input Property<String> outputFormat, @OutputFile @Optional Property<File> outputFile (only if HTML format), @Input Property<Boolean> failOnCritical. Implement @TaskAction void scan() method delegating to SqlScanner: validate inputs, load configuration, execute scan (reuse Task 3.7 logic), generate output based on format, handle failOnCritical: if failOnCritical.get() && criticalCount > 0 throw new GradleException("SQL Safety Scan failed: " + criticalCount + " CRITICAL violations"), log results via project.getLogger().lifecycle().

4. **TestKit Integration Testing:** Write integration tests using Gradle TestKit: add gradleTestKit() dependency to sql-scanner-gradle POM testImplementation. Create test class `SqlScannerPluginFunctionalTest`: implement test method testPluginExecution() creating temporary test project directory, writing build.gradle with plugin applied and sqlScanner configuration, writing test SQL files with violations, executing task via GradleRunner runner = GradleRunner.create().withProjectDir(testProjectDir).withPluginClasspath().withArguments("sqlScan").build(), verifying task SUCCESS, verifying output generated. Test caching: execute task twice with same inputs, verify second execution shows UP-TO-DATE, modify SQL file, verify task re-executes. Test failOnCritical: configure critical violations, enable failOnCritical, verify build fails with GradleException. Test multi-version compatibility: run tests against Gradle 6.9, 7.6, 8.5 using GradleRunner.withGradleVersion(), verify plugin works on all versions. Write Kotlin DSL test: create build.gradle.kts with type-safe configuration, verify plugin works with Kotlin DSL syntax. Run `gradle test functionalTest` ensuring all tests pass.

5. **Plugin Portal Publishing:** Configure plugin publishing for Gradle Plugin Portal: add java-gradle-plugin to build.gradle, configure gradlePlugin block: gradlePlugin { plugins { sqlScanner { id = 'com.footstone.sqlguard.scanner', implementationClass = 'com.footstone.sqlguard.gradle.SqlScannerPlugin', displayName = 'SQL Safety Guard Scanner', description = 'Static SQL safety scanner for MyBatis applications' } } }, add plugin-publish plugin for portal publication, configure publishPlugins task with portal credentials. Create plugin marker artifact automatically via java-gradle-plugin. Document plugin usage in README: provide Groovy DSL example (plugins { id 'com.footstone.sqlguard.scanner' version '1.0.0' }), provide Kotlin DSL example (plugins { id("com.footstone.sqlguard.scanner") version "1.0.0" }), document sqlScanner extension configuration block with all properties, document task invocation (`gradle sqlScan` explicit, `gradle check` implicit), provide complete working examples for both DSLs. Test plugin installation from portal (or local plugin repository for testing): apply plugin by id, verify auto-resolution works, verify configuration DSL works. Run `gradle publishPlugins` for portal publication.

## Phase 6: Spring Boot Integration - Agent_Spring_Integration

### Task 6.1 – Auto-Configuration Class Implementation │ Agent_Spring_Integration

- **Objective:** Implement Spring Boot auto-configuration providing zero-configuration SQL safety integration with automatic bean creation, conditional component activation, interceptor registration across MyBatis/MyBatis-Plus/JDBC layers, and seamless Spring Boot ecosystem integration following auto-configuration best practices.
- **Output:**
  - SqlGuardAutoConfiguration class with @Configuration and conditional annotations
  - @Bean methods for JSqlParserFacade, all RuleChecker implementations, DefaultSqlSafetyValidator
  - @ConditionalOnClass guards ensuring beans created only when dependencies present
  - @ConditionalOnMissingBean allowing user overrides of default beans
  - BeanPostProcessor for MyBatis SqlSessionFactory interceptor injection
  - MybatisPlusInterceptor configuration for MyBatis-Plus integration
  - Datasource-specific JDBC interceptor configuration (Druid/HikariCP/P6Spy)
  - META-INF/spring.factories registration for auto-discovery
  - Comprehensive auto-configuration tests with @SpringBootTest validation
- **Guidance:** Spring Boot auto-configuration enables "just add starter" zero-configuration experience. @Configuration + META-INF/spring.factories registration makes SqlGuardAutoConfiguration discoverable by Spring Boot's auto-configuration scanning. @ConditionalOnClass ensures beans only created when required dependencies (MyBatis, MyBatis-Plus, Druid, etc.) present on classpath - prevents startup failures in mixed environments. @ConditionalOnMissingBean allows advanced users to override default beans with custom implementations. BeanPostProcessor pattern required for MyBatis SqlSessionFactory post-processing (interceptor must be added after factory creation). @Order controls interceptor sequence in multi-layer scenarios. Configuration should be idempotent and safe - multiple invocations harmless, missing dependencies graceful. Depends on: Task 2.13 (validator), Tasks 4.1-4.5 (all interceptors).

1. **Auto-Configuration TDD:** Write test class `SqlGuardAutoConfigurationTest` with test methods: `testAutoConfigurationLoads_withAllDependencies()` (all beans created when all deps present), `testValidatorBean_shouldCreate()` (DefaultSqlSafetyValidator bean created), `testConditionalOnClass_withoutMyBatis_shouldNotCreateMyBatisInterceptor()` (MyBatis interceptor not created if MyBatis absent), `testConditionalOnMissingBean_withUserBean_shouldNotOverride()` (user-defined validator bean takes precedence), `testInterceptorRegistration_shouldRegisterInCorrectOrder()` (interceptors registered with correct @Order sequence). Add spring-boot-autoconfigure dependency to sql-guard-spring-boot-starter module POM. Implement `SqlGuardAutoConfiguration` class in `com.footstone.sqlguard.spring.autoconfigure` package with @Configuration annotation. Add @ConditionalOnClass(SqlSafetyValidator.class) ensuring auto-configuration only activates when core module present. Add @EnableConfigurationProperties(SqlGuardProperties.class) binding properties (Task 6.2 dependency).

2. **Core Bean Definitions:** Implement core @Bean methods: @Bean @ConditionalOnMissingBean JSqlParserFacade sqlParserFacade() creating facade with default configuration (lenient mode configurable via properties), @Bean @ConditionalOnMissingBean for each RuleChecker implementation (NoWhereClauseChecker, DummyConditionChecker, BlacklistFieldChecker, WhitelistFieldChecker, all pagination checkers from Task 2.2-2.12), pass SqlGuardProperties to each checker constructor for configuration, @Bean @ConditionalOnMissingBean DefaultSqlSafetyValidator sqlSafetyValidator(List<RuleChecker> checkers, JSqlParserFacade facade) creating validator wiring all autowired checkers. Spring automatically collects all RuleChecker beans into list for validator injection. @ConditionalOnMissingBean allows users to replace default implementations: create custom @Bean with same type, auto-configuration defers to user bean.

3. **Interceptor Registration:** Implement interceptor beans with conditional activation: @Bean @ConditionalOnClass(name = "org.apache.ibatis.plugin.Interceptor") SqlSafetyInterceptor myBatisInterceptor(SqlSafetyValidator validator) from Task 4.1, implement BeanPostProcessor registering interceptor: @Bean SqlSessionFactoryBeanPostProcessor(SqlSafetyInterceptor interceptor) creating BeanPostProcessor, override postProcessAfterInitialization checking if bean instanceof SqlSessionFactory, call sqlSessionFactory.getConfiguration().addInterceptor(interceptor), return bean. For MyBatis-Plus: @Bean @ConditionalOnClass(name = "com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor") MpSqlSafetyInnerInterceptor mpInterceptor(SqlSafetyValidator validator) from Task 4.2, implement BeanPostProcessor for MybatisPlusInterceptor injection if exists. For JDBC: @Bean @ConditionalOnClass(name = "com.alibaba.druid.pool.DruidDataSource") DruidSqlSafetyFilter druidFilter(SqlSafetyValidator validator) from Task 4.3, @Bean @ConditionalOnClass(name = "com.zaxxer.hikari.HikariDataSource") HikariSqlSafetyProxyFactory hikariProxyFactory(SqlSafetyValidator validator) from Task 4.4, configure via BeanPostProcessor or direct datasource configuration.

4. **Auto-Configuration Testing:** Write Spring Boot test `SqlGuardAutoConfigurationIntegrationTest` using @SpringBootTest: create test Spring Boot application with sql-guard-spring-boot-starter dependency, configure minimal application.yml, inject SqlSafetyValidator via @Autowired and verify not null, inject all RuleChecker beans via @Autowired List<RuleChecker> and verify expected count, verify interceptors registered: inject SqlSessionFactory and verify interceptor present in configuration.getInterceptors(). Test conditional bean creation: create test with MyBatis excluded from classpath, verify MyBatis interceptor not created (use @ConditionalOnMissingClass test configuration), create test with Druid datasource, verify DruidSqlSafetyFilter created, create test with HikariCP datasource, verify HikariSqlSafetyProxyFactory created. Test user override: define custom @Bean DefaultSqlSafetyValidator in test configuration, verify user bean used instead of auto-configured bean.

5. **Spring Boot Integration:** Create META-INF/spring.factories file in sql-guard-spring-boot-starter/src/main/resources: register org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.footstone.sqlguard.spring.autoconfigure.SqlGuardAutoConfiguration enabling auto-discovery. Test auto-configuration loading: create minimal Spring Boot app with just starter dependency, run SpringApplication.run(), verify auto-configuration loads automatically (check logs for auto-configuration report), verify beans created without manual @Import or @EnableSqlGuard annotation. Test auto-configuration ordering: configure @AutoConfigureAfter(DataSourceAutoConfiguration.class) ensuring SQL guard configures after datasource, configure @AutoConfigureBefore if needed for specific integrations, verify ordering correct via Spring Boot Actuator conditions report endpoint. Run `mvn test` ensuring all auto-configuration tests pass.

### Task 6.2 – Configuration Properties Binding │ Agent_Spring_Integration

- **Objective:** Implement type-safe Spring Boot configuration properties with @ConfigurationProperties binding, JSR-303 validation, nested property support, IDE autocomplete via metadata generation, sensible defaults, and profile-specific configuration enabling declarative YAML-based SQL guard configuration.
- **Output:**
  - SqlGuardProperties class with @ConfigurationProperties(prefix="sql-guard")
  - Nested static classes for all rule configurations matching design 5.1 structure
  - @NestedConfigurationProperty annotations for nested config binding
  - JSR-303 validation annotations (@NotNull, @Min, @Max) with fail-fast validation
  - spring-configuration-metadata.json for IDE autocomplete and documentation
  - Default values matching SqlGuardConfigDefaults from Phase 1 Task 1.3
  - @RefreshScope support for dynamic config updates with Spring Cloud Config
  - Integration with auto-configuration via constructor injection
  - Comprehensive property binding tests with profile-specific configurations
- **Guidance:** @ConfigurationProperties provides type-safe binding from application.yml to Java objects with validation and IDE support. Prefix "sql-guard" maps all sql-guard.* properties to SqlGuardProperties fields. Nested static classes mirror YAML structure: sql-guard.rules.noWhereClause.* → NoWhereClauseProperties. @NestedConfigurationProperty tells Spring Boot to recursively bind nested objects. JSR-303 validation (@Validated + annotations) enforces constraints at startup preventing invalid configurations. spring-configuration-metadata.json generated from Javadoc provides IDE autocomplete showing available properties with descriptions. Sensible defaults from SqlGuardConfigDefaults ensure zero-configuration works out-of-box. Profile-specific configs (application-{profile}.yml) enable environment-specific behavior: dev=LOG, prod=BLOCK. @RefreshScope with Spring Cloud Config enables runtime config reload without restart. Depends on: Task 1.3 (SqlGuardConfigDefaults).

1. **Properties Class TDD:** Write test class `SqlGuardPropertiesTest` with test methods: `testYamlBinding_shouldBindAllProperties()` (YAML properties bind to Java fields), `testNestedProperties_shouldBindRecursively()` (nested configs bind correctly), `testDefaults_shouldMatchDesign()` (default values match design 5.1), `testValidation_withInvalidValues_shouldFail()` (JSR-303 validation catches invalid configs), `testValidation_withValidConfig_shouldPass()` (valid config passes validation). Add spring-boot-configuration-processor dependency (optional, annotation processor) to sql-guard-spring-boot-starter for metadata generation. Implement `SqlGuardProperties` class in com.footstone.sqlguard.spring.config package with @ConfigurationProperties(prefix = "sql-guard") and @Validated annotations. Define root fields: boolean enabled = true, String activeStrategy = "prod", InterceptorsConfig interceptors = new InterceptorsConfig(), DeduplicationConfig deduplication = new DeduplicationConfig(), RulesConfig rules = new RulesConfig().

2. **Nested Configuration Classes:** Implement nested static classes mirroring design 5.1 YAML structure: public static class InterceptorsConfig { @NestedConfigurationProperty MyBatisConfig mybatis = new MyBatisConfig(); @NestedConfigurationProperty MyBatisPlusConfig mybatisPlus = new MyBatisPlusConfig(); @NestedConfigurationProperty JdbcConfig jdbc = new JdbcConfig(); }, public static class MyBatisConfig { boolean enabled = true; }, public static class DeduplicationConfig { boolean enabled = true; @Min(1) int cacheSize = 1000; @Min(1) long ttlMs = 100; }, public static class RulesConfig { @NestedConfigurationProperty NoWhereClauseProperties noWhereClause = new NoWhereClauseProperties(); @NestedConfigurationProperty PaginationAbuseProperties paginationAbuse = new PaginationAbuseProperties(); /* ... all 7 rule properties */ }. Implement rule property classes: public static class NoWhereClauseProperties { boolean enabled = true; RiskLevel riskLevel = RiskLevel.CRITICAL; }, similar for all rules from Tasks 2.2-2.12 with appropriate defaults.

3. **Validation and Metadata:** Add JSR-303 validation: @NotNull on required fields, @Min/@Max on numeric constraints (cacheSize > 0, ttlMs > 0, pagination maxOffset > 0), custom @Constraint for complex validation if needed (e.g., outputFormat must be "console" or "html"). Generate spring-configuration-metadata.json: add comprehensive Javadoc to all properties explaining purpose, valid values, defaults, ensure spring-boot-configuration-processor generates metadata during compilation, verify target/classes/META-INF/spring-configuration-metadata.json created with all properties documented. Test metadata in IDE: create sample application.yml, verify IDE autocomplete shows sql-guard.* properties with descriptions, verify validation warnings for invalid values.

4. **Integration with Auto-Configuration:** Inject SqlGuardProperties into SqlGuardAutoConfiguration via constructor: @EnableConfigurationProperties(SqlGuardProperties.class) on auto-configuration class, inject via constructor parameter: public SqlGuardAutoConfiguration(SqlGuardProperties properties), use properties to configure beans: pass properties.getRules().getNoWhereClause() to NoWhereClauseChecker constructor, pass properties.getActiveStrategy() to interceptor for strategy selection, pass properties.getDeduplication() to validator for deduplication config. Implement @RefreshScope support: annotate DefaultSqlSafetyValidator or config holder bean with @RefreshScope if spring-cloud-context present, add @ConditionalOnClass guard for RefreshScope, implement config reload hook calling validator.reloadConfig(newProperties), test with Spring Cloud Config Server: change config value, trigger /actuator/refresh endpoint, verify validator uses new config without app restart.

5. **Property Binding Tests:** Write comprehensive test `SqlGuardPropertiesBindingTest` with sample YAML configs in src/test/resources: application-test.yml with all properties configured, application-defaults.yml with minimal config testing defaults, application-invalid.yml with invalid values for validation testing. Test scenarios: load application-test.yml via @TestPropertySource, inject SqlGuardProperties, verify all values match YAML, test nested binding (rules.noWhereClause.enabled binds to properties.getRules().getNoWhereClause().isEnabled()), test defaults: load minimal config, verify default values applied, test validation: load invalid config, verify Spring Boot startup fails with BindException or ValidationException, verify error message indicates which property invalid. Test profile-specific configs: create application-dev.yml (activeStrategy=LOG), application-prod.yml (activeStrategy=BLOCK), activate profiles via @ActiveProfiles("dev"), verify correct config loaded. Run `mvn test` ensuring all binding tests pass.

### Task 6.3 – Config Center Extension Points │ Agent_Spring_Integration

- **Objective:** Implement extension point architecture for config center integration enabling hot-reload from Apollo and Nacos configuration centers, providing ConfigCenterAdapter SPI, implementing adapters with @ConditionalOnClass guards, integrating with validator for thread-safe runtime config updates, and documenting extension pattern for custom config center implementations.
- **Output:**
  - ConfigCenterAdapter interface defining config reload contract
  - ConfigChangeEvent class encapsulating changed property information
  - ApolloConfigCenterAdapter with @ApolloConfigChangeListener integration
  - NacosConfigCenterAdapter with @NacosConfigListener integration
  - ConfigReloadSupport in DefaultSqlSafetyValidator for thread-safe reload
  - Cache invalidation on config change (deduplication cache, JSqlParser cache)
  - @ConditionalOnClass guards ensuring adapters only activate when dependencies present
  - Integration tests with embedded/mock config centers
  - Extension point documentation for custom adapter implementation
- **Guidance:** Config center integration enables runtime configuration updates without application restart - critical for production tuning (adjust risk levels, enable/disable rules, change strategies). ConfigCenterAdapter provides uniform interface abstracting Apollo/Nacos differences. @ConditionalOnClass ensures adapters only created when Apollo/Nacos client libraries present - prevents startup failures in environments without config centers. Thread-safe reload essential as config changes occur asynchronously - use AtomicReference or volatile for config holder, synchronize validator state updates. Cache invalidation required to prevent stale validation: deduplication cache from Task 2.13 must be cleared, JSqlParser cache from Task 1.4 should be cleared. Extension point pattern allows custom implementations: document adapter interface, provide example implementation, support ServiceLoader discovery. Depends on: Task 2.13 (validator with reload support), Task 6.2 (properties binding).

1. **Extension Point Interface TDD:** Write test class `ConfigCenterAdapterTest` with test methods: `testOnConfigChange_shouldNotifyListeners()` (config change triggers notification), `testReloadConfig_shouldUpdateProperties()` (reloadConfig updates SqlGuardProperties), `testConfigChangeEvent_shouldContainChangedKeys()` (event contains which properties changed). Define `ConfigCenterAdapter` interface in com.footstone.sqlguard.spring.config.center package with methods: void onConfigChange(ConfigChangeEvent event) (callback when config changes), void reloadConfig() (trigger full config reload), optional default methods for common functionality. Define `ConfigChangeEvent` class with fields: Map<String, String> changedKeys (property key → new value), String namespace (config namespace/group), long timestamp (change timestamp). Provide helper methods: boolean hasChanged(String key), String getNewValue(String key).

2. **Apollo Adapter Implementation:** Implement `ApolloConfigCenterAdapter` class in config.center.apollo package with @Configuration and @ConditionalOnClass(name = "com.ctrip.framework.apollo.Config") annotations ensuring only activated when Apollo client present: inject ApolloConfig via constructor, inject SqlGuardProperties for binding refresh, implement method annotated with @ApolloConfigChangeListener: @ApolloConfigChangeListener void onChange(ConfigChangeEvent changeEvent) { log.info("Apollo config changed: {}", changeEvent.changedKeys()); rebindProperties(changeEvent); notifyValidator(); }, implement rebindProperties extracting changed values from Apollo, updating SqlGuardProperties fields (use reflection or property binding), implement notifyValidator calling validator.reloadConfig(updatedProperties), register adapter as Spring bean in auto-configuration via @Bean @ConditionalOnClass method. Handle namespaces: support multiple Apollo namespaces via configuration, monitor all namespaces containing sql-guard.* properties.

3. **Nacos Adapter Implementation:** Implement `NacosConfigCenterAdapter` class in config.center.nacos package with @Configuration and @ConditionalOnClass(name = "com.alibaba.nacos.api.config.ConfigService") annotations: inject NacosConfigManager via constructor, inject SqlGuardProperties, implement method annotated with @NacosConfigListener: @NacosConfigListener(dataId = "${nacos.config.data-id:sql-guard}", groupId = "${nacos.config.group:DEFAULT_GROUP}") void onConfigChange(String configInfo) { log.info("Nacos config changed"); parseAndRebindProperties(configInfo); notifyValidator(); }, implement parseAndRebindProperties parsing YAML/properties from configInfo string, binding to SqlGuardProperties, implement notifyValidator similarly to Apollo adapter. Support dynamic dataId/groupId from configuration. Test both YAML and properties formats: Nacos supports both, adapter should detect format and parse accordingly.

4. **Validator Reload Integration:** Implement ConfigReloadSupport in DefaultSqlSafetyValidator: add private volatile SqlGuardConfig config field or use AtomicReference<SqlGuardConfig> for thread-safe updates, implement public void reloadConfig(SqlGuardConfig newConfig) method: validate newConfig via config.validate() from Task 1.3, atomically swap config reference, invalidate deduplication cache (call deduplicationFilter.clearAll()), invalidate JSqlParser cache (call jsqlParserFacade.clearCache() from Task 1.4), log config change at INFO level with changed fields, notify all RuleChecker instances of config change if stateful (most are stateless, config passed on each check). Test thread-safety: execute validation concurrent with config reload, verify no race conditions, verify atomicity (validation uses old or new config consistently, never partial state), verify cache invalidation prevents stale results.

5. **Integration and Extension Documentation:** Write integration test `ConfigCenterIntegrationTest` for Apollo: use embedded Apollo mock server or @MockBean ApolloConfig, trigger config change via Apollo API, verify SqlGuardProperties updated, verify validator uses new config, execute SQL validation and verify new rules applied. Write integration test for Nacos: use Nacos embedded server or mock, publish config change, verify hot-reload works. Test without config center: start app without Apollo/Nacos dependencies, verify adapters not created (@ConditionalOnClass prevents), verify static config still works. Create docs/integration/config-center-extension.md documenting: ConfigCenterAdapter interface contract, how to implement custom adapter (step-by-step with code example), how to register custom adapter (Spring bean registration, ServiceLoader pattern), example for custom config center (etcd, Consul, Zookeeper), troubleshooting guide. Run `mvn test` ensuring all config center tests pass.

## Phase 7: Examples & Documentation - Agent_Testing_Documentation

### Task 7.1 – Dangerous SQL Pattern Samples │ Agent_Testing_Documentation

- **Objective:** Create comprehensive example repository demonstrating all dangerous SQL patterns detected by system, providing educational samples with explanatory comments, BAD and GOOD versions for comparison, integration test validating scanner accuracy, and regression test suite preventing future false negatives.
- **Output:**
  - Examples module with sample MyBatis XML mappers for all violation types
  - Sample annotation-based mappers (@Select/@Update/@Delete) with dangerous patterns
  - Sample MyBatis-Plus service classes using QueryWrapper with problematic conditions
  - Organized samples by violation type with explanatory headers
  - BAD versions (violating patterns) and GOOD versions (corrected patterns) for each violation
  - Comprehensive comments explaining why dangerous, expected violation message, suggested fix
  - References to design document sections for each pattern
  - Integration test running scanner on examples validating detection accuracy
  - Regression test suite ensuring scanner catches all expected violations
- **Guidance:** Examples serve triple purpose: education for developers learning system, validation that scanner works correctly, regression prevention ensuring future changes don't break detection. Organize by violation type (no-WHERE, dummy-condition, blacklist-only, etc.) mirroring rule checker tasks (2.2-2.12) for easy reference. Each sample file should be self-documenting with header comment block explaining pattern, why dangerous, real-world impact, fix recommendation. BAD/GOOD pair pattern enables developers to see problem and solution side-by-side - critical for training and onboarding. Integration test with scanner provides automated validation: scan BAD examples, assert expected violations detected, scan GOOD examples, assert zero violations. Regression test prevents scanner degradation over time. Depends on: Task 3.7 (scanner CLI for testing).

- **MyBatis XML Examples:** Create examples/src/main/resources/mappers/bad/ directory with sample XMLs: NoWhereClauseMapper.xml (DELETE/UPDATE without WHERE, SELECT without WHERE), DummyConditionMapper.xml (WHERE 1=1, WHERE true, WHERE 'a'='a'), BlacklistOnlyMapper.xml (WHERE deleted=0, WHERE status='active' AND enabled=1), WhitelistViolationMapper.xml (user table query missing id/user_id from whitelist), LogicalPaginationMapper.xml (using RowBounds without PageHelper plugin configured), NoConditionPaginationMapper.xml (SELECT * FROM user LIMIT 100 without WHERE), DeepPaginationMapper.xml (LIMIT 20 OFFSET 50000), LargePageSizeMapper.xml (LIMIT 5000), MissingOrderByMapper.xml (paginated SELECT without ORDER BY), NoPaginationMapper.xml (SELECT * FROM large_table without pagination), CombinedViolationsMapper.xml (multiple violations in single SQL). Create examples/src/main/resources/mappers/good/ directory with corrected versions: each file mirrors bad/ structure but with fixes applied (proper WHERE clauses, PageHelper configuration, reasonable pagination parameters, ORDER BY added). Add XML comment headers to each file explaining pattern, expected violation, fix applied.

- **Annotation and QueryWrapper Examples:** Create examples/src/main/java/com/footstone/sqlguard/examples/bad/ with annotation mappers: NoWhereClauseAnnotationMapper.java (@Select/@Update/@Delete without WHERE), DummyConditionAnnotationMapper.java (@Select with WHERE 1=1), similar for all patterns. Create service classes: BadQueryWrapperService.java using QueryWrapper with empty wrapper (no conditions), blacklist-only wrapper (only status/deleted fields), no pagination on large tables. Create examples/src/main/java/.../good/ with corrected versions: proper WHERE in annotations, QueryWrapper with proper conditions, pagination applied. Add Javadoc comments to each class explaining pattern and fix.

- **Organization and Documentation:** Create examples/README.md explaining: purpose of examples, directory structure (bad/ vs good/), how to run scanner on examples, how each example maps to design sections and rule checkers, index of all examples by violation type. For each example file, add comprehensive header comment: /* VIOLATION: No WHERE Clause (CRITICAL) * PATTERN: DELETE FROM user * WHY DANGEROUS: Deletes entire table, catastrophic data loss * REAL-WORLD IMPACT: Production incident, customer data loss * EXPECTED MESSAGE: "SQL语句缺少WHERE条件,可能导致全表操作" * FIX: Add WHERE clause with business condition or unique key * DESIGN REFERENCE: Section 3.3.1, Task 2.2 * GOOD VERSION: See mappers/good/NoWhereClauseMapper.xml */. Reference design document sections linking examples to specifications.

- **Integration and Regression Testing:** Create test class `ExamplesValidationTest` in examples module: implement testScanBadExamples_shouldDetectAllViolations() running scanner CLI on bad/ directory, parsing output, asserting each expected violation detected with correct risk level, implement testScanGoodExamples_shouldPassAllChecks() running scanner on good/ directory, asserting zero violations. Create detailed assertions: for NoWhereClauseMapper.xml expect CRITICAL violation with message containing "缺少WHERE条件", for DummyConditionMapper.xml expect HIGH violation with "无效条件", etc. Implement regression test testAllKnownPatterns_shouldBeDetected() maintaining list of all known dangerous patterns, asserting scanner detects each one, preventing future changes from breaking detection. Run tests during CI build: if examples validation fails, block merge preventing regression. Use examples as acceptance test: new rule checkers must add corresponding examples, verify detection works, update regression test. Run `mvn test` in examples module ensuring validation passes.

### Task 7.2 – Spring Boot Demo Project │ Agent_Testing_Documentation

- **Objective:** Create production-ready Spring Boot demonstration application showcasing SQL Safety Guard System integration with real-world MyBatis/MyBatis-Plus usage, interactive REST endpoints triggering all violation types, comprehensive README with usage instructions, Docker Compose environment for quick deployment, and validation testing ensuring demo accurately represents system capabilities for evaluation and onboarding.
- **Output:**
  - Complete Spring Boot application with sql-guard-spring-boot-starter dependency
  - application.yml with comprehensive configuration demonstrating all settings from design 5.1
  - Sample domain entities (User, Order, Product) with MyBatis XML mappers and annotation mappers
  - Sample MyBatis-Plus services using QueryWrapper demonstrating common patterns
  - REST controller with endpoints triggering each violation type on demand
  - Violation log dashboard endpoint returning recent violations with details
  - Configuration management endpoint demonstrating hot-reload with config center
  - Comprehensive demo README with setup instructions, usage examples, troubleshooting
  - Docker Compose environment with MySQL database, demo app, optional Apollo/Nacos
  - Pre-populated database schema and test data for immediate demonstration
  - Validation tests ensuring demo triggers expected violations correctly
- **Guidance:** Demo application serves as live proof-of-concept for evaluating SQL Safety Guard before adoption, educational tool for developers learning system usage, and integration test validating end-to-end functionality. Application must demonstrate real-world scenarios: typical Spring Boot app structure, common MyBatis patterns (XML mappers + annotation mappers + MyBatis-Plus), REST API exposing business operations. Interactive endpoints critical for evaluation: users can trigger specific violations via HTTP requests, observe BLOCK/WARN/LOG strategies in action, toggle configuration dynamically. Docker Compose essential for easy evaluation: users run `docker-compose up` and demo starts with database pre-populated, no manual setup required. README must be comprehensive: non-technical managers evaluating tool should understand value proposition, developers should know how to integrate into existing projects. Depends on: Tasks 6.1-6.3 (Spring Boot integration complete), Tasks 2.2-2.12 (all rule checkers for violation demonstration), Tasks 4.1-4.5 (runtime interception for BLOCK strategy demonstration).

1. **Spring Boot Application Structure:** Create sql-guard-demo module in examples/ directory with standard Spring Boot structure: src/main/java/com/footstone/sqlguard/demo, src/main/resources, src/test/java. Add sql-guard-spring-boot-starter dependency to pom.xml along with spring-boot-starter-web for REST API, mybatis-spring-boot-starter for MyBatis integration, mybatis-plus-boot-starter for MyBatis-Plus features, mysql-connector-java for database connectivity, lombok for entity boilerplate reduction, spring-boot-starter-test for testing. Create `DemoApplication` main class with @SpringBootApplication annotation and SpringApplication.run() entry point. Configure application.yml in src/main/resources: datasource configuration (jdbc:mysql://localhost:3306/sqlguard_demo), MyBatis configuration (mapper locations, type aliases package), sql-guard configuration mirroring design 5.1 with all rules enabled, activeStrategy=LOG initially for safe demo, interceptors configuration enabling MyBatis/MyBatis-Plus/JDBC layers. Create application-block.yml profile with activeStrategy=BLOCK for blocking mode demonstration, application-warn.yml with activeStrategy=WARN for warning mode.

2. **Sample Domain Model and Mappers:** Create sample entities in com.footstone.sqlguard.demo.entity package: User entity (id, username, email, status, deleted, createTime), Order entity (id, userId, totalAmount, status, orderTime), Product entity (id, name, price, stock, categoryId). Create MyBatis XML mappers in src/main/resources/mapper demonstrating various patterns: UserMapper.xml with safe query (SELECT * FROM user WHERE id = #{id}), unsafe query for demo (deleteAllUsers without WHERE for demo endpoint), query with dummy condition (WHERE 1=1) for demo, query with blacklist-only (WHERE deleted=0) for demo, deep pagination query (LIMIT 20 OFFSET 50000) for demo. Create annotation-based mappers: UserAnnotationMapper interface with @Select/@Update/@Delete demonstrating both safe and unsafe patterns for demo purposes. Create MyBatis-Plus mappers: UserMybatisPlusMapper extending BaseMapper<User>, OrderService using QueryWrapper with methods demonstrating safe wrapper (queryWrapper.eq("id", id)) and unsafe empty wrapper for demo. Annotate unsafe methods with comments explaining they're intentionally dangerous for demo purposes.

3. **Interactive Demo REST Endpoints:** Create DemoController in com.footstone.sqlguard.demo.controller package with REST endpoints triggering each violation type: @GetMapping("/violations/no-where-clause") executing DELETE/UPDATE without WHERE (returns violation details caught by guard), @GetMapping("/violations/dummy-condition") executing query with WHERE 1=1, @GetMapping("/violations/blacklist-only") executing query with only status/deleted conditions, @GetMapping("/violations/whitelist-missing") executing user table query without id/user_id from whitelist, @GetMapping("/violations/logical-pagination") executing query with RowBounds without PageHelper configured, @GetMapping("/violations/deep-pagination") executing query with LIMIT 20 OFFSET 50000, @GetMapping("/violations/large-page-size") executing query with LIMIT 5000, @GetMapping("/violations/missing-orderby") executing paginated query without ORDER BY, @GetMapping("/violations/no-pagination") executing SELECT * FROM large_table without pagination. Each endpoint should return violation details (risk level, message, SQL) when caught, or success response if strategy=LOG/WARN. Create @GetMapping("/violations/logs") endpoint returning recent violations from in-memory log or database log table. Create @PostMapping("/config/strategy/{strategy}") endpoint allowing runtime strategy change (LOG/WARN/BLOCK) demonstrating configuration hot-reload if config center present.

4. **Docker Compose and Database Setup:** Create docker-compose.yml in demo root: MySQL 8.0 service (sqlguard-mysql) with environment variables (MYSQL_ROOT_PASSWORD, MYSQL_DATABASE=sqlguard_demo), port 3306 exposed, volume for data persistence, init script mounting. Demo app service (sqlguard-demo-app) building from Dockerfile, depends_on sqlguard-mysql, environment variables for datasource URL/credentials, port 8080 exposed. Optional Apollo service for config center demo (apolloconfig/apollo-quick-start image). Optional Nacos service for alternative config center demo (nacos/nacos-server image). Create init.sql in src/main/resources/db creating tables (user, order, product) with schema matching entities, inserting test data (100 users, 500 orders, 50 products) providing realistic dataset for demo queries. Create Dockerfile for demo app: FROM openjdk:11-jre-slim, COPY target/sql-guard-demo.jar, EXPOSE 8080, ENTRYPOINT ["java", "-jar", "sql-guard-demo.jar"]. Test Docker Compose: run `docker-compose up`, verify MySQL starts and initializes with test data, verify demo app connects to database, verify http://localhost:8080 accessible.

5. **Demo README and Validation Testing:** Create examples/sql-guard-demo/README.md with comprehensive documentation: **Overview** section explaining SQL Safety Guard demo purpose, **Features Demonstrated** list (all 7 rule types, 3 violation strategies, hot-reload, multi-layer interception), **Quick Start** with prerequisites (Docker + Docker Compose) and `docker-compose up` command, **Running Without Docker** with Maven instructions (mvn spring-boot:run), **Demo Endpoints** table listing all violation trigger endpoints with descriptions and expected responses, **Testing Different Strategies** showing how to switch between LOG/WARN/BLOCK modes using profiles or config endpoint, **Violation Examples** section with curl commands demonstrating each violation type with expected output, **Configuration Hot-Reload** section demonstrating Apollo/Nacos integration if running, **Troubleshooting** section for common issues (port conflicts, database connection failures). Add screenshots or ASCII art showing violation log output, BLOCK strategy SQLException response. Create test class `DemoApplicationTest` in src/test/java: test Spring Boot context loads successfully (@SpringBootTest), test each violation endpoint with RestTemplate verifying expected behavior (LOG strategy allows execution with log, BLOCK strategy throws exception), test violation logs endpoint returns violations with correct details, test configuration endpoint changes strategy successfully. Test demo end-to-end: start Docker Compose environment, execute curl commands from README against each violation endpoint, verify violations logged correctly, verify BLOCK mode prevents dangerous SQL execution, verify WARN mode logs but allows execution, take screenshots for README. Run `mvn clean package` and `docker-compose up` ensuring demo builds and runs successfully.

### Task 7.3 – User Documentation │ Agent_Testing_Documentation

- **Objective:** Create comprehensive user-facing documentation enabling successful adoption across all user personas (developers integrating system, DevOps deploying to production, managers evaluating value), providing quick-start guides, detailed configuration reference, troubleshooting resources, and phased deployment guidance ensuring safe production rollout following design 8.2 strategy.
- **Output:**
  - Professional README.md in project root with overview, features, quick-start, badges
  - docs/user-guide/ directory with installation, configuration, usage, deployment guides
  - Rule checker reference documentation for all 7 violation types with examples and fixes
  - Phased deployment guide (observation → warning → blocking) with environment-specific configs
  - Performance tuning guide covering deduplication, cache sizing, overhead optimization
  - Comprehensive FAQ and troubleshooting section addressing common issues
  - All documentation with clear examples, code snippets, configuration samples
- **Guidance:** User documentation critical for adoption success: poor docs lead to integration failures, support burden, abandonment. Target three personas: developers need integration instructions and API reference, DevOps needs deployment and configuration guidance, managers need value proposition and success metrics. README is first impression: must be professional with clear value proposition, visual elements (architecture diagram, badges), and 5-minute quick-start getting users to success fast. Configuration reference must be exhaustive: every YAML property documented with type, default, valid values, example - users should never need to read source code. Phased deployment guide essential for risk mitigation: design 8.2 three-phase rollout (LOG for observation, WARN for validation, BLOCK for enforcement) prevents production incidents during adoption. Performance tuning critical for large-scale deployment: document deduplication effectiveness, cache sizing impact, overhead benchmarks. FAQ prevents support tickets: address known issues (JSqlParser limitations, false positives, integration conflicts) proactively. Depends on: All phases output for complete documentation of all features.

1. **Professional README.md:** Create README.md in project root with compelling structure: **Badges** section at top with Maven Central version, build status (GitHub Actions), code coverage (Codecov), license (Apache 2.0), stars/forks. **Overview** section with elevator pitch: "SQL Safety Guard: Automated SQL safety validation for MyBatis applications preventing catastrophic production incidents through static scanning and runtime interception." Key features list with icons/emojis: ✅ Detects 7 types of dangerous SQL patterns, ✅ Dual-layer protection (static + runtime), ✅ Zero-config Spring Boot starter, ✅ <5% performance overhead, ✅ Phased deployment support (LOG/WARN/BLOCK). **Architecture** section with high-level diagram showing scanning flow and interception flow. **Quick Start** section with 5-minute integration: Maven dependency snippet for Spring Boot starter, minimal application.yml config, "You're protected! Dangerous SQL will now be blocked." **Documentation Links** pointing to detailed guides in docs/. **Contributing** and **License** sections. **Real-World Impact** section with testimonials or metrics if available: "Prevented X production incidents at Y company." Keep README concise (2-3 screens), visually appealing with proper markdown formatting, code syntax highlighting, emoji accents.

2. **Installation and Configuration Guides:** Create docs/user-guide/installation.md with platform-specific instructions: **Maven Integration** section with parent POM dependencyManagement snippet (for library users), Spring Boot starter dependency for Spring Boot apps, standalone dependency for non-Spring projects. **Gradle Integration** section with equivalent Gradle dependency configurations using Kotlin DSL and Groovy DSL examples. **Version Compatibility Matrix** table showing supported Java versions (8/11/17/21), MyBatis versions (3.4.6+, 3.5.13+), MyBatis-Plus versions (3.4.0+, 3.5.3+), Spring Boot versions (2.x, 3.x). **Build Tool Plugin Installation** for scanner CLI: Maven plugin configuration with execution binding to verify phase, Gradle plugin application and task configuration. Create docs/user-guide/configuration-reference.md documenting every YAML property: organize by category matching design 5.1 structure (rules, interceptors, deduplication, activeStrategy), for each property provide: name, type, default value, valid values/range, description, example YAML snippet. Document strategy hierarchy: activeStrategy with global default, strategyProfiles for environment-specific overrides, per-rule strategy override capability. Include complete example configurations: minimal config (just starter dependency, all defaults), development config (LOG strategy, all rules enabled with verbose logging), production config (BLOCK strategy, optimized deduplication, monitoring integration).

3. **Rule Checker Documentation:** Create docs/user-guide/rules/ directory with one markdown file per rule type: no-where-clause.md, dummy-condition.md, blacklist-whitelist.md, logical-pagination.md, pagination-abuse.md (covering no-condition, deep-offset, large-page-size), missing-orderby.md, no-pagination.md. For each rule document: **Risk Level** (CRITICAL/HIGH/MEDIUM/LOW from design), **What It Detects** section with SQL pattern description, **Why Dangerous** section explaining real-world impact with production incident examples, **Examples** section with BAD SQL (triggering violation) and GOOD SQL (corrected version) side-by-side, **Expected Message** showing exact violation message users will see, **How to Fix** with step-by-step remediation guidance, **Configuration** showing how to adjust risk level or disable rule if needed (with warning about security implications), **Design Reference** linking to design document section. Use consistent template across all rule docs for easy navigation. Add index page docs/user-guide/rules/README.md listing all rules with risk levels and one-line descriptions.

4. **Deployment and Performance Guides:** Create docs/user-guide/deployment.md documenting phased rollout strategy from design 8.2: **Phase 1: Observation Mode (1-2 weeks)** section with activeStrategy=LOG configuration, instructions to monitor logs identifying violations without blocking, guidance on analyzing violation frequency and false positive rate, decision criteria for proceeding to Phase 2. **Phase 2: Warning Mode (1-2 weeks)** section with activeStrategy=WARN configuration, instructions to validate warnings don't disrupt user experience, guidance on tuning rules based on Phase 1 observations (adjust risk levels, configure whitelists), decision criteria for proceeding to Phase 3. **Phase 3: Blocking Mode** section with activeStrategy=BLOCK configuration, instructions for gradual rollout (canary deployment, percentage-based rollout), rollback plan if incidents occur. **Environment-Specific Configuration** section showing dev (LOG), staging (WARN), production (BLOCK) YAML profiles. Create docs/user-guide/performance.md covering: **Overhead Benchmarks** from design 8.3 (baseline <5%, deduplication optimization effectiveness), **Deduplication Tuning** explaining cache size vs. hit rate tradeoff with sizing recommendations (default 1000, high-volume systems 5000-10000), TTL configuration for cache expiration, **Cache Configuration** for JSqlParser parse results, **Performance Monitoring** guidance on measuring overhead in production using metrics (validation latency, cache hit rates), **Optimization Tips** for high-throughput scenarios (disable low-value rules, increase cache sizes, tune deduplication TTL).

5. **FAQ and Troubleshooting:** Create docs/user-guide/faq.md addressing common questions: **Q: What's the performance impact?** A: <5% overhead typically, see performance guide for benchmarks. **Q: Can I disable specific rules?** A: Yes, set enabled=false in rule config. **Q: How do I whitelist legacy SQL?** A: Use rule-specific whitelists (e.g., whitelistFields for whitelist checker). **Q: What if scanner fails to parse SQL?** A: JSqlParser has limitations with proprietary SQL extensions, use lenientMode=true. **Q: How to handle false positives?** A: Adjust risk levels, configure whitelists, or disable specific rules - see configuration reference. **Q: Can I use without Spring Boot?** A: Yes, instantiate DefaultSqlSafetyValidator directly, see standalone usage guide. **Q: Does it support prepared statements?** A: Yes, runtime interceptors work with prepared statements, scanner works with static SQL only. Create docs/user-guide/troubleshooting.md with common issues and solutions: **Issue: JSqlParser ParseException** (solution: enable lenientMode or upgrade JSqlParser version), **Issue: False positives for dummy conditions** (solution: configure dummy condition patterns via config), **Issue: Performance degradation** (solution: increase deduplication cache size, verify cache hit rate), **Issue: Spring Boot auto-configuration not loading** (solution: verify starter in dependencies, check META-INF/spring.factories, enable debug logging), **Issue: Interceptor not triggering** (solution: verify interceptor order, check MyBatis vs. MyBatis-Plus vs. JDBC layer configuration). Each troubleshooting entry with diagnostic steps, root cause explanation, solution, verification method. Include "How to Report Bugs" section with GitHub issue template guidance.

### Task 7.4 – Developer Documentation │ Agent_Testing_Documentation

- **Objective:** Create comprehensive developer-facing documentation enabling project contributors to understand system architecture, follow development standards, extend functionality through custom rules and interceptors, and contribute high-quality code following established patterns and TDD methodology.
- **Output:**
  - ARCHITECTURE.md documenting system design, modules, patterns, data flows, extension points
  - CONTRIBUTING.md with development setup, code standards, TDD requirements, PR process
  - Complete Javadoc coverage on all public APIs with maven-javadoc-plugin site generation
  - CHANGELOG.md following Keep a Changelog format with version history and migration guides
  - Developer tutorials for common extension scenarios (custom rules, JDBC interceptors, config centers)
  - All guides with working code examples and testing instructions
- **Guidance:** Developer documentation enables project sustainability through contributor onboarding and knowledge transfer. ARCHITECTURE.md critical for understanding design decisions: new contributors should understand module boundaries, design pattern rationale, data flow without reading entire codebase. CONTRIBUTING.md ensures code quality consistency: enforce Google Java Style, mandate TDD (tests before code), define PR review criteria. Javadoc essential for API consumers: library users integrating validator or creating custom rules need comprehensive API documentation without reading implementation. CHANGELOG maintains version history transparency: users upgrading need migration guidance for breaking changes, contributors need context for past decisions. Extension tutorials demonstrate extensibility: "How to add custom rule" guide proves system is extensible and reduces feature request burden. All examples must be complete and tested: guides with broken code damage trust and waste contributor time. Depends on: All phases output for complete documentation of architecture and extension points.

1. **Architecture Documentation:** Create ARCHITECTURE.md in project root documenting system design comprehensively: **System Overview** section with elevator pitch, core capabilities (static scanning, runtime interception), design principles (performance <5% overhead, zero false negatives for CRITICAL rules, extensibility via SPI). **Module Structure** section listing all 9 modules with ASCII diagram showing dependencies: sql-scanner-core (foundation models + validation engine), sql-scanner-cli (command-line interface), sql-scanner-maven-plugin (Maven integration), sql-scanner-gradle-plugin (Gradle integration), sql-guard-mybatis (MyBatis interceptor), sql-guard-mybatis-plus (MyBatis-Plus interceptor), sql-guard-jdbc (JDBC interception), sql-guard-spring-boot-starter (Spring Boot integration), sql-guard-examples (samples). For each module document: purpose, key classes, public APIs, dependencies, extension points. **Design Patterns** section explaining pattern usage with rationale: Chain of Responsibility for RuleChecker validation (enables extensibility, sequential validation with short-circuiting), Strategy Pattern for violation handling (LOG/WARN/BLOCK strategies swapped at runtime), Builder Pattern for SqlContext construction (complex object creation with many optional fields), Visitor Pattern for JSqlParser AST traversal (FieldExtractorVisitor extracting fields from SELECT), Factory Pattern for interceptor creation (different factories for Druid/HikariCP/P6Spy). **Data Flow Diagrams** section with ASCII or Mermaid diagrams: Static Scanning Flow (source files → parser → AST → rule checkers → violation report), Runtime Interception Flow (MyBatis invocation → BoundSql extraction → validator → strategy handler → proceed/throw). **Threading Model** explaining thread-safety: validator is thread-safe (immutable after construction), deduplication filter uses ThreadLocal (per-thread LRU cache), interceptors are stateless (safe for concurrent invocation). **Extension Points** documenting SPI interfaces: RuleChecker for custom validation rules, ConfigCenterAdapter for custom config centers, Interceptor pattern for custom JDBC pools.

2. **Contributing Guide:** Create CONTRIBUTING.md with complete development workflow: **Development Setup** section with prerequisites (Java 11 for development, Maven 3.6+, IDE setup with Checkstyle plugin for Google Java Style), clone and build instructions (`git clone`, `mvn clean install`), running tests (`mvn test`), building Javadoc (`mvn javadoc:javadoc`). **Code Style Guidelines** section mandating Google Java Style: install google-java-format plugin in IDE, configure Checkstyle with google_checks.xml, run `mvn checkstyle:check` before committing, formatting requirements (120-char line length, 2-space indentation, proper Javadoc on all public members). **Test-Driven Development Requirements** section enforcing TDD: all features must have tests written FIRST before implementation code, test class naming: TestClass for unit tests, IntegrationTest for integration tests, test method naming: testMethodName_shouldExpectedBehavior, minimum 80% code coverage enforced by Jacoco (CI build fails below threshold). **Pull Request Process** section documenting workflow: create feature branch from main (`git checkout -b feature/your-feature`), make changes following TDD (tests first, then code), ensure all tests pass and coverage maintained, ensure Checkstyle passes (`mvn checkstyle:check`), push branch and create PR with description explaining change rationale, PR review criteria (code quality, test coverage, Javadoc completeness, design alignment), address review feedback, squash commits before merge, delete branch after merge. **How to Add New Rule Checker** tutorial with step-by-step guide: create test class in sql-scanner-core test directory, write failing tests for new violation pattern, create RuleChecker implementation extending base class, implement check() method with JSqlParser AST analysis, register checker in DefaultSqlSafetyValidator, run tests ensuring they pass, add examples to sql-guard-examples module, document rule in docs/user-guide/rules/, update CHANGELOG.md. **How to Support New JDBC Pool** tutorial: create test class in sql-guard-jdbc module, identify pool-specific interception mechanism (Druid uses FilterAdapter, HikariCP uses ProxyFactory, P6Spy uses JDBC proxy), implement interceptor adapter for pool, test with actual pool instance, add Spring Boot auto-configuration with @ConditionalOnClass guard, document in user guide, add example to demo project.

3. **Javadoc API Documentation:** Ensure comprehensive Javadoc coverage on all public APIs in sql-scanner-core module: `SqlSafetyValidator` interface documenting validation contract with @param/@return/@throws tags, code examples showing standalone usage, `RuleChecker` interface documenting custom rule implementation requirements with implementation guide, `SqlContext` class documenting all context fields with semantic descriptions, `ValidationResult` class documenting result interpretation, `JSqlParserFacade` class documenting SQL parsing API. Document public APIs in sql-guard-spring-boot-starter: `SqlGuardAutoConfiguration` class explaining auto-configuration behavior and conditional bean creation, `SqlGuardProperties` class documenting all configuration properties with @see links to user guide, `ConfigCenterAdapter` interface documenting custom adapter implementation contract. Configure maven-javadoc-plugin in parent POM: set source version to 8 for compatibility, configure custom stylesheet for professional appearance, exclude test and internal packages, generate Javadoc during package phase, deploy to GitHub Pages or Maven Central during release. Generate Javadoc site: run `mvn javadoc:aggregate` producing site in target/site/apidocs, verify completeness by spot-checking key classes, verify no warnings/errors in Javadoc generation, publish to GitHub Pages via gh-pages branch. Add Javadoc badge to README linking to published API docs.

4. **Changelog and Version History:** Create CHANGELOG.md following Keep a Changelog format: **[Unreleased]** section at top for pending changes not yet released, version sections in reverse chronological order **[1.0.0] - 2024-XX-XX**, for each version use categories: **Added** for new features, **Changed** for changes in existing functionality, **Deprecated** for soon-to-be removed features, **Removed** for removed features, **Fixed** for bug fixes, **Security** for vulnerability fixes. Document breaking changes prominently: **BREAKING CHANGE:** prefix on items breaking backward compatibility, migration guides for major version changes explaining how to adapt code. Initial 1.0.0 release content: **Added** section listing all 7 rule types, static scanner CLI/Maven/Gradle plugins, runtime interceptors for MyBatis/MyBatis-Plus/JDBC, Spring Boot auto-configuration, Apollo/Nacos config center support. Link to GitHub releases: add compare URLs at bottom (e.g., [1.0.0]: https://github.com/org/repo/compare/v0.9.0...v1.0.0). Maintain CHANGELOG during development: every PR adding feature/fix must update CHANGELOG in Unreleased section, maintainer moves Unreleased items to version section during release, ensures transparency of changes for users evaluating upgrades.

5. **Extension Tutorials:** Create docs/developer-guide/tutorials/ directory with practical guides: **tutorial-custom-rule-checker.md** with complete working example: problem statement (detect SELECT COUNT(*) on large tables without WHERE as MEDIUM violation), TDD process showing test-first development (write CheckerTest with testCountStarWithoutWhere_shouldDetectViolation), implementation guide (create CountStarChecker class, override check() method, use JSqlParser to detect COUNT(*) and absent WHERE), registration in DefaultSqlSafetyValidator, testing with real SQL, integration into scanner CLI. Include complete source code in tutorial that users can copy-paste and run. **tutorial-jdbc-interceptor.md** for supporting custom JDBC pool: problem statement (add support for Tomcat JDBC Pool), identify interception mechanism (Tomcat uses JdbcInterceptor interface), implement TomcatSqlSafetyInterceptor extending JdbcInterceptor, test with TomcatJdbc DataSource, add Spring Boot @Bean with @ConditionalOnClass guard, document in configuration reference. **tutorial-config-center-adapter.md** for integrating custom config center: problem statement (add support for etcd configuration), implement ConfigCenterAdapter for etcd client, handle configuration change events, test reload functionality, register adapter as Spring bean, document usage. Each tutorial must include: complete working code example, step-by-step instructions, expected output/behavior, troubleshooting common issues, verification testing. Test tutorials by following exactly: have developer unfamiliar with codebase follow tutorial start to finish, verify they achieve working result without external help, iterate tutorial based on feedback. Run `mvn clean install` ensuring all documentation builds successfully and Javadoc generates without errors.

