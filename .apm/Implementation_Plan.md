# SQL Safety Guard System – Implementation Plan

**Memory Strategy:** Dynamic-MD (directory structure with Markdown logs)
**Last Modification:** 2025-12-17 - Phase 3系统性审查完成，应用17项修改: (Critical) C1-替换Structured Concurrency为CompletableFuture.allOf(), C2-明确Java版本模块边界; (High) H1-新增Task 8.3.5 HikariCP审计拦截器, H2-ClickHouse设为可选提供PostgreSQL-only模式, H3-标记P2 Checker对Task 10.4的显式依赖; (Medium) M1-增加JDBC拦截器选型决策树, M2-标注P0 Checker复杂度(FullTableScan/ErrorRate建议分阶段), M3-新增配置诊断端点, M11-配置自动迁移适配器; (Low) L1-新增迁移集成测试套件, L2-新增运维手册, L3-澄清API使用示例范围。工作量调整: Phase 8 15→17天, Phase 9 26→28天, Phase 10 13→16天, Phase 11 7→8天, Phase 12 12→13天, 总计73→82天(+12%)。
**Project Overview:** Build enterprise-grade SQL Safety Guard System for MyBatis applications with dual-layer protection: (1) Pre-execution defense (Phases 1-7 COMPLETED) - static scanning and runtime interception preventing dangerous SQL execution, (2) Post-execution audit (Phases 8-12 NEW) - audit log collection, advanced analysis with execution metrics, behavioral anomaly detection, and centralized audit service. System supports Java 8 baseline for business applications, Java 21 for audit service leveraging Virtual Threads, comprehensive Spring Boot integration, phased deployment strategy (LOG→WARN→BLOCK), and <5% performance overhead target through optimization.

**Architecture Notes:**
- **Dual-Config Pattern:** System uses two separate config class hierarchies: (1) `com.footstone.sqlguard.config.*Config` for YAML deserialization (simple POJOs), (2) `com.footstone.sqlguard.validator.rule.impl.*Config` for runtime checker behavior (extends CheckerConfig). See `sql-guard-core/docs/Dual-Config-Pattern.md` for details. This pattern ensures YAML compatibility while providing rich domain objects for validation logic.

## Phase 1: Foundation & Core Models - Agent_Core_Engine_Foundation

### Task 1.1 – Project Structure & Multi-Module Build Configuration │ Agent_Core_Engine_Foundation

- **Objective:** Establish complete Maven multi-module project foundation with standardized structure, dependency management, quality enforcement, and multi-version Java compatibility for the entire SQL Safety Guard System.
- **Output:**
  - Parent POM with comprehensive dependency management for all core libraries (JSqlParser 4.x, JavaParser 3.x, DOM4J 2.x, MyBatis 3.4.6/3.5.13, MyBatis-Plus 3.4.0/3.5.3, SLF4J 1.7.x, Logback 1.2.x, SnakeYAML 1.33, JUnit 5, Mockito 4.x) and multi-version profiles (Java 8/11/17/21)
  - Nine module POMs with proper inheritance and inter-module dependencies
  - Standard Maven directory structure across all modules with com.footstone.sqlguard.* package hierarchy
  - Build verification demonstrating successful compilation and test infrastructure
- **Guidance:** This is the foundational task enabling all subsequent development. Use Maven 3.6+ best practices for parent POM structure. Configure all dependency versions in parent POM <dependencyManagement> to ensure consistency. Set Java 8 as baseline (source/target 1.8) with profiles for 11/17/21 testing. Integrate Google Java Style via Checkstyle plugin with enforcement in verify phase to prevent style violations early. The placeholder test class validates JUnit 5 + Mockito 4.x integration works correctly before real test development begins. All nine modules must compile successfully to ensure proper dependency resolution. Depends on: None (foundational task).

1. **Parent POM Setup:** Create parent `pom.xml` in project root with groupId `com.footstone`, artifactId `sql-safety-guard-parent`, packaging `pom`. Define <properties> for all dependency versions (JSqlParser 4.9.0, JavaParser 3.25.7, DOM4J 2.1.4, MyBatis 3.4.6/3.5.13, MyBatis-Plus 3.4.0/3.5.3, SLF4J 1.7.36, Logback 1.2.12, SnakeYAML 1.33, JUnit 5.10.1, Mockito 4.11.0). Configure <dependencyManagement> importing all libraries with versions from properties. Set maven.compiler.source and maven.compiler.target to 1.8, project.build.sourceEncoding to UTF-8.
2. **Multi-Version Profiles:** Define Maven profiles in parent POM for Java 11 (profile id `java11`), Java 17 (profile id `java17`), and Java 21 (profile id `java21`). Each profile overrides compiler source/target to respective version. Document profile activation in project README for CI/CD matrix builds.
3. **Module POM Creation:** Create child module directories and POMs for: sql-scanner-core (core scanning engine), sql-scanner-cli (CLI tool), sql-scanner-maven (Maven plugin), sql-scanner-gradle (Gradle plugin), sql-guard-core (validation engine), sql-guard-mybatis (MyBatis interceptor), sql-guard-mp (MyBatis-Plus interceptor), sql-guard-jdbc (JDBC layer interceptors), sql-guard-spring-boot-starter (Spring Boot auto-configuration). Each module POM specifies parent reference and declares direct dependencies (not versions, inherited from parent). Configure inter-module dependencies where needed (e.g., sql-guard-mybatis depends on sql-guard-core).
4. **Directory Structure:** For each of the nine modules, create standard Maven layout: src/main/java (production source), src/main/resources (configuration files), src/test/java (test source), src/test/resources (test resources). Establish base package structure: com.footstone.sqlguard.core (core models), com.footstone.sqlguard.scanner (scanning engine), com.footstone.sqlguard.interceptor (interceptors), com.footstone.sqlguard.config (configuration).
5. **Build Plugin Configuration:** In parent POM <build><pluginManagement>, configure maven-compiler-plugin version 3.11.0 (source/target 1.8, encoding UTF-8, showWarnings true), maven-surefire-plugin version 3.2.3 (JUnit 5 support), maven-source-plugin version 3.3.0 (attach sources on package), maven-javadoc-plugin version 3.6.3 (generate javadoc JAR). Configure checkstyle-maven-plugin version 3.3.1 with Google Java Style (google_checks.xml), bind to verify phase with failOnViolation true to enforce style compliance before build completion.
6. **Build Verification:** Execute `mvn clean compile` from project root to verify parent + all nine modules compile successfully without errors. Create placeholder test class `com.footstone.sqlguard.core.FoundationTest` in sql-guard-core module with simple JUnit 5 @Test annotated method using Mockito mock() to verify test infrastructure (JUnit Platform + Mockito framework) is properly configured. Run `mvn test` to confirm test execution works. Check Checkstyle reports to ensure Google Java Style enforcement is active.

### Task 1.2 – Core Data Models & Domain Types │ Agent_Core_Engine_Foundation

- **Objective:** Implement fundamental domain models (SqlContext, ValidationResult, enums, ViolationInfo) that form the contract between SQL parsing, validation, and interception layers, following TDD methodology to ensure correctness and immutability where required.
- **Output:**
  - SqlContext class with builder pattern for capturing complete SQL execution context (SQL string, parsed AST, command type, mapper ID, parameters, datasource, pagination info)
  - ValidationResult class with methods for violation aggregation and risk level determination
  - RiskLevel enum (SAFE/LOW/MEDIUM/HIGH/CRITICAL) with severity ordering
  - SqlCommandType enum (SELECT/UPDATE/DELETE/INSERT)
  - ViolationInfo value object for individual violation details
  - Comprehensive unit tests demonstrating all model behaviors and constraints
- **Guidance:** These models are referenced throughout the system by all validation checkers and interceptors. SqlContext uses builder pattern to accommodate varying contexts (XML Mapper vs JDBC vs QueryWrapper). Ensure immutability for parsedSql, type, and mapperId to prevent accidental modification during validation chain execution. ValidationResult must support multiple violations from different checkers and correctly aggregate to highest risk level. All classes must have comprehensive Javadoc explaining field meanings and usage patterns. Apply Google Java Style and fail-fast validation (throw IllegalArgumentException for invalid states). Depends on: Task 1.1 Output (project structure and build configuration).

1. **SqlContext TDD:** Write test class `SqlContextTest` covering: builder creation with all fields populated, builder with minimal fields (sql only), immutability verification for critical fields (parsedSql should be set once), null handling for optional fields (params, datasource, rowBounds can be null). Then implement `SqlContext` in `com.footstone.sqlguard.core.model` package with fields: String sql (required), Statement parsedSql (optional, set during validation), SqlCommandType type (required), String mapperId (required, format "namespace.methodId"), Map<String, Object> params (optional), String datasource (optional), RowBounds rowBounds (optional for MyBatis pagination detection). Implement static builder() method returning SqlContextBuilder with fluent API. Add field validation in build() throwing IllegalArgumentException if sql/type/mapperId are null.
2. **ValidationResult TDD:** Write test class `ValidationResultTest` covering: initial creation with passed=true, adding single violation changes passed to false, adding multiple violations aggregates to highest risk level (e.g., MEDIUM + CRITICAL = CRITICAL), empty violations list means passed, getRiskLevel() returns SAFE when passed. Then implement `ValidationResult` in core.model package with fields: boolean passed (default true), RiskLevel riskLevel (default SAFE), List<ViolationInfo> violations (ArrayList), Map<String, Object> details (LinkedHashMap for insertion order). Implement addViolation(RiskLevel, String message, String suggestion) method that creates ViolationInfo, adds to list, sets passed=false, updates riskLevel to max(current, new). Implement static pass() factory method.
3. **Enums TDD:** Write test class `EnumsTest` covering: RiskLevel ordering (SAFE < LOW < MEDIUM < HIGH < CRITICAL), RiskLevel.compareTo() works correctly, SqlCommandType values match expected (SELECT/UPDATE/DELETE/INSERT). Then implement `RiskLevel` enum in core.model with constants SAFE, LOW, MEDIUM, HIGH, CRITICAL (declaration order determines natural ordering). Implement Comparable<RiskLevel> with compareTo using ordinal(). Add getSeverity() returning ordinal. Implement `SqlCommandType` enum with SELECT, UPDATE, DELETE, INSERT values. Add fromString(String) static method for case-insensitive lookup.
4. **ViolationInfo TDD:** Write test class `ViolationInfoTest` covering: creation with all fields, equals() compares riskLevel+message (not suggestion), hashCode() consistency with equals, toString() includes all fields. Then implement `ViolationInfo` value object in core.model with fields: RiskLevel riskLevel (required), String message (required), String suggestion (optional). Make class final and fields final (immutable). Implement constructor with validation (riskLevel and message cannot be null). Override equals() using Objects.equals on riskLevel+message, override hashCode() using Objects.hash, override toString() returning formatted string "ViolationInfo{riskLevel=X, message='...', suggestion='...'}".
5. **Documentation & Validation:** Add Javadoc to all public classes and methods: SqlContext (explain builder pattern usage and field purposes), ValidationResult (explain violation aggregation logic), RiskLevel (explain severity ordering), SqlCommandType (explain SQL type categorization), ViolationInfo (explain immutability and value object pattern). Write additional unit tests for builder immutability: attempt to modify SqlContext after build() should not affect original, ValidationResult modifications don't leak to callers. Run `mvn test` to verify all tests pass. Run `mvn checkstyle:check` to ensure Google Java Style compliance. Verify fail-fast: SqlContext.builder().build() without required fields throws IllegalArgumentException with clear message.

### Task 1.3 – Configuration Model with YAML Support │ Agent_Core_Engine_Foundation

- **Objective:** Implement comprehensive configuration system supporting YAML file loading, nested rule configurations for all 7 validation rules, fail-fast validation, and default configuration merging to enable flexible runtime behavior control.
- **Output:**
  - SqlGuardConfig root class with all configuration sections (enabled, activeStrategy, interceptors, deduplication, rules)
  - Configuration classes for 7 rules: NoWhereClauseConfig, DummyConditionConfig, BlacklistFieldsConfig, WhitelistFieldsConfig, PaginationAbuseConfig, NoPaginationConfig, EstimatedRowsConfig
  - YamlConfigLoader with loadFromFile() and loadFromClasspath() methods
  - SqlGuardConfigDefaults providing sensible defaults matching design document section 5.1
  - Comprehensive validation ensuring configurations fail-fast on invalid values
- **Guidance:** Configuration system must support both file-based (deployment) and classpath-based (testing) loading. Use SnakeYAML for YAML parsing with proper type mapping for nested structures. Implement fail-fast validation in setters or post-construction validation method to catch misconfigurations early (maxOffset > 0, cacheSize > 0, valid strategy names). Default configuration should match design document to work out-of-box for common scenarios. Merging logic allows user config to override only specific fields while inheriting sensible defaults for unspecified fields. All config classes should be mutable POJOs for YAML binding but validate constraints. Depends on: Task 1.1 Output (project structure with SnakeYAML dependency).

1. **Root Config TDD:** Write test class `SqlGuardConfigTest` covering: default config creation, enabled flag toggle, activeStrategy setting (dev/test/prod), interceptors config structure (mybatis.enabled, mybatis-plus.enabled, jdbc.enabled + type), deduplication config (enabled, cacheSize, ttlMs values). Then implement `SqlGuardConfig` in `com.footstone.sqlguard.config` package with fields: boolean enabled (default true), String activeStrategy (default "prod"), InterceptorsConfig interceptors (nested object), DeduplicationConfig deduplication (nested object), RulesConfig rules (nested object containing all 7 rule configs). Implement nested static classes InterceptorsConfig (MyBatisConfig mybatis, MyBatisPlusConfig mybatisPlus, JdbcConfig jdbc), DeduplicationConfig (boolean enabled, int cacheSize, long ttlMs), RulesConfig (fields for each of 7 rule configs).
2. **Rule Configs TDD:** Write test classes for each rule config covering valid configurations and constraint violations. Implement config classes in config package: `NoWhereClauseConfig` (boolean enabled, RiskLevel riskLevel), `DummyConditionConfig` (enabled, riskLevel, List<String> patterns, List<String> customPatterns), `BlacklistFieldsConfig` (enabled, riskLevel, Set<String> fields), `WhitelistFieldsConfig` (enabled, riskLevel, Set<String> fields, Map<String, List<String>> byTable, boolean enforceForUnknownTables), `PaginationAbuseConfig` (enabled, riskLevel, nested LogicalPaginationConfig, PhysicalNoConditionConfig, PhysicalDeepPaginationConfig with maxOffset/maxPageNum, LargePageSizeConfig with maxPageSize, NoOrderByConfig), `NoPaginationConfig` (enabled, riskLevel, boolean enforceForAllQueries, List<String> whitelistMapperIds, List<String> whitelistTables, List<String> uniqueKeyFields), `EstimatedRowsConfig` (enabled, riskLevel, Map<SqlCommandType, Integer> thresholds). Each config class is mutable POJO for YAML deserialization.
3. **YAML Loader Implementation:** Add SnakeYAML 1.33 dependency to sql-guard-core module POM. Implement `YamlConfigLoader` class in config package with methods: `loadFromFile(Path path)` throws IOException for file-based loading, `loadFromClasspath(String resourcePath)` for classpath resource loading. Use SnakeYAML's Constructor with PropertyUtils for proper nested type mapping. Configure SnakeYAML to handle Map<String, List<String>> in WhitelistFieldsConfig.byTable correctly. Add error handling for FileNotFoundException, YAMLException (malformed YAML), and ClassCastException (type mismatches). Wrap exceptions in custom ConfigLoadException with descriptive messages indicating which field/section failed.
4. **Fail-Fast Validation:** Implement validation method in SqlGuardConfig: `validate()` throws IllegalArgumentException with clear messages. Validation rules: enabled must be boolean, activeStrategy must be one of [dev, test, prod], deduplication.cacheSize > 0, deduplication.ttlMs > 0, PaginationAbuseConfig.maxOffset > 0, PaginationAbuseConfig.maxPageSize > 0, pattern lists not empty if configured. Add @PostConstruct or manual validate() call after YAML deserialization. Write tests: valid YAML loads successfully, invalid YAML syntax throws exception with line/column info, invalid values (maxOffset = -1) throw IllegalArgumentException, type mismatches (string instead of int) throw ConfigLoadException, missing required nested sections use defaults.
5. **Defaults & Merging:** Implement `SqlGuardConfigDefaults` class providing static method `getDefault()` returning SqlGuardConfig with sensible defaults matching design section 5.1: enabled=true, activeStrategy="prod", mybatis.enabled=true, mybatisPlus.enabled=false, jdbc.enabled=true with type="auto", deduplication.enabled=true with cacheSize=1000 and ttlMs=100, all rules enabled with appropriate risk levels (NoWhereClauseConfig: CRITICAL, DummyConditionConfig: HIGH, BlacklistFieldsConfig: HIGH with default fields [deleted, del_flag, status], etc.). Implement merging logic in YamlConfigLoader: load user YAML, load defaults, overlay user values over defaults (non-null user values override defaults), return merged SqlGuardConfig. Write tests: partial user config merges with defaults correctly, user config overrides specific fields while inheriting others, empty YAML file results in complete default configuration.
6. **Comprehensive Testing:** Write integration test `YamlConfigLoaderIntegrationTest` with sample YAML files in src/test/resources: valid-complete.yml (all sections defined), valid-partial.yml (only some rules configured), invalid-syntax.yml (malformed YAML), invalid-values.yml (maxOffset=-1), invalid-types.yml (string where int expected), missing-required.yml (missing critical sections). Each test verifies expected behavior: successful load, ConfigLoadException with descriptive message, IllegalArgumentException for constraint violations, correct merging with defaults. Verify fail-fast: invalid config detected before any SQL validation occurs. Run `mvn test` ensuring all config tests pass.

### Task 1.4 – JSqlParser Integration Facade │ Agent_Core_Engine_Foundation

- **Objective:** Create unified facade for JSqlParser 4.x providing SQL parsing, AST extraction utilities, fail-fast error handling with configurable lenient mode, and LRU caching for parsed statements to optimize repeated SQL validation performance.
- **Output:**
  - JSqlParserFacade class with parse() method returning JSqlParser Statement AST
  - Utility methods: extractWhere(), extractTableName(), extractFields() for common SQL analysis operations
  - Fail-fast and lenient error handling modes
  - LRU cache for parsed SQL statements with configurable size and cache statistics
  - Comprehensive tests covering multiple database dialects and edge cases
- **Guidance:** JSqlParser is the core SQL parsing engine used throughout validation. Facade pattern isolates rest of system from JSqlParser API changes. Fail-fast mode (default) ensures invalid SQL is rejected immediately; lenient mode (for optional rules) logs warnings and continues. LRU cache is critical for performance when same SQL template is validated repeatedly (common with PreparedStatements). Cache key should be normalized SQL (trimmed, lowercase) to maximize hit rate. Utility methods reduce code duplication across rule checkers. Test with multiple database dialects since JSqlParser supports MySQL, PostgreSQL, Oracle, SQL Server syntax variations. Depends on: Task 1.1 Output (project structure with JSqlParser 4.x dependency).

1. **Basic Parsing TDD:** Write test class `JSqlParserFacadeTest` covering: parse valid SELECT statement returns Statement, parse valid UPDATE/DELETE/INSERT statements, parse invalid SQL syntax throws SqlParseException, parse null SQL throws IllegalArgumentException, parse empty/whitespace-only SQL throws SqlParseException. Then add JSqlParser 4.9.0 dependency to sql-guard-core module POM. Implement `JSqlParserFacade` class in `com.footstone.sqlguard.parser` package with constructor accepting `boolean lenientMode` (default false). Implement `parse(String sql)` method: validate sql not null/empty, call CCJSqlParserUtil.parse(sql) catching JSQLParserException, in fail-fast mode throw custom SqlParseException (extends RuntimeException) wrapping original exception and including original SQL in message, in lenient mode log warning via SLF4J and return null.
2. **Error Handling Strategy:** Implement custom `SqlParseException` extending RuntimeException in parser package with constructor accepting String message and Throwable cause. Exception message format: "Failed to parse SQL: [first 100 chars of SQL]... - Reason: [JSQLParserException message]". Add `boolean isLenientMode()` getter to JSqlParserFacade. Write tests: fail-fast mode throws SqlParseException with descriptive message containing SQL snippet, lenient mode returns null and logs warning at WARN level (verify with Logback test appender), SqlParseException message includes both SQL and parse error reason, exception includes original JSQLParserException as cause for debugging.
3. **Extraction Utilities TDD:** Write tests for utility methods: extractWhere(SELECT) returns WHERE Expression, extractWhere(UPDATE) returns WHERE, extractWhere(DELETE) returns WHERE, extractWhere(INSERT) returns null (no WHERE), extractTableName(SELECT) returns table name, extractTableName(multi-table JOIN) returns first/primary table, extractFields(Expression) returns Set containing all field names from WHERE. Then implement utility methods in JSqlParserFacade: `extractWhere(Statement)` using instanceof checks and casting, `extractTableName(Statement)` traversing FromItem to get table name, `extractFields(Expression)` implementing custom FieldExtractorVisitor (extends ExpressionVisitorAdapter) that visits Column nodes and collects getColumnName() into Set<String>. Add null-safe handling: return null/empty set for null inputs. Write edge case tests: complex WHERE with AND/OR/NOT operators, nested subqueries, table aliases in field references.
4. **LRU Cache Implementation:** Implement LRU cache using LinkedHashMap with accessOrder=true and size bound. Add constructor parameter `int cacheSize` (default 1000). Implement `parseCached(String sql)` method: normalize SQL (trim, lowercase), check cache with get(normalizedSql), if hit increment hit counter and return cached Statement, if miss call parse(sql), cache result with put(normalizedSql, stmt), if cache exceeds size remove eldest entry, increment miss counter. Add `getCacheStatistics()` returning CacheStats object with hitCount, missCount, size, hitRate. Implement `clearCache()` method. Write tests: cache hit returns same Statement instance, cache miss calls parse and caches result, cache size limit enforced (eldest evicted when exceeded), cache statistics accurate, clearCache() empties cache.
5. **Multi-Database Dialect Testing:** Write integration test `JSqlParserMultiDialectTest` with SQL samples from different databases in src/test/resources: MySQL syntax (LIMIT, backtick identifiers, UNSIGNED), PostgreSQL syntax (LIMIT/OFFSET, ::cast, dollar quotes), Oracle syntax (ROWNUM, dual table, (+) outer join), SQL Server syntax (TOP, square bracket identifiers, NOLOCK hint). For each dialect: parse valid simple SELECT/UPDATE/DELETE/INSERT, parse complex SQL with subqueries and joins, verify extractWhere/extractTableName/extractFields work correctly. Test edge cases: empty SQL, null SQL, whitespace-only SQL, SQL comments (-- and /* */), dynamic SQL with ? placeholders, very long SQL (10000+ chars). Verify fail-fast exceptions for truly invalid syntax. Run comprehensive tests ensuring JSqlParser handles expected SQL variations.

### Task 1.5 – Logging Infrastructure Setup │ Agent_Core_Engine_Foundation

- **Objective:** Configure SLF4J and Logback logging framework across core modules providing consistent log formatting, appropriate log levels for development and testing, and verification that logging infrastructure works correctly before core development begins.
- **Output:**
  - SLF4J and Logback dependencies properly configured in parent POM and core modules
  - Production logging configuration (logback.xml) with structured console output
  - Test logging configuration (logback-test.xml) with reduced noise for test execution
  - Verification test demonstrating logging works at different levels
- **Guidance:** SLF4J provides logging API abstraction while Logback implements actual logging. Configure dependencies in parent POM <dependencyManagement> for version consistency, then add actual dependencies to sql-guard-core and sql-scanner-core modules (where logging will be used). Production config (logback.xml) should output structured logs with timestamp, level, logger name, and message for operational visibility. Test config (logback-test.xml) should reduce noise (root at WARN) while enabling DEBUG for our code to facilitate test debugging. Verification test confirms Logback test configuration overrides production config during test execution. Depends on: Task 1.1 Output (project structure and dependency management).

- **Dependency Configuration:** In parent POM <dependencyManagement>, add SLF4J API version 1.7.36 (groupId org.slf4j, artifactId slf4j-api) and Logback Classic version 1.2.12 (groupId ch.qos.logback, artifactId logback-classic, note: Logback Classic transitively includes logback-core). In sql-guard-core/pom.xml and sql-scanner-core/pom.xml, add SLF4J API and Logback Classic dependencies without version tags (inherited from parent <dependencyManagement>). Logback Classic includes SLF4J binding, so no additional binding dependency needed.
- **Production Logging Configuration:** Create file src/main/resources/logback.xml in sql-guard-core module with <configuration> root element. Define <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"> with <encoder> pattern: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n" (includes timestamp, thread name, log level padded to 5 chars, logger name truncated to 36 chars, message, newline). Configure <logger name="com.footstone.sqlguard" level="DEBUG"/> for development visibility. Set <root level="INFO"><appender-ref ref="CONSOLE"/></root> to reduce third-party library noise. Copy this logback.xml to sql-scanner-core/src/main/resources as well for consistency.
- **Test Logging Configuration:** Create file src/test/resources/logback-test.xml in sql-guard-core module (Logback prioritizes logback-test.xml during test execution, overriding logback.xml). Define console appender with simpler pattern: "%d{HH:mm:ss.SSS} %-5level %logger{20} - %msg%n" (shorter timestamp, truncated logger for readability). Configure <logger name="com.footstone.sqlguard" level="DEBUG"/> to enable our debug logs during testing. Set <root level="WARN"> to suppress INFO logs from test frameworks (JUnit, Mockito) and third-party libraries, keeping test output focused on our code. Copy to sql-scanner-core/src/test/resources.
- **Logging Verification Test:** Create test class `LoggingInfrastructureTest` in sql-guard-core/src/test/java/com/footstone/sqlguard/core with JUnit 5 @Test method `testLoggingWorks()`. Get SLF4J Logger via LoggerFactory.getLogger(LoggingInfrastructureTest.class). Log messages at different levels: logger.trace("Trace message"), logger.debug("Debug message"), logger.info("Info message"), logger.warn("Warn message"), logger.error("Error message"). Run test with `mvn test` and verify console output shows debug/info/warn/error messages (trace not shown since root level WARN in logback-test.xml, but com.footstone.sqlguard at DEBUG shows debug), verify logback-test.xml is applied (shorter timestamp format visible), verify no duplicate log entries (single appender). Check log output format matches expected pattern with timestamp, level, logger name, message.

## Phase 2: Validation Engine - Agent_Core_Engine_Validation (13 tasks - Task 2.8 split into 4 focused checkers)

**Status:** 12/13 tasks completed (Tasks 2.1-2.12 ✅). Task 2.13 ready for execution.

**Config Architecture Note:** Tasks 2.1-2.12 created config classes in `validator/rule/impl` package extending CheckerConfig. Corresponding YAML-binding config classes exist in `config` package (Dual-Config Pattern). Task 2.13 assembly must use validator package configs for checker construction.

### Task 2.1 – Rule Checker Framework & Interfaces │ Agent_Core_Engine_Validation

- **Objective:** Establish foundational framework for Chain of Responsibility pattern rule checking system with RuleChecker interface, AbstractRuleChecker base class providing shared utilities, and RuleCheckerOrchestrator coordinating validation across all enabled checkers.
- **Output:**
  - RuleChecker interface defining check contract for all validation rules
  - CheckerConfig base class for common configuration (enabled flag)
  - AbstractRuleChecker base class with utility methods (extractWhere, extractTableName, FieldExtractorVisitor, isDummyCondition, isConstant)
  - RuleCheckerOrchestrator managing checker execution and violation aggregation
  - Integration tests verifying orchestration, enabled/disabled toggling, violation aggregation
- **Guidance:** This framework is used by all subsequent rule checkers (Tasks 2.2-2.12). RuleChecker interface provides uniform contract allowing polymorphic checker execution. AbstractRuleChecker reduces code duplication by implementing common SQL analysis operations used across multiple checkers. FieldExtractorVisitor uses JSqlParser's visitor pattern to traverse Expression AST collecting field names. RuleCheckerOrchestrator implements Chain of Responsibility pattern iterating through checkers, allowing each to add violations independently. Final risk level is highest among all violations to ensure most severe issue is surfaced. Depends on: None within phase (depends on Phase 1 Task 1.4 for JSqlParser facade).

1. **RuleChecker Interface TDD:** Write test class `RuleCheckerTest` covering: checker with no violations leaves ValidationResult passed, checker adding violation changes passed to false, disabled checker is skipped (isEnabled returns false), verify check method signature accepts SqlContext and ValidationResult. Then implement `RuleChecker` interface in `com.footstone.sqlguard.validator.rule` package with methods: `void check(SqlContext context, ValidationResult result)` (performs validation, may add violations to result), `boolean isEnabled()` (returns true if checker should execute). Define `CheckerConfig` base class with boolean enabled field (default true) and getter isEnabled().
2. **AbstractRuleChecker Utilities TDD:** Write test class `AbstractRuleCheckerTest` covering: extractWhere from SELECT/UPDATE/DELETE returns Expression or null for INSERT, extractTableName from simple SELECT returns table name, extractTableName from JOIN returns primary table, FieldExtractorVisitor extracts all field names from complex WHERE (AND/OR/nested), isDummyCondition detects "1=1" and constant comparisons, isConstant identifies literals vs column references. Then implement `AbstractRuleChecker` abstract class implementing RuleChecker in validator.rule package with utility methods: `protected Expression extractWhere(Statement)` using instanceof casting, `protected String extractTableName(Statement)` traversing FromItem, `protected Set<String> extractFields(Expression)` using FieldExtractorVisitor, `protected boolean isDummyCondition(Expression)` checking for dummy patterns and constant equality, `protected boolean isConstant(Expression)` detecting Value nodes. Implement inner class `FieldExtractorVisitor` extending ExpressionVisitorAdapter overriding visit(Column) to collect column names into Set.
3. **RuleCheckerOrchestrator TDD:** Write test class `RuleCheckerOrchestratorTest` covering: orchestrator with no checkers returns passed ValidationResult, single enabled checker adds violation correctly, multiple checkers add violations independently, disabled checker is skipped, final risk level is max of all violations (MEDIUM + CRITICAL = CRITICAL), orchestrator preserves checker execution order. Then implement `RuleCheckerOrchestrator` class in validator.rule package with constructor accepting `List<RuleChecker> checkers`. Implement `void orchestrate(SqlContext context, ValidationResult result)` method: iterate through checkers list, for each checker call isEnabled(), if enabled call check(context, result), continue through all enabled checkers regardless of violations (don't short-circuit, collect all issues). Note: final risk level aggregation handled by ValidationResult.addViolation() from Task 1.2.
4. **Integration Testing:** Write integration test `RuleCheckerIntegrationTest` creating mock RuleChecker implementations (MockChecker1 adds LOW violation, MockChecker2 adds HIGH violation, MockChecker3 disabled). Test orchestration: create orchestrator with all three checkers, call orchestrate with test SqlContext, verify result contains violations from checker1 and checker2 only (checker3 skipped), verify final risk level is HIGH (max of LOW and HIGH), verify checker execution order preserved. Test enabled/disabled toggling: disable checker1, re-run orchestration, verify only checker2 violation present. Test empty checker list returns passed result. Run `mvn test` verifying all rule framework tests pass.

### Task 2.2 – NoWhereClauseChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting SQL statements (SELECT/UPDATE/DELETE) completely missing WHERE clause, preventing catastrophic full-table operations that could delete/update entire datasets or return millions of rows causing memory exhaustion.
- **Output:**
  - NoWhereClauseChecker class extending AbstractRuleChecker
  - Comprehensive tests covering all SQL command types and edge cases
  - Configuration enabled/disabled toggle verification
- **Guidance:** This is the most critical check (CRITICAL risk level) as missing WHERE clause in UPDATE/DELETE causes irreversible data loss, while in SELECT causes memory overflow. Checker analyzes parsed Statement AST using JSqlParser to detect null WHERE expressions. INSERT statements don't have WHERE clauses so are deliberately skipped. Edge case: SQL with dummy conditions like "WHERE 1=1" has WHERE clause present (passes this checker) but flagged by DummyConditionChecker. Configuration follows CheckerConfig pattern with enabled flag. Depends on: Task 2.1 Output (AbstractRuleChecker and framework).

- **Basic TDD:** Write test class `NoWhereClauseCheckerTest` with test methods: `testDeleteWithoutWhere_shouldViolate()` (DELETE FROM user → CRITICAL violation), `testUpdateWithoutWhere_shouldViolate()` (UPDATE user SET status=1 → CRITICAL violation), `testSelectWithoutWhere_shouldViolate()` (SELECT * FROM user → CRITICAL violation), `testSelectWithWhere_shouldPass()` (SELECT * FROM user WHERE id=1 → pass), `testInsertStatement_shouldSkip()` (INSERT INTO user VALUES(...) → pass, not applicable). Implement `NoWhereClauseChecker` class in validator.rule.impl package extending AbstractRuleChecker with NoWhereClauseConfig (extends CheckerConfig). Implement check(SqlContext, ValidationResult): call extractWhere(context.getParsedSql()) from AbstractRuleChecker, if WHERE is null and statement is SELECT/UPDATE/DELETE, call result.addViolation(RiskLevel.CRITICAL, "SQL语句缺少WHERE条件,可能导致全表操作", "请添加WHERE条件限制操作范围"). Skip check if statement instanceof Insert.
- **Edge Case Testing:** Write additional test methods: `testWhereWithDummyCondition_shouldPass()` (SELECT * FROM user WHERE 1=1 → pass, has WHERE clause even if dummy), `testComplexWhere_shouldPass()` (SELECT * FROM user WHERE status='active' AND create_time > ? → pass), `testDisabledChecker_shouldSkip()` (create checker with enabled=false, verify no violations added). Run tests ensuring all pass. Verify configuration: create NoWhereClauseConfig with enabled=false, inject into checker, verify isEnabled() returns false and check() is not executed by orchestrator.

### Task 2.3 – DummyConditionChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting invalid/dummy WHERE conditions like "1=1", "true", "'a'='a'" that developers add for dynamic SQL convenience but effectively make condition meaningless, resulting in full-table scans despite apparent WHERE clause presence.
- **Output:**
  - DummyConditionChecker class with pattern-based and AST-based dummy detection
  - DummyConditionConfig supporting default patterns and custom pattern extensions
  - Comprehensive pattern tests including case-insensitive matching and embedded patterns
- **Guidance:** Dummy conditions are HIGH risk as they bypass NoWhereClauseChecker but still cause full-table scans. Detection uses dual approach: (1) string pattern matching for known dummy patterns (configurable), (2) AST traversal detecting constant equality (both sides of EqualsTo are constants). Pattern matching handles variations ("1=1", "1 = 1", "'1'='1'"). AST traversal catches programmatically generated constant comparisons not matching string patterns. Configuration allows custom patterns for organization-specific dummy conditions. Depends on: Task 2.1 Output (AbstractRuleChecker with isDummyCondition and isConstant helpers).

- **Pattern-Based Detection TDD:** Write test class `DummyConditionCheckerTest` with pattern test methods: `testOneEqualsOne_shouldViolate()` (WHERE 1=1), `testOneEqualsOneWithSpaces_shouldViolate()` (WHERE 1 = 1), `testStringConstantEquals_shouldViolate()` (WHERE '1'='1', WHERE 'a'='a'), `testTrue_shouldViolate()` (WHERE true), `testConstantComparison_shouldViolate()` (WHERE 2=2, WHERE 100=100), `testFieldComparison_shouldPass()` (WHERE user_id=1), `testPlaceholder_shouldPass()` (WHERE id=?), `testEmbeddedDummy_shouldViolate()` (WHERE status='active' AND 1=1). Implement `DummyConditionChecker` extending AbstractRuleChecker with `DummyConditionConfig` (extends CheckerConfig, adds List<String> patterns with defaults ["1=1", "1 = 1", "'1'='1'", "true", "'a'='a'"], List<String> customPatterns). In check(): extract WHERE expression, if null return (no WHERE to check), normalize WHERE to string (toLowerCase, replaceAll("\\s+", "")), check if normalized contains any pattern from patterns+customPatterns lists, also call isDummyCondition(where) from AbstractRuleChecker for AST-based constant equality detection. If either detection method triggers, add HIGH violation "检测到无效条件(如 1=1),请移除" with suggestion "使用<where>标签或真实业务条件".
- **Comprehensive Pattern Testing:** Add test methods: `testAllDefaultPatterns_shouldDetect()` (verify all patterns in default list detected), `testCaseInsensitiveMatching_shouldDetect()` (WHERE 1=1, where 1=1, WhErE 1=1 all violate), `testPatternInAndOr_shouldDetect()` (WHERE id>0 OR 1=1), `testCustomPattern_shouldDetect()` (add custom pattern "always_true", test WHERE always_true), `testEmptyPattern_shouldPass()` (DummyConditionConfig with empty patterns should not false-positive). Run comprehensive tests ensuring pattern matching and AST-based detection both work correctly.

### Task 2.4 – BlacklistFieldChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker detecting WHERE conditions using only blacklisted fields (deleted, del_flag, status, is_deleted, etc.) which are typically state flags with low cardinality causing excessive row matches and near-full-table scans.
- **Output:**
  - BlacklistFieldChecker class with configurable blacklist field set
  - BlacklistFieldsConfig supporting field list and wildcard patterns
  - Tests covering blacklist-only, mixed conditions, empty blacklist scenarios
- **Guidance:** Blacklist fields have HIGH risk as they appear to have WHERE clause (pass NoWhereClauseChecker) with real business fields (pass DummyConditionChecker) but still match most table rows. Common blacklist fields: deleted, del_flag, status, is_deleted, enabled, type, create_*, update_*. Checker uses FieldExtractorVisitor from AbstractRuleChecker to extract all field names from WHERE expression, then checks if ALL fields are blacklisted. If any non-blacklist field present, condition is acceptable (mixed conditions allow sufficient selectivity). Wildcard patterns ("create_*") enable flexible blacklist definitions. Depends on: Task 2.1 Output (AbstractRuleChecker with FieldExtractorVisitor and extractFields).

- **Blacklist Detection TDD:** Write test class `BlacklistFieldCheckerTest` with test methods: `testDeletedOnly_shouldViolate()` (WHERE deleted=0), `testStatusOnly_shouldViolate()` (WHERE status='active'), `testMultipleBlacklistFields_shouldViolate()` (WHERE deleted=0 AND enabled=1), `testMixedConditions_shouldPass()` (WHERE id=1 AND deleted=0 - id is not blacklist), `testNonBlacklistOnly_shouldPass()` (WHERE user_id=? AND order_id=?), `testNoWhereClause_shouldPass()` (checker skips, handled by NoWhereClauseChecker). Implement `BlacklistFieldChecker` extending AbstractRuleChecker with `BlacklistFieldsConfig` (extends CheckerConfig, adds Set<String> fields with defaults [deleted, del_flag, status, is_deleted, enabled, type]). In check(): extract WHERE using extractWhere(), if null return (skip), call extractFields(where) to get Set<String> of field names, check if fields.stream().allMatch(f -> isBlacklisted(f, config.getFields())), if true add HIGH violation "WHERE条件只包含黑名单字段" + fields + ",条件过于宽泛" with suggestion "添加主键或业务唯一键字段(如id, user_id)".
- **Edge Case Testing:** Add test methods: `testWildcardPattern_shouldMatch()` (configure blacklist with "create_*", test WHERE create_time > ? and WHERE create_by=? both violate), `testCaseInsensitive_shouldMatch()` (WHERE DELETED=0 and WHERE deleted=0 both violate), `testEmptyBlacklist_shouldPassAll()` (config with empty fields set should not violate any SQL), `testBlacklistPlusDummy_shouldBothViolate()` (WHERE deleted=0 AND 1=1 violates both BlacklistFieldChecker and DummyConditionChecker). Implement isBlacklisted() helper method supporting wildcard matching using regex or simple * pattern. Run tests verifying blacklist detection accuracy.

### Task 2.5 – WhitelistFieldChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement checker enforcing table-specific mandatory WHERE fields (whitelist) to ensure queries include primary keys, tenant IDs, or other high-selectivity fields, providing additional safety layer for critical tables.
- **Output:**
  - WhitelistFieldChecker class with table-specific whitelist configuration
  - WhitelistFieldsConfig supporting byTable map and enforceForUnknownTables flag
  - Tests covering table-specific rules, multi-table scenarios, whitelist pass/fail cases
- **Guidance:** Whitelist checking is MEDIUM risk (less severe than blacklist-only) providing opt-in enforcement for specific tables. Configuration uses Map<String, List<String>> byTable where key is table name and value is list of required fields (any one sufficient). Example: user table requires [id, user_id], order table requires [id, order_id, user_id]. Checker extracts table name and WHERE fields, verifies at least one required field present. Tables not in whitelist map are skipped unless enforceForUnknownTables=true. Useful for multi-tenant systems (enforce tenant_id), GDPR compliance (enforce user_id for personal data), or critical business tables. Depends on: Task 2.1 Output (AbstractRuleChecker with extractTableName and extractFields).

- **Table-Specific Whitelist TDD:** Write test class `WhitelistFieldCheckerTest` with test methods: `testUserTableWithId_shouldPass()` (configure user table whitelist [id, user_id], test SELECT * FROM user WHERE id=? → pass), `testUserTableWithoutRequiredField_shouldViolate()` (SELECT * FROM user WHERE status=? → violate, no id or user_id), `testOrderTableNoWhitelist_shouldPass()` (SELECT * FROM order WHERE status=? → pass, order table not in whitelist), `testMultipleRequiredFieldsAny_shouldPass()` (user table requires [id, user_id], WHERE user_id=? satisfies requirement). Implement `WhitelistFieldChecker` extending AbstractRuleChecker with `WhitelistFieldsConfig` (extends CheckerConfig, adds Set<String> fields for global whitelist optional, Map<String, List<String>> byTable for table-specific whitelist required, boolean enforceForUnknownTables default false). In check(): extract table name using extractTableName(), lookup requiredFields = config.getByTable().get(tableName), if requiredFields null and enforceForUnknownTables false return (skip), extract WHERE fields using extractFields(), check if fields.stream().anyMatch(requiredFields::contains), if false add MEDIUM violation "表" + tableName + "的WHERE条件必须包含以下字段之一:" + requiredFields.
- **Edge Case Testing:** Add test methods: `testJoinMultipleTables_shouldUsePrimaryTable()` (SELECT * FROM user JOIN order ON user.id=order.user_id WHERE order.status=? → extract primary table "user", check against user whitelist), `testTableWithMultipleRequiredFields_anyOneSatisfies()` (user table requires [id, user_id, email], WHERE email=? passes), `testTableNotInWhitelist_shouldPass()` (config table not in byTable map, query passes), `testEmptyRequiredFields_shouldPass()` (table in byTable map with empty list, all queries pass), `testEnforceForUnknownTables_shouldViolate()` (config.enforceForUnknownTables=true, unknown table without required fields violates). Run tests ensuring table-specific whitelist enforcement works correctly.

### Task 2.6 – Pagination Detection Infrastructure │ Agent_Core_Engine_Validation

- **Objective:** Build shared pagination detection infrastructure distinguishing between LOGICAL (dangerous in-memory pagination), PHYSICAL (SQL-level LIMIT pagination), and NONE types, with plugin detection for MyBatis PageHelper and MyBatis-Plus PaginationInnerInterceptor to enable accurate pagination abuse checking.
- **Output:**
  - PaginationType enum (LOGICAL, PHYSICAL, NONE) categorizing pagination approaches
  - PaginationPluginDetector class detecting MyBatis and MyBatis-Plus pagination plugins
  - detectPaginationType() method implementing design 3.3.5 detection logic
  - Comprehensive tests covering all pagination scenario combinations
- **Guidance:** Pagination detection is foundational for Tasks 2.7-2.12 pagination checkers. LOGICAL pagination (RowBounds without plugin) loads entire result set into memory then skips rows in-memory causing OOM. PHYSICAL pagination (LIMIT in SQL or plugin-assisted) performs database-level filtering. Detection logic checks SQL for LIMIT clause, context for RowBounds/IPage parameters, and Spring context for pagination plugin beans. Plugin detection handles both PageHelper (MyBatis) and PaginationInnerInterceptor (MyBatis-Plus). Design section 3.3.5 provides complete detection logic decision tree. Depends on: Task 2.1 Output (RuleChecker framework).

1. **PaginationType Enum TDD:** Write test class `PaginationDetectionTest` with test method `testPaginationTypeEnum()` verifying enum has three constants: LOGICAL (dangerous), PHYSICAL (safe), NONE (no pagination). Implement `PaginationType` enum in `com.footstone.sqlguard.validator.pagination` package with constants LOGICAL, PHYSICAL, NONE. Add Javadoc explaining each type: LOGICAL - RowBounds/IPage without pagination plugin, loads entire result set into memory then skips in-memory (OOM risk); PHYSICAL - LIMIT clause in SQL or pagination plugin enabled, database performs row filtering (safe); NONE - no pagination detected.
2. **Plugin Detection TDD:** Write test class `PaginationPluginDetectorTest` with test methods: `testNoPaginationPlugin_shouldReturnFalse()`, `testPageHelper_shouldReturnTrue()` (MyBatis interceptor list contains PageHelper), `testMpPaginationInnerInterceptor_shouldReturnTrue()` (MybatisPlusInterceptor contains PaginationInnerInterceptor). Implement `PaginationPluginDetector` class with constructor accepting optional `List<Interceptor> mybatisInterceptors` (nullable) and optional `MybatisPlusInterceptor mybatisPlusInterceptor` (nullable). Implement `boolean hasPaginationPlugin()` method: if mybatisPlusInterceptor not null, call getInterceptors() and stream().anyMatch(i -> i instanceof PaginationInnerInterceptor); if mybatisInterceptors not null, stream().anyMatch(i -> i.getClass().getName().contains("PageInterceptor")); return true if either detection succeeds, false otherwise.
3. **Pagination Type Detection TDD:** Write test class `PaginationTypeDetectionTest` with comprehensive test methods: `testRowBoundsWithoutPlugin_shouldBeLogical()` (SqlContext with RowBounds, no plugin configured), `testRowBoundsWithPageHelper_shouldBePhysical()` (RowBounds + plugin), `testIPageWithMpPlugin_shouldBePhysical()` (IPage parameter + PaginationInnerInterceptor), `testLimitInSql_shouldBePhysical()` (SQL contains LIMIT clause), `testPlainQuery_shouldBeNone()` (no LIMIT, no RowBounds, no IPage). Implement `PaginationType detectPaginationType(SqlContext context)` method in PaginationPluginDetector: extract Statement from context.getParsedSql(), check hasLimit = (stmt instanceof Select && ((Select)stmt).getLimit() != null), check hasPageParam = (context.getRowBounds() != null && context.getRowBounds() != RowBounds.DEFAULT) || hasIPageParameter(context.getParams()), call hasPlugin = hasPaginationPlugin(). Apply logic from design 3.3.5: if (hasPageParam && !hasLimit && !hasPlugin) return LOGICAL; if (hasLimit || (hasPageParam && hasPlugin)) return PHYSICAL; else return NONE. Implement helper hasIPageParameter() checking if any param value instanceof IPage.
4. **Comprehensive Scenario Testing:** Write integration test `PaginationScenarioIntegrationTest` with all combinations: test RowBounds(offset=0, limit=10) without plugin configured (expect LOGICAL), test RowBounds with PageHelper interceptor in list (expect PHYSICAL), test IPage parameter with MybatisPlusInterceptor containing PaginationInnerInterceptor (expect PHYSICAL), test SQL "SELECT * FROM user LIMIT 10" (expect PHYSICAL), test SQL "SELECT * FROM user LIMIT 10 OFFSET 5" (expect PHYSICAL), test plain SQL "SELECT * FROM user WHERE id=?" with no pagination params (expect NONE), test RowBounds.DEFAULT (infinite bounds, should be NONE not LOGICAL). Verify detection accuracy 100% across all combinations. Run `mvn test` ensuring all pagination detection tests pass.

### Task 2.7 – Logical Pagination Checker │ Agent_Core_Engine_Validation

- **Objective:** Implement CRITICAL-level checker detecting logical pagination (RowBounds/IPage without pagination plugin), the most dangerous pagination pattern causing entire result sets to load into memory before in-memory row skipping, frequently causing production OOM crashes.
- **Output:**
  - LogicalPaginationChecker class using PaginationDetection infrastructure
  - CRITICAL violation with actionable suggestion to configure pagination plugin
  - Integration tests with actual RowBounds instances and violation detail verification
- **Guidance:** Logical pagination is CRITICAL risk as it bypasses database-level filtering, loading potentially millions of rows into JVM memory. MyBatis RowBounds without PageHelper plugin executes full query, then skips offset rows and limits result in-memory. MyBatis-Plus IPage without PaginationInnerInterceptor has same behavior. Detection leverages Task 2.6 PaginationType infrastructure. Violation message must be urgent and actionable, directing developers to immediate fix (configure plugin). Violation details should include pagination parameters (offset, limit) for debugging. Depends on: Task 2.6 Output (PaginationDetection infrastructure).

- **Logical Pagination Detection TDD:** Write test class `LogicalPaginationCheckerTest` with test methods: `testRowBoundsWithoutPlugin_shouldViolate()` (create SqlContext with RowBounds(100, 20), no plugin, expect CRITICAL violation), `testRowBoundsWithPageHelper_shouldPass()` (RowBounds + PageHelper plugin configured, expect no violation as PHYSICAL pagination), `testNoRowBounds_shouldPass()` (plain query without RowBounds), `testRowBoundsDefault_shouldPass()` (RowBounds.DEFAULT is infinite bounds, not pagination). Implement `LogicalPaginationChecker` class in validator.pagination.impl package extending AbstractRuleChecker with LogicalPaginationConfig (extends CheckerConfig). In check(SqlContext, ValidationResult): call paginationDetector.detectPaginationType(context), if type == PaginationType.LOGICAL, add CRITICAL violation "检测到逻辑分页!将加载全表数据到内存,可能导致OOM" with suggestion "立即配置分页插件:MyBatis-Plus PaginationInnerInterceptor或PageHelper". Extract RowBounds from context.getRowBounds(), add to violation details map: details.put("offset", rowBounds.getOffset()), details.put("limit", rowBounds.getLimit()).
- **Integration Testing:** Write integration test `LogicalPaginationIntegrationTest` with actual RowBounds instances: test various offset/limit combinations (offset=0 limit=10, offset=100 limit=50, offset=10000 limit=100), verify each violates when plugin not configured. Verify violation detail extraction: assert result.getDetails().get("offset") equals expected offset, assert result.getDetails().get("limit") equals expected limit. Test configuration enabled/disabled toggle: create LogicalPaginationConfig with enabled=false, verify checker.isEnabled() returns false and no violations added by orchestrator. Run `mvn test` ensuring logical pagination detection is accurate.

### Task 2.8 – Physical Pagination - No-Condition Check │ Agent_Core_Engine_Validation

- **Objective:** Implement highest-priority CRITICAL-level physical pagination checker detecting unconditioned LIMIT queries (e.g., "SELECT * FROM user LIMIT 100") which still scan entire table despite pagination, with early-return mechanism preventing lower-priority pagination checks when violated.
- **Output:**
  - NoConditionPaginationChecker class with early-return violation handling
  - CRITICAL violation for unconditioned or dummy-conditioned physical pagination
  - Integration tests verifying early-return prevents subsequent pagination checkers
- **Guidance:** No-condition physical pagination is CRITICAL as developers assume LIMIT prevents issues, but database still performs full table scan when WHERE missing, just limits returned rows. This checker has highest priority among physical pagination checks (Tasks 2.8-2.11), implementing early-return to prevent misleading additional violations (deep offset, missing ORDER BY don't matter if query scans entire table anyway). Reuses isDummyCondition() from AbstractRuleChecker to detect "WHERE 1=1" patterns. LIMIT details included in violation report for debugging. Depends on: Task 2.6 Output (PaginationDetection for PHYSICAL type detection).

1. **No-Condition Detection TDD:** Write test class `NoConditionPaginationCheckerTest` with test methods: `testPhysicalPaginationNoWhere_shouldViolate()` (SQL "SELECT * FROM user LIMIT 10" with PHYSICAL type), `testPhysicalPaginationDummyWhere_shouldViolate()` (SQL "SELECT * FROM user WHERE 1=1 LIMIT 10"), `testPhysicalPaginationValidWhere_shouldPass()` (SQL "SELECT * FROM user WHERE id > ? LIMIT 10"), `testLogicalPagination_shouldSkip()` (LOGICAL type should not trigger this checker), `testNoPagination_shouldSkip()` (NONE type should not trigger). Implement `NoConditionPaginationChecker` class in validator.pagination.impl package extending AbstractRuleChecker. In check(): call detectPaginationType(context), if type != PHYSICAL return early (skip), extract WHERE = extractWhere(context.getParsedSql()), check if WHERE == null || isDummyCondition(WHERE), if true extract LIMIT details from SELECT statement and add CRITICAL violation "无条件物理分页,仍会全表扫描" with suggestion "添加业务WHERE条件限制查询范围".
2. **Early Return Implementation:** Implement early-return mechanism in check() method: after detecting no-condition physical pagination violation, set special flag in ValidationResult.details indicating early-return ("earlyReturn", true). Document in Javadoc that this checker should run before other physical pagination checkers (Tasks 2.9-2.11) to prevent misleading violations. Include LIMIT details in violation: extract limit.getRowCount() and limit.getOffset() (if present), add to violation details for debugging context.
3. **Integration Testing:** Write integration test `NoConditionPaginationIntegrationTest` verifying early-return behavior: create orchestrator with NoConditionPaginationChecker (Task 2.8) + DeepPaginationChecker (Task 2.9) + MissingOrderByChecker (Task 2.11), execute SQL "SELECT * FROM user LIMIT 10000" (no WHERE, deep offset), verify only NoConditionPaginationChecker violation present (early-return prevents deep offset check). Test PHYSICAL pagination with no WHERE (violate), test PHYSICAL with dummy WHERE "1=1" (violate), test PHYSICAL with valid WHERE "id > 0" (pass). Verify CRITICAL risk level. Run tests ensuring early-return mechanism works correctly.

### Task 2.9 – Physical Pagination - Deep Offset Check │ Agent_Core_Engine_Validation

- **Objective:** Implement MEDIUM-level checker detecting deep pagination (high OFFSET values in LIMIT queries) causing database to scan and skip large row counts before returning results, degrading performance significantly as offset increases.
- **Output:**
  - DeepPaginationChecker class with offset calculation supporting multiple LIMIT syntaxes
  - PaginationAbuseConfig.maxOffset threshold configuration (default 10000)
  - Boundary condition tests verifying threshold enforcement accuracy
- **Guidance:** Deep pagination is MEDIUM risk (less severe than no-condition) as query is properly filtered by WHERE but requires database to scan offset+limit rows, discarding first offset rows. Common when users navigate to high page numbers. Example: OFFSET 100000 LIMIT 20 scans 100020 rows, returns 20. Performance degrades linearly with offset. Solution is cursor-based pagination (WHERE id > lastId). Checker handles both LIMIT syntaxes: "LIMIT n OFFSET m" and "LIMIT m,n" (MySQL). Threshold configurable via PaginationAbuseConfig.maxOffset (default 10000). Depends on: Task 2.6 Output (PHYSICAL type detection), Task 2.8 must run first (early-return skips this checker if no-condition).

1. **Deep Offset Detection TDD:** Write test class `DeepPaginationCheckerTest` with test methods: `testOffsetBelowThreshold_shouldPass()` (LIMIT 20 OFFSET 9999 with maxOffset=10000), `testOffsetAboveThreshold_shouldViolate()` (LIMIT 20 OFFSET 10001 with maxOffset=10000), `testOffsetEqualsThreshold_shouldPass()` (LIMIT 20 OFFSET 10000 with maxOffset=10000), `testNoConditionPagination_shouldSkipThisChecker()` (if Task 2.8 early-returned). Implement `DeepPaginationChecker` class extending AbstractRuleChecker with PaginationAbuseConfig containing maxOffset field (default 10000). In check(): call detectPaginationType(), if type != PHYSICAL return, check if ValidationResult.details contains "earlyReturn" (Task 2.8 triggered, skip), extract Limit from SELECT statement, calculate offset.
2. **Offset Calculation:** Implement offset calculation supporting multiple LIMIT syntaxes: if limit.getOffset() != null, offset = limit.getOffset().getValue() (explicit OFFSET syntax "LIMIT n OFFSET m"); else if limit.getRowCount() and limit.getOffsetJdbcParameter() exist, use MySQL syntax "LIMIT offset,rowCount" where getOffsetJdbcParameter() provides offset; else offset = 0 (no offset, just LIMIT n). Compare calculated offset against config.getMaxOffset(), if offset > maxOffset add MEDIUM violation "深分页offset=" + offset + ",需扫描并跳过" + offset + "行数据,性能较差" with suggestion "建议使用游标分页(WHERE id > lastId)避免深度offset".
3. **Boundary Testing:** Write boundary condition tests: `testOffsetMaxMinusOne_shouldPass()` (offset = maxOffset - 1), `testOffsetMaxPlusOne_shouldViolate()` (offset = maxOffset + 1), `testLimitOffsetSyntax_shouldCalculateCorrectly()` (LIMIT 20 OFFSET 5000), `testLimitCommaSyntax_shouldCalculateCorrectly()` (LIMIT 5000,20 MySQL syntax), `testOnlyLimitNoOffset_shouldPassWithZeroOffset()` (LIMIT 100). Test configuration toggle: disabled checker should not add violations. Verify MEDIUM risk level. Run `mvn test` ensuring offset calculation and threshold checking work correctly.

### Task 2.10 – Physical Pagination - Large PageSize Check │ Agent_Core_Engine_Validation

- **Objective:** Implement MEDIUM-level checker detecting excessively large pageSize values in LIMIT queries (e.g., LIMIT 10000) causing single query to return massive datasets potentially overwhelming application memory or network bandwidth.
- **Output:**
  - LargePageSizeChecker class extracting page size from LIMIT clause
  - PaginationAbuseConfig.maxPageSize threshold configuration (default 1000)
  - Tests covering both LIMIT syntaxes and boundary conditions
- **Guidance:** Large pageSize is MEDIUM risk as properly filtered query (has WHERE, reasonable offset) still returns too many rows per request. Common when developers set pagination but use unreasonably high page sizes. Example: LIMIT 5000 returns 5000 rows consuming significant memory and bandwidth. Checker extracts pageSize from LIMIT clause handling both syntaxes: "LIMIT n" extracts n as pageSize, "LIMIT m,n" extracts n as pageSize (m is offset). Threshold configurable via PaginationAbuseConfig.maxPageSize (default 1000 rows). Independent check from deep offset (Task 2.9), both can trigger on same SQL. Depends on: Task 2.6 Output (PHYSICAL type detection).

1. **PageSize Extraction TDD:** Write test class `LargePageSizeCheckerTest` with test methods: `testPageSizeBelowThreshold_shouldPass()` (LIMIT 999 with maxPageSize=1000), `testPageSizeAboveThreshold_shouldViolate()` (LIMIT 1001 with maxPageSize=1000), `testPageSizeEqualsThreshold_shouldPass()` (LIMIT 1000 with maxPageSize=1000). Implement `LargePageSizeChecker` class extending AbstractRuleChecker using PaginationAbuseConfig.maxPageSize field (default 1000). In check(): detectPaginationType(), if != PHYSICAL return, extract Limit from SELECT, calculate pageSize.
2. **PageSize Calculation:** Implement pageSize extraction supporting both LIMIT syntaxes: if limit.getRowCount() != null, pageSize = limit.getRowCount().getValue() (works for both "LIMIT n" and "LIMIT m,n" syntaxes as getRowCount() returns the row count portion); else pageSize = 0 (shouldn't happen if LIMIT exists). Compare pageSize against config.getMaxPageSize(), if pageSize > maxPageSize add MEDIUM violation "pageSize=" + pageSize + "过大,单次查询数据量过多" with suggestion "建议降低pageSize到" + maxPageSize + "以内,避免单次返回过多数据".
3. **Testing:** Write tests: `testPageSizeMaxMinusOne_shouldPass()` (999 vs 1000), `testPageSizeMaxPlusOne_shouldViolate()` (1001 vs 1000), `testLimitOnlySyntax_shouldExtractCorrectly()` (LIMIT 500), `testLimitCommaSyntax_shouldExtractRowCount()` (LIMIT 100,500 extracts 500 as pageSize). Test configuration toggle. Verify MEDIUM risk level. Run `mvn test` ensuring pageSize extraction and threshold checking work.

### Task 2.11 – Physical Pagination - Missing ORDER BY Check │ Agent_Core_Engine_Validation

- **Objective:** Implement LOW-level checker detecting physical pagination queries lacking ORDER BY clause, causing unstable result ordering across pages (same query may return different row orders on different executions, pagination becomes non-deterministic).
- **Output:**
  - MissingOrderByChecker class verifying ORDER BY presence in paginated SELECT
  - LOW violation indicating result instability issue
  - Simple tests for ORDER BY presence/absence with configuration toggle
- **Guidance:** Missing ORDER BY is LOW risk (least severe pagination issue) as query works but results unpredictable. Database default ordering is not guaranteed stable across executions or version changes. Without ORDER BY, paginating "page 2" may show rows from "page 1" on subsequent request or vice versa. Critical for user-facing pagination where consistency matters. Simple check: if PHYSICAL pagination detected and SELECT.getOrderByElements() is null or empty, violate. Configuration allows disabling if organization accepts non-deterministic pagination. Depends on: Task 2.6 Output (PHYSICAL type detection).

- **ORDER BY Detection TDD:** Write test class `MissingOrderByCheckerTest` with test methods: `testPaginationWithOrderBy_shouldPass()` (SELECT * FROM user WHERE id>0 ORDER BY id LIMIT 10), `testPaginationWithoutOrderBy_shouldViolate()` (SELECT * FROM user WHERE id>0 LIMIT 10), `testNoPagination_shouldSkip()` (plain query without LIMIT). Implement `MissingOrderByChecker` class extending AbstractRuleChecker with MissingOrderByConfig (extends CheckerConfig). In check(): detectPaginationType(), if != PHYSICAL return, cast statement to SELECT, call select.getOrderByElements(), if orderByElements == null || orderByElements.isEmpty() add LOW violation "分页查询缺少ORDER BY,结果顺序不稳定" with suggestion "添加ORDER BY子句确保分页结果顺序稳定".
- **Testing:** Write tests: `testMultipleOrderByColumns_shouldPass()` (ORDER BY create_time DESC, id ASC), `testSingleOrderBy_shouldPass()` (ORDER BY id), `testNoOrderBy_shouldViolate()`, `testDisabledChecker_shouldSkip()`. Verify LOW risk level. Test configuration toggle. Run `mvn test` ensuring ORDER BY detection works.

### Task 2.12 – NoPaginationChecker Implementation │ Agent_Core_Engine_Validation

- **Objective:** Implement comprehensive checker detecting SELECT queries completely lacking pagination limits (no LIMIT, no RowBounds, no IPage), with risk stratification (CRITICAL for no WHERE, HIGH for blacklist-only WHERE, MEDIUM for others), whitelist exemptions for known-safe queries, and unique key detection.
- **Output:**
  - NoPaginationChecker class with hasPaginationLimit(), assessNoPaginationRisk(), isWhitelisted(), hasUniqueKeyCondition() methods
  - NoPaginationConfig with whitelistMapperIds, whitelistTables, uniqueKeyFields, enforceForAllQueries
  - Comprehensive tests covering all risk levels and whitelist exemptions
- **Guidance:** No pagination is variable risk depending on WHERE clause: CRITICAL if no WHERE (returns entire table), HIGH if blacklist-only WHERE (returns most rows), MEDIUM if enforceForAllQueries enabled (preventive measure). Whitelist provides escape hatch for legitimate full-table queries (config tables, getById methods, count queries). Unique key detection exempts single-row queries (WHERE id=123). Risk stratification ensures most dangerous scenarios flagged highest. Whitelist supports wildcards (*.getById, *.count*) for pattern matching. Depends on: Task 2.6 Output (pagination detection to verify no pagination), Task 2.4 for blacklist field detection logic.

1. **Pagination Detection TDD:** Write test class `NoPaginationCheckerTest` with test method `testHasPaginationLimit()` covering: SQL with LIMIT clause (true), SqlContext with RowBounds + pagination plugin (true), SqlContext with IPage + plugin (true), plain query with none of above (false). Implement `hasPaginationLimit(Select select, SqlContext context)` method in NoPaginationChecker: check select.getLimit() != null, check context.getRowBounds() != null && RowBounds.DEFAULT != context.getRowBounds() && pluginDetector.hasPaginationPlugin(), check hasIPageParameter(context.getParams()) && pluginDetector.hasPaginationPlugin(), return true if any condition met.
2. **Risk Stratification TDD:** Write test method `testAssessNoPaginationRisk()` covering three risk levels: no WHERE clause (CRITICAL "SELECT查询无条件且无分页限制,可能返回全表数据导致内存溢出"), blacklist-only WHERE (HIGH "SELECT查询条件只有黑名单字段{fields}且无分页,可能返回大量数据"), normal WHERE with enforceForAllQueries=true (MEDIUM "SELECT查询缺少分页限制,建议添加LIMIT或使用分页"). Implement `assessNoPaginationRisk(Select, SqlContext, ValidationResult)`: extract WHERE, if WHERE == null || isDummyCondition(WHERE) add CRITICAL violation; else extract fields, if allBlacklisted(fields) add HIGH violation; else if config.isEnforceForAllQueries() add MEDIUM violation.
3. **Whitelist Matching TDD:** Write test method `testIsWhitelisted()` covering: mapperId matching wildcard pattern "*.getById" (true), table name in whitelistTables (true), WHERE contains unique key field with equals (true), none of above (false). Implement `isWhitelisted(SqlContext)`: check mapperId against config.getWhitelistMapperIds() using wildcard matching, check extractTableName() against config.getWhitelistTables(), call hasUniqueKeyCondition(), return true if any match.
4. **Unique Key Detection TDD:** Write test method `testHasUniqueKeyCondition()` covering: WHERE id=? (true), WHERE id=123 (true), WHERE user_id=? with user_id in uniqueKeyFields config (true), WHERE status=? (false). Implement `hasUniqueKeyCondition(SqlContext)`: extract WHERE expression, extract fields, check if any field in ["id"] + config.getUniqueKeyFields(), if found check if isEqualsCondition(where, field) using helper traversing Expression tree looking for EqualsTo with field on left side, return true if unique key with equals condition found.
5. **Integration Testing:** Write comprehensive integration test covering all scenarios: no WHERE + no pagination (CRITICAL), blacklist-only WHERE + no pagination (HIGH), normal WHERE + no pagination + enforceForAllQueries (MEDIUM), whitelisted by mapperId pattern (pass), whitelisted by table name (pass), whitelisted by unique key WHERE id=? (pass), RowBounds + plugin present (pass, has pagination), LIMIT clause present (pass, has pagination). Verify interaction with LogicalPaginationChecker: RowBounds without plugin should trigger LogicalPaginationChecker not NoPaginationChecker. Run `mvn test` ensuring all risk levels and exemptions work correctly.

### Task 2.13 – DefaultSqlSafetyValidator Assembly │ Agent_Core_Engine_Validation

- **Objective:** Assemble complete validation engine coordinating all rule checkers (Tasks 2.2-2.12), implementing parse-once SQL parsing with JSqlParser facade, SQL deduplication filter preventing redundant validation, and end-to-end integration with performance benchmarking achieving <5% overhead target.
- **Output:**
  - DefaultSqlSafetyValidator class implementing SqlSafetyValidator interface
  - SqlDeduplicationFilter with ThreadLocal LRU cache and configurable TTL
  - Comprehensive integration tests with multi-rule violations and parse failure scenarios
  - JMH performance benchmark demonstrating <5% overhead target achievement
- **Guidance:** This is final assembly task integrating all validation components into production-ready engine. SqlSafetyValidator interface defines public contract used by interceptors (Phase 4). Deduplication filter prevents same SQL being validated multiple times when multiple interception layers enabled (MyBatis + JDBC). Parse-once optimization parses SQL once via JSqlParserFacade, stores in SqlContext.parsedSql, all checkers reuse parsed AST. RuleCheckerOrchestrator from Task 2.1 manages checker execution. Performance critical: validation must add <5% overhead to SQL execution (measured via JMH). **Config Usage Note:** Checker constructors require config classes from `com.footstone.sqlguard.validator.rule.impl` package (runtime configs extending CheckerConfig), NOT from `com.footstone.sqlguard.config` package (YAML POJOs). See Dual-Config Pattern doc for details. Depends on: Task 2.1 (orchestrator), Tasks 2.2-2.12 (all checkers), Phase 1 Task 1.4 (JSqlParser facade).

1. **Interface Implementation TDD:** Write test class `DefaultSqlSafetyValidatorTest` with test method `testValidateInterface()` verifying SqlSafetyValidator contract: validate(SqlContext) returns ValidationResult, result contains violations from enabled checkers, result.passed = false when violations present. Implement `SqlSafetyValidator` interface in com.footstone.sqlguard.validator package with single method `ValidationResult validate(SqlContext context)`. Implement `DefaultSqlSafetyValidator` class in same package with constructor accepting JSqlParserFacade facade and List<RuleChecker> checkers. Store as final fields. In validate(): call deduplicationFilter.shouldCheck(), if false return ValidationResult.pass(), proceed with validation.
2. **Deduplication Filter TDD:** Write test class `SqlDeduplicationFilterTest` with test methods: `testFirstCheck_shouldAllow()`, `testSameS SQLWithinTTL_shouldSkip()` (same SQL checked twice within 100ms TTL, second returns false), `testSameSQLAfterTTL_shouldAllow()` (same SQL after TTL expires, returns true), `testDifferentSQL_shouldAllow()`, `testClearThreadCache_shouldClearCache()`. Implement `SqlDeduplicationFilter` class with ThreadLocal<LRUCache<String, Long>> field initialized with LRU cache of configurable size (default 1000). Implement `boolean shouldCheck(String sql)`: compute MD5 hash of sql as key (or use sql directly if short), get cache from ThreadLocal, check cache.get(key), if value exists and (System.currentTimeMillis() - value) < config.getTtlMs(), return false (skip, recently checked), else put(key, currentTimeMillis) and return true. Implement static `clearThreadCache()` calling ThreadLocal.remove() for cleanup.
3. **Parse-Once Integration TDD:** Write test class `ParseOnceIntegrationTest` verifying: parsedSql null in context triggers facade.parse() call, parsedSql set in context after parse, all checkers receive same parsedSql instance (no re-parsing), parse failure with fail-fast config throws SqlParseException, parse failure with lenient config logs warning and returns pass. Implement parse-once logic in validate(): check if context.getParsedSql() == null, if null call Statement stmt = facade.parse(context.getSql()), call context.setParsedSql(stmt), if facade.parse() throws SqlParseException call handleParseFailure(context, exception): if failFast throw exception, else log.warn() and return ValidationResult.pass(). After parse completes, proceed to checker orchestration.
4. **Orchestrator Integration:** Integrate RuleCheckerOrchestrator from Task 2.1: create ValidationResult result = new ValidationResult(), call orchestrator.orchestrate(context, result), return result. Orchestrator handles checker iteration, enabled/disabled filtering, violation aggregation. Ensure all checkers (Tasks 2.2-2.12: NoWhereClauseChecker, DummyConditionChecker, BlacklistFieldChecker, WhitelistFieldChecker, LogicalPaginationChecker, NoConditionPaginationChecker, DeepPaginationChecker, LargePageSizeChecker, MissingOrderByChecker, NoPaginationChecker) injected in constructor List<RuleChecker>.
5. **End-to-End Integration & Performance Testing:** Write integration test `SqlSafetyValidatorIntegrationTest` with realistic SQL samples: test SQL violating multiple rules (no WHERE + no pagination + missing ORDER BY, verify all violations reported with correct risk levels aggregated to highest), test SQL with no violations (proper WHERE + pagination + ORDER BY, verify passed=true), test parse failure (invalid SQL syntax, verify fail-fast throws exception or lenient returns pass), test deduplication (validate same SQL twice, second call skips validation, verify cache works), test all checkers enabled (verify all 10 checkers execute). Write JMH micro-benchmark `SqlValidationBenchmark`: establish baseline (parse SQL + extract WHERE without validation), measure validation overhead (full validate() call with all checkers), calculate overhead percentage, verify <5% overhead target from design section 9.1. Run `mvn test` and `mvn test -Pbenchmark` ensuring all integration tests pass and performance target met.

## Phase 3: Static Code Scanner - Agent_Static_Scanner

### Task 3.1 – Scanner Core Framework & Orchestration │ Agent_Static_Scanner

- **Objective:** Establish complete static analysis framework providing core data models (SqlEntry, ScanReport, ScanContext), parser interfaces (SqlParser, WrapperScanner), and orchestration engine (SqlScanner) that coordinates XML/annotation/wrapper scanning to produce comprehensive scan reports for dangerous SQL detection.
- **Output:**
  - SqlEntry class capturing SQL location metadata (source type, filePath, mapperId, sqlType, rawSql, lineNumber, dynamic flag, sqlVariants list for dynamic SQL)
  - ScanReport class aggregating scan results (SqlEntry list, WrapperUsage list, statistics summary)
  - ScanContext class encapsulating scan configuration (projectPath, SqlGuardConfig)
  - SqlParser interface defining parse contract for XML and annotation parsers
  - WrapperScanner interface defining scan contract for QueryWrapper detection
  - WrapperUsage class tracking MyBatis-Plus wrapper usage locations requiring runtime validation
  - SqlScanner orchestration class coordinating all parsers and report generation
  - Comprehensive unit tests validating data models, interfaces, and orchestration logic
- **Guidance:** This framework is foundational for all static scanning tasks (Tasks 3.2-3.7). SqlEntry supports both static SQL (XML/annotations) and dynamic SQL (MyBatis variants) through sqlVariants list. ScanReport provides unified structure for console and HTML report generation (Task 3.6). SqlScanner implements orchestration pattern accepting all parsers via constructor injection, enabling extensibility for future parser types. Parser interfaces define uniform contracts allowing polymorphic scanner execution. WrapperUsage captures QueryWrapper locations for runtime interception coordination, as static analysis cannot determine dynamic conditions. Follow TDD methodology with comprehensive tests before implementation. Depends on: None (foundational task).

1. **Data Model TDD:** Write test class `SqlEntryTest` covering: creation with all fields, source type validation (XML/ANNOTATION/WRAPPER), dynamic flag toggling, sqlVariants list manipulation, equals/hashCode based on filePath+lineNumber. Write test class `ScanReportTest` covering: adding SqlEntry items, adding WrapperUsage items, statistics calculation (total counts, violation counts by risk level), empty report handling. Write test class `ScanContextTest` covering: construction with projectPath and config, null handling, immutability verification. Then implement `SqlEntry` class in `com.footstone.sqlguard.scanner.model` package with fields: SourceType source (enum: XML, ANNOTATION, WRAPPER), String filePath, String mapperId, SqlCommandType sqlType, String rawSql, int lineNumber, boolean dynamic, List<String> sqlVariants (ArrayList). Implement `ScanReport` class with fields: List<SqlEntry> entries, List<WrapperUsage> wrapperUsages, Map<String, Integer> statistics. Implement `ScanContext` class with fields: Path projectPath, SqlGuardConfig config. Add validation: filePath and rawSql cannot be null/empty, lineNumber > 0.

2. **Parser Interface TDD:** Write test class `SqlParserInterfaceTest` with mock implementations verifying: parse(File) returns List<SqlEntry>, parse handles file not found, parse handles malformed XML/Java gracefully. Write test class `WrapperScannerInterfaceTest` with mock implementations verifying: scan(File) returns List<WrapperUsage>, scan handles directory traversal, scan handles parse errors. Then define `SqlParser` interface in `com.footstone.sqlguard.scanner.parser` package with method: `List<SqlEntry> parse(File file) throws IOException, ParseException`. Define `WrapperScanner` interface with method: `List<WrapperUsage> scan(File projectRoot) throws IOException`. Implement `WrapperUsage` class in scanner.model with fields: String filePath, String methodName, int lineNumber, String wrapperType (QueryWrapper/LambdaQueryWrapper/UpdateWrapper/LambdaUpdateWrapper), boolean needsRuntimeCheck (default true indicating static analysis insufficient).

3. **Orchestration TDD:** Write test class `SqlScannerTest` covering: scan with all parsers returns complete ScanReport, scan aggregates entries from XML and annotation parsers, scan aggregates wrapper usages from wrapper scanner, scan calculates statistics (total SQL count, dynamic SQL count, wrapper count), scan handles empty project (no SQL files), scan handles parser exceptions gracefully. Then implement `SqlScanner` class in `com.footstone.sqlguard.scanner` package with constructor accepting: `XmlMapperParser xmlParser`, `AnnotationParser annotationParser`, `QueryWrapperScanner wrapperScanner`, `SqlRiskEvaluator evaluator` (all injected dependencies). Implement `scan(ScanContext context)` method from design 6.2: discover all relevant files (*.xml under src/main/resources for MyBatis mappers, *.java under src/main/java for annotations/wrappers), delegate XML files to xmlParser.parse(), delegate Java files to annotationParser.parse() for annotation extraction, delegate project root to wrapperScanner.scan() for wrapper detection, collect all SqlEntry results into ScanReport.entries list, collect all WrapperUsage into ScanReport.wrapperUsages list, calculate statistics: total count, violation count by risk level (after evaluator.evaluate() on each entry), wrapper usage count, return populated ScanReport.

4. **Integration Testing:** Write integration test `SqlScannerIntegrationTest` with mock parser implementations: create MockXmlMapperParser returning predefined SqlEntry list, create MockAnnotationParser returning predefined SqlEntry list, create MockWrapperScanner returning predefined WrapperUsage list, create MockSqlRiskEvaluator assigning risk levels. Test orchestration: create SqlScanner with all mock parsers, create ScanContext with test project path, call scan(), verify ScanReport contains entries from all parsers, verify statistics accurate (counts match mock data), verify orchestrator handled all parser results correctly. Test error handling: mock parser throwing IOException, verify SqlScanner handles gracefully without crashing, verify error logged. Run `mvn test` ensuring all framework tests pass.

### Task 3.2 – XML Mapper Parser Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 32 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_2_XML_Mapper_Parser_Implementation.md`

- **Objective:** Implement comprehensive MyBatis XML Mapper parser extracting SQL statements from mapper XML files, detecting dynamic tags (if/where/foreach/choose), generating SQL variants for dynamic scenarios, and producing SqlEntry instances with accurate line numbers and mapperId references for static analysis.
- **Output:**
  - XmlMapperParser class implementing SqlParser interface from Task 3.1
  - DOM4J-based XML parsing extracting namespace and SQL statement tags (select/update/delete/insert)
  - Dynamic tag detection identifying MyBatis control flow tags (if, where, foreach, choose/when/otherwise, set, trim, bind)
  - SQL variant generation for dynamic SQL producing representative execution scenarios
  - Comprehensive tests with sample MyBatis XML files covering static and dynamic SQL patterns
- **Guidance:** XML Mappers are primary SQL source in MyBatis applications requiring accurate parsing with line number preservation for violation reporting. DOM4J 2.x provides SAX-based parsing with line number access via Element.getData(). MapperId format is "namespace.statementId" matching MyBatis runtime convention. Dynamic tags require special handling: static portions extracted as rawSql, variants generated for different execution paths (Task 3.5 generates detailed variants). This parser feeds SqlEntry instances to validation engine allowing pre-deployment SQL safety checks. Follow TDD with comprehensive XML test fixtures covering nested tags, CDATA sections, multi-line SQL, comments. Depends on: Task 3.1 Output (SqlParser interface and SqlEntry class).

1. **Basic XML Parsing TDD:** Write test class `XmlMapperParserTest` with test methods: `testSimpleSelect_shouldCreateSqlEntry()` (parse simple SELECT statement, verify SqlEntry created with correct mapperId, SQL, line number), `testMultipleStatements_shouldCreateMultipleEntries()` (parse XML with select/update/delete/insert, verify all extracted), `testNamespaceExtraction_shouldPrefixMapperId()` (verify namespace attribute used as mapperId prefix), `testLineNumberExtraction_shouldBeAccurate()` (verify line numbers match XML file positions). Add DOM4J 2.1.4 dependency to sql-scanner-core module POM. Implement `XmlMapperParser` class in `com.footstone.sqlguard.scanner.parser.impl` package implementing SqlParser interface. Implement `parse(File file)` method: read file with DOM4J SAXReader, get Document root element, extract namespace attribute for mapperId prefix, call selectNodes("//select|//update|//delete|//insert") to get all SQL statement elements, iterate through elements extracting: id attribute, tag name for SqlCommandType, text content for rawSql (trimmed), line number from element.getData(), create SqlEntry(source=XML, filePath=file.getAbsolutePath(), mapperId=namespace+"."+id, sqlType=commandType, rawSql=sql, lineNumber=lineNum), add to result list, return List<SqlEntry>.

2. **Dynamic Tag Detection TDD:** Write test class `DynamicTagDetectionTest` with test methods: `testIfTag_shouldSetDynamicFlag()` (XML with <if> tag should mark SqlEntry.dynamic=true), `testWhereTag_shouldSetDynamicFlag()` (XML with <where> tag should mark dynamic), `testForeachTag_shouldSetDynamicFlag()` (XML with <foreach> should mark dynamic), `testChooseWhenTag_shouldSetDynamicFlag()` (XML with <choose><when> should mark dynamic), `testStaticSQL_shouldNotBeDynamic()` (XML without dynamic tags should have dynamic=false), `testNestedDynamicTags_shouldDetect()` (nested if inside where should detect). Implement `hasDynamicTags(Element element)` method in XmlMapperParser: recursively check element and descendants for dynamic tag names using Set<String> dynamicTagNames = [\"if\", \"where\", \"foreach\", \"choose\", \"when\", \"otherwise\", \"set\", \"trim\", \"bind\"], call element.selectNodes(\".//\" + tagName) for each dynamic tag, return true if any found. Call hasDynamicTags() during parse() and set SqlEntry.dynamic flag accordingly.

3. **Variant Generation TDD:** Write test class `VariantGenerationTest` with test methods: `testIfTagVariants_shouldGenerateTwoScenarios()` (if tag generates variant with condition true and condition false), `testForeachVariants_shouldGenerateRepresentative()` (foreach generates empty/single/multiple item variants), `testChooseVariants_shouldGeneratePerBranch()` (choose generates one variant per when branch plus otherwise). Implement `generateVariants(Element element)` method from design 6.3: if element has <if> child, generate 2 variants (include content, exclude content), if element has <foreach> child, generate 3 variants (empty collection removes clause, single item no separator, multiple items with separators), if element has <choose> child, generate variant per <when> branch plus <otherwise> branch. For simple cases return List<String> sqlVariants with representative SQL strings. Call generateVariants() during parse() and populate SqlEntry.sqlVariants list. Keep generation simple (representative scenarios, not exhaustive combinations).

4. **Comprehensive Testing:** Write integration test `XmlMapperParserIntegrationTest` with sample XML files in src/test/resources/mappers: simple-static.xml (plain SQL without dynamic tags), if-condition.xml (SQL with <if test="...">), foreach-loop.xml (SQL with <foreach collection="list">), where-tag.xml (SQL with <where> wrapper), nested-dynamic.xml (nested if inside where inside foreach), complex-real-world.xml (realistic MyBatis mapper with multiple statements and dynamic tags). For each test file: parse with XmlMapperParser, verify correct number of SqlEntry instances created, verify line numbers accurate (match actual XML positions), verify mapperId generation correct (namespace.id format), verify dynamic flag set correctly, verify sqlVariants populated for dynamic SQL. Test edge cases: CDATA sections (SQL wrapped in <![CDATA[...]]>), XML comments (should be ignored), multi-line SQL (preserve line breaks), special characters in SQL (quotes, <, >, &). Run `mvn test` ensuring all XML parsing tests pass.

### Task 3.3 – Java Annotation Parser Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 18 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_3_Annotation_Parser_Implementation.md`

- **Objective:** Implement MyBatis annotation-based SQL parser extracting SQL from @Select, @Update, @Delete, @Insert annotations in Java mapper interfaces, handling multiple annotation syntaxes (value="" vs array {"sql"}), generating SqlEntry instances with accurate source locations for static analysis of annotation-defined SQL statements.
- **Output:**
  - AnnotationParser class implementing SqlParser interface from Task 3.1
  - JavaParser 3.x-based Java source parsing traversing method declarations
  - Annotation detection for MyBatis SQL annotations (@Select/@Update/@Delete/@Insert)
  - SQL extraction handling value parameter variations and multi-line strings
  - MapperId generation using className.methodName convention
  - Edge case handling for escaped quotes, concatenated strings, non-SQL annotations
  - Comprehensive tests with sample Java mapper interfaces covering annotation variations
- **Guidance:** Annotation-based mappers are increasingly common in modern MyBatis applications as alternative to XML, requiring robust parsing for complete SQL coverage. JavaParser 3.x provides complete Java AST allowing precise annotation extraction with source positions. SQL in annotations typically uses value="" parameter but MyBatis supports array syntax {"line1", "line2"} for multi-line SQL requiring concatenation during extraction. Line number from annotation.getBegin() provides violation reporting context. This parser complements XmlMapperParser (Task 3.2) enabling comprehensive static analysis across both SQL definition approaches. Follow TDD with diverse annotation test fixtures. Depends on: Task 3.1 Output (SqlParser interface and SqlEntry class).

- **Annotation Parsing TDD:** Write test class `AnnotationParserTest` with test methods: `testSelectAnnotation_shouldExtractSql()` (parse @Select(\"SELECT * FROM user WHERE id=?\") returns SqlEntry), `testUpdateAnnotation_shouldExtractSql()` (parse @Update), `testDeleteAnnotation_shouldExtractSql()` (parse @Delete), `testInsertAnnotation_shouldExtractSql()` (parse @Insert), `testMultipleAnnotatedMethods_shouldExtractAll()` (interface with 5 annotated methods returns 5 SqlEntry), `testNonSqlAnnotation_shouldSkip()` (@Param, @ResultMap annotations ignored). Add JavaParser 3.25.7 dependency to sql-scanner-core module POM. Implement `AnnotationParser` class in `com.footstone.sqlguard.scanner.parser.impl` package implementing SqlParser interface. Implement `parse(File file)` method from design 6.4: parse Java file with `CompilationUnit cu = StaticJavaParser.parse(file)`, extract class name via cu.findFirst(ClassOrInterfaceDeclaration.class).get().getNameAsString() for mapperId prefix, call cu.findAll(MethodDeclaration.class) to get all methods, iterate through methods calling method.getAnnotations(), for each annotation check if annotation.getNameAsString() matches \"Select\"|\"Update\"|\"Delete\"|\"Insert\" (case-sensitive MyBatis annotation names), extract SQL from annotation value parameter, determine SqlCommandType from annotation name, get line number from annotation.getBegin().get().line, create SqlEntry(source=ANNOTATION, filePath=file.getAbsolutePath(), mapperId=className+\".\"+method.getNameAsString(), sqlType=commandType, rawSql=extractedSql, lineNumber=lineNum, dynamic=false), add to result list.

- **SQL Extraction Logic:** Implement `extractSqlFromAnnotation(AnnotationExpr annotation)` helper method handling multiple syntaxes: check if annotation has single member (value="...") vs named member (value="..."), handle both NormalAnnotationExpr and SingleMemberAnnotationExpr from JavaParser, extract value as StringLiteralExpr for simple case, extract value as ArrayInitializerExpr for array syntax {"line1", "line2"}, concatenate array elements with space separator for multi-line SQL, remove quotes from string literals, handle escaped quotes (\" → "), trim whitespace, return extracted SQL string. Handle annotations with additional parameters (@Select(value="...", timeout=30)) by extracting only value parameter. Log warning if value parameter missing or not string/array type.

- **Edge Case Testing:** Write comprehensive tests: `testMultiLineSqlString_shouldConcatenate()` (@Select(value={"SELECT * FROM user", "WHERE id=?"}) concatenates to single SQL), `testEscapedQuotes_shouldHandle()` (@Select(\"SELECT * FROM user WHERE name='O\\'Brien'\") preserves quotes), `testAnnotationWithOtherParams_shouldExtractValue()` (@Select(value="...", timeout=30, fetchSize=100) extracts only value), `testNonSqlAnnotation_shouldSkip()` (@Param(\"id\"), @ResultMap(\"userMap\") do not create SqlEntry), `testLineNumberAccuracy_shouldMatch()` (verify annotation.getBegin().line matches actual Java file line), `testStringConcatenation_shouldHandle()` (@Select(\"SELECT * \" + \"FROM user\") extracts concatenated SQL if possible, or logs warning if too complex). Test with src/test/resources/mappers sample Java files: SimpleMapper.java (basic @Select/@Update/@Delete/@Insert), ComplexMapper.java (multi-line SQL arrays, escaped quotes, additional parameters), MixedMapper.java (SQL and non-SQL annotations mixed). Run `mvn test` ensuring all annotation parsing tests pass.

### Task 3.4 – QueryWrapper Static Scanner Implementation │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 39 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_4_QueryWrapper_Scanner_Implementation.md`

- **Objective:** Implement MyBatis-Plus QueryWrapper usage scanner detecting QueryWrapper, LambdaQueryWrapper, UpdateWrapper, and LambdaUpdateWrapper instantiations in Java source code, marking usage locations for runtime interception since static analysis cannot determine dynamic query conditions, producing WrapperUsage entries for scan reports.
- **Output:**
  - QueryWrapperScanner class implementing WrapperScanner interface from Task 3.1
  - Recursive Java file discovery using Files.walk() traversing src/main/java
  - JavaParser-based wrapper instantiation detection via ObjectCreationExpr AST nodes
  - WrapperUsage entry creation with filePath, methodName, lineNumber, wrapperType, needsRuntimeCheck=true
  - Performance optimization for large codebases (1000+ Java files)
  - Filtering logic excluding test files and generated code
  - False positive prevention for non-wrapper object creations
- **Guidance:** MyBatis-Plus QueryWrapper provides fluent API for dynamic query construction making static SQL extraction impossible (conditions determined at runtime). Static scanner's role is only to mark usage locations, signaling runtime interceptor (Task 4.2) must validate actual SQL execution. Design 6.5 specifies "只标记使用位置" (only mark usage locations) - deliberately avoiding complex condition analysis. WrapperUsage.needsRuntimeCheck flag indicates these locations require runtime validation layer. Scanner must handle large codebases efficiently (stream-based processing, parallel parsing if needed) while avoiding false positives (verify wrapper types are from MyBatis-Plus com.baomidou.mybatisplus.core.conditions package). Depends on: Task 3.1 Output (WrapperScanner interface and WrapperUsage class).

- **Wrapper Detection TDD:** Write test class `QueryWrapperScannerTest` with test methods: `testQueryWrapperDetection_shouldCreateUsage()` (Java file with `new QueryWrapper<User>()` creates WrapperUsage), `testLambdaQueryWrapperDetection_shouldCreateUsage()` (detect `new LambdaQueryWrapper<>()`), `testUpdateWrapperDetection_shouldCreateUsage()` (detect `new UpdateWrapper<>()`), `testLambdaUpdateWrapperDetection_shouldCreateUsage()` (detect `new LambdaUpdateWrapper<>()`), `testNonWrapperObjectCreation_shouldSkip()` (new ArrayList(), new User() should not create WrapperUsage), `testMultipleWrappersInFile_shouldDetectAll()` (file with 3 wrapper creations creates 3 WrapperUsage). Implement `QueryWrapperScanner` class in `com.footstone.sqlguard.scanner.wrapper` package implementing WrapperScanner interface. Implement `scan(File projectRoot)` method: recursively find all .java files using Files.walk(projectRoot.toPath()).filter(p -> p.toString().endsWith(\".java\") && p.toString().contains(\"src/main/java\")), parse each Java file with JavaParser CompilationUnit cu = StaticJavaParser.parse(file), call cu.findAll(ObjectCreationExpr.class) to find all `new X()` expressions, for each ObjectCreationExpr check if type name matches wrapper patterns using Set<String> wrapperTypes = [\"QueryWrapper\", \"LambdaQueryWrapper\", \"UpdateWrapper\", \"LambdaUpdateWrapper\"], extract enclosing method name using expr.findAncestor(MethodDeclaration.class).map(m -> m.getNameAsString()).orElse(\"unknown\"), get line number from expr.getBegin().get().line, create WrapperUsage(filePath=file.getAbsolutePath(), methodName=enclosingMethod, lineNumber=lineNum, wrapperType=typeName, needsRuntimeCheck=true), collect all WrapperUsage into List, return result.

- **Implementation Details:** Implement wrapper type matching with package verification to prevent false positives: check if ObjectCreationExpr.getType().resolve().getQualifiedName() starts with \"com.baomidou.mybatisplus.core.conditions\" (requires JavaParser symbol resolution). If symbol resolution fails (missing dependencies), fall back to simple type name matching with warning log. Extract enclosing method using AST traversal: expr.findAncestor(MethodDeclaration.class) for method-level wrappers, use class-level \"<init>\" or \"<static>\" for wrappers in constructors/static blocks. Skip detailed condition analysis (per design: no need to extract eq(), like(), orderBy() calls - runtime interceptor handles actual SQL validation). Set needsRuntimeCheck=true for all WrapperUsage entries indicating static analysis insufficient.

- **Performance Testing:** Write performance test `QueryWrapperScannerPerformanceTest` simulating large projects: generate 1000 Java files with varying wrapper usage (some with wrappers, most without), execute scan() and measure execution time (should complete in reasonable time <10 seconds for 1000 files), verify memory usage remains bounded (no memory leaks from JavaParser AST retention), test parallel processing optimization if needed (Stream.parallel() on file list). Write filtering test `ScanFilteringTest`: create directory structure with src/main/java (include), src/test/java (exclude), target/generated-sources (exclude), verify scanner only processes src/main/java files, verify no false positives from test files or generated code. Test false positive prevention: create Java files with non-wrapper object creations (new ArrayList<>(), new HashMap<>(), custom domain objects), verify scanner does not create WrapperUsage for these, verify wrapper type matching is precise (QueryWrapper detected, QueryWrapperTest not detected). Run `mvn test` ensuring wrapper scanner performance and accuracy.

### Task 3.5 – Dynamic SQL Scenario Generator │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 37 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_5_Dynamic_SQL_Variant_Generator.md`

- **Objective:** Implement comprehensive MyBatis dynamic SQL variant generator producing representative SQL execution scenarios for if/foreach/where/choose/when/otherwise tags, enabling static validation of dynamic SQL by generating concrete SQL strings covering different runtime execution paths without combinatorial explosion.
- **Output:**
  - Tag-specific variant generation methods (handleIfTag, handleForeachTag, handleWhereTag, handleChooseWhenTag)
  - If-tag variant generation: 2 scenarios (condition true/false)
  - Foreach-tag variant generation: 3 representative scenarios (empty/single/multiple items)
  - Where-tag variant generation: smart WHERE clause insertion with AND/OR removal
  - Choose-when variant generation: one variant per branch (when branches + otherwise)
  - Nested tag handling with recursive combination generation
  - Variant description annotations ("with condition X", "without condition Y")
  - Comprehensive integration tests with complex nested dynamic SQL patterns
- **Guidance:** Dynamic SQL in MyBatis XML mappers requires variant generation to enable static validation of all possible execution paths. Goal is representative coverage (not exhaustive) - generate enough variants to catch dangerous patterns without exploding variant count. For if tags: 2 variants cover include/exclude scenarios. For foreach: 3 variants (empty/single/multiple) represent typical collection sizes. For choose: one variant per branch ensures all branches validated. Nested tags require recursive handling generating combinations (limit combinatorial growth with max variant count per SQL). Generated variants must be syntactically valid SQL (where tag properly adds WHERE keyword and removes leading AND/OR). This task enhances Task 3.2 XML parser by populating SqlEntry.sqlVariants list. Depends on: Task 3.2 Output (XmlMapperParser and DOM4J Element manipulation).

1. **If-Tag Variant Generation TDD:** Write test class `IfTagVariantGeneratorTest` with test methods: `testSimpleIf_shouldGenerateTwoVariants()` (SQL with <if test=\"id != null\">AND id=#{id}</if> generates variant with condition included and variant with condition excluded), `testMultipleIf_shouldGenerateCombinations()` (SQL with 2 independent if tags generates 4 variants covering all combinations), `testNestedIf_shouldHandleRecursively()` (if inside if generates correct nested variants). Implement `handleIfTag(Element element)` method in variant generator component: detect <if> tags in element tree, for each if tag generate 2 scenarios (include content = condition true, exclude content = condition false), for nested if tags generate combinations recursively, limit total variant count to reasonable number (e.g., max 10 variants per SQL to prevent combinatorial explosion), add meaningful variant descriptions like \"with id condition\", \"without id condition\", return List<String> containing variant SQL strings with if tag content either included or removed.

2. **Foreach-Tag Variant Generation TDD:** Write test class `ForeachTagVariantGeneratorTest` with test methods: `testForeachEmpty_shouldRemoveClause()` (SQL with <foreach collection=\"ids\" item=\"id\" separator=\",\">#{id}</foreach> in WHERE id IN (...) generates variant with entire IN clause removed for empty collection), `testForeachSingle_shouldNoSeparator()` (single item variant: WHERE id IN (?) without separator), `testForeachMultiple_shouldUseSeparator()` (multiple item variant: WHERE id IN (?, ?, ?) with separators). Implement `handleForeachTag(Element element)` method: detect <foreach> tags, extract collection attribute, item attribute, separator attribute, generate 3 representative variants: (1) empty collection - remove entire foreach content and surrounding clause (e.g., remove \"AND id IN ()\" entirely), (2) single item - replace foreach with single item placeholder (no separator), (3) multiple items - replace foreach with 3 item placeholders separated by separator (e.g., \"?, ?, ?\"), use placeholder values for item references (#{item} → ?), add variant descriptions like \"foreach empty\", \"foreach single item\", \"foreach 3 items\".

3. **Where-Tag Variant Generation TDD:** Write test class `WhereTagVariantGeneratorTest` with test methods: `testWhereWithContent_shouldAddWhere()` (SQL with <where>AND id=#{id}</where> generates variant \"WHERE id=#{id}\" with WHERE keyword added and leading AND removed), `testWhereWithoutContent_shouldRemove()` (where tag with all dynamic content excluded generates variant without WHERE clause), `testWhereMultipleConditions_shouldHandleAndOr()` (where tag with multiple AND/OR conditions correctly removes only leading AND/OR, preserves internal ones). Implement `handleWhereTag(Element element)` method: detect <where> tags, generate variants based on dynamic content inside: if content present after processing nested dynamic tags (if/foreach), add WHERE keyword at start, remove leading AND/OR/AND\\s+/OR\\s+ from first condition using regex, preserve internal AND/OR operators, if content completely excluded (all if conditions false), remove entire where tag including WHERE keyword, ensure generated SQL is syntactically valid (no dangling WHERE, no double AND/OR).

4. **Choose-When Variant Generation TDD:** Write test class `ChooseWhenVariantGeneratorTest` with test methods: `testChooseMultipleWhen_shouldGeneratePerBranch()` (SQL with <choose><when test=\"type=1\">...</when><when test=\"type=2\">...</when><otherwise>...</otherwise></choose> generates 3 variants, one per branch), `testChooseNoOtherwise_shouldHandleMissing()` (choose without otherwise generates variant for each when only), `testChooseSingleBranch_shouldIncludeExclusively()` (each variant includes only one branch content, not multiple). Implement `handleChooseWhenTag(Element element)` method: detect <choose> tags, find all <when> child elements and optional <otherwise> element, generate one variant per when branch: include that when's content, exclude all other when and otherwise content, generate additional variant for otherwise branch if present: include otherwise content, exclude all when content, ensure only one branch included per variant (MyBatis switch-case semantics), add variant descriptions like \"choose when type=1\", \"choose otherwise\".

5. **Comprehensive Integration Testing:** Write integration test `DynamicSqlVariantGeneratorIntegrationTest` with complex XML test fixtures: complex-nested.xml (if inside where inside foreach with multiple nesting levels), real-world-mapper.xml (realistic MyBatis mapper with dynamic where, multiple if conditions, foreach in IN clause, choose-when for different query modes), edge-cases.xml (empty where tag, foreach with no items, choose with only otherwise, nested choose). For each test file: parse with enhanced XmlMapperParser including variant generation, verify SqlEntry.sqlVariants list populated correctly, verify variant count reasonable (not exponential explosion), verify all generated variants are syntactically valid SQL (can be parsed by JSqlParser without errors), verify variant descriptions meaningful for debugging, test variant SQL against validation engine to ensure dangerous patterns detected across execution paths. Write performance test: complex dynamic SQL with 5+ nested dynamic tags generates variants in reasonable time (<1 second) without memory explosion. Run `mvn test` ensuring all variant generation tests pass.

### Task 3.6 – Scan Report Generator (Console + HTML) │ Agent_Static_Scanner │ ✅ COMPLETED

**Completion:** 2025-12-15 | **Tests:** 57 passing (100%) | **Memory Log:** `.apm/Memory/Phase_03_Static_Scanner/Task_3_6_Report_Generator_Implementation.md`

- **Objective:** Implement dual-format report generation system producing actionable scan reports in console (ANSI-colored text for terminal display) and HTML (styled web page with sortable tables) formats, processing ScanReport data structures from Task 3.1 to group violations by severity, format output with file:line references, SQL snippets, violation messages, and suggestions.
- **Output:**
  - ReportProcessor class aggregating and preparing report data structures
  - ConsoleReportGenerator producing ANSI-colored terminal output matching design 6.8 format
  - HtmlReportGenerator producing styled HTML with sortable violation tables
  - Violation grouping by risk level (CRITICAL/HIGH/MEDIUM) with severity sorting
  - Statistics summary (total SQL count, violation counts by level, wrapper usage count)
  - Formatted violation entries with file:line, mapper ID, SQL snippet, message, suggestion
  - Collapsible SQL preview sections and syntax highlighting in HTML
  - Comprehensive tests for formatting accuracy, HTML validity, special character handling
- **Guidance:** Report generation is final step in static scanning workflow, presenting actionable findings to developers. Console format is default for CLI usage providing immediate feedback with ANSI colors (red=CRITICAL, yellow=HIGH, blue=MEDIUM) for visual severity distinction. HTML format enables detailed analysis with sortable tables, collapsible sections, and persistent reports for CI/CD integration or team review. ReportProcessor separates data preparation (grouping, sorting, statistics) from rendering (console vs HTML) following Single Responsibility Principle. Violation entries must include precise file:line references enabling IDE navigation. SQL snippets should be truncated if excessive (max 100 chars in console, expandable in HTML). Follow design 6.8 console format specification. Depends on: Task 3.1 Output (ScanReport data structures).

1. **Report Processing TDD:** Write test class `ReportProcessorTest` with test methods: `testGroupByRiskLevel_shouldGroupCorrectly()` (ScanReport with violations at CRITICAL/HIGH/MEDIUM creates grouped map), `testSortBySeverity_shouldOrderCriticalFirst()` (violations sorted CRITICAL > HIGH > MEDIUM > LOW), `testExtractStatistics_shouldCalculateCorrectly()` (total SQL count, violation count by level, wrapper usage count accurate), `testPrepareFormattedData_shouldCreateRenderStructure()` (prepares data structures optimized for console and HTML renderers). Implement `ReportProcessor` class in `com.footstone.sqlguard.scanner.report` package with method `process(ScanReport report)` returning ProcessedReport: group violations by RiskLevel using Map<RiskLevel, List<ViolationEntry>> where ViolationEntry contains filePath, lineNumber, mapperId, sqlSnippet (truncated to 100 chars), message, suggestion, sort groups by severity (CRITICAL first, LOW last), calculate statistics: int totalSqlCount = report.entries.size(), Map<RiskLevel, Integer> violationCountByLevel, int wrapperUsageCount = report.wrapperUsages.size(), int totalViolations = violationCountByLevel.values().stream().sum(), prepare formatted data structures for renderers.

2. **Console Report Generation TDD:** Write test class `ConsoleReportGeneratorTest` with test methods: `testConsoleOutputFormat_shouldMatchDesign()` (output matches design 6.8 format with header, statistics, grouped violations), `testAnsiColors_shouldApplyCorrectly()` (CRITICAL uses red ANSI code \\033[31m, HIGH uses yellow \\033[33m, MEDIUM uses blue \\033[34m), `testViolationEntry_shouldFormatCorrectly()` (entry format: \"[file:line] mapperId - message\"), `testSqlSnippet_shouldTruncate()` (SQL > 100 chars truncated with \"...\"), `testSummaryStatistics_shouldDisplay()` (header shows total SQL count, violation count by level, wrapper count). Implement `ConsoleReportGenerator` class in scanner.report with method `printToConsole(ScanReport report)` from design 6.8: create formatted text output with ANSI colors for severity levels (define constants: RED = \"\\033[31m\", YELLOW = \"\\033[33m\", BLUE = \"\\033[34m\", RESET = \"\\033[0m\"), print summary statistics header: \"SQL Safety Scan Report\\n====================\\nTotal SQL: X | Violations: Y (CRITICAL: a, HIGH: b, MEDIUM: c) | Wrapper Usages: Z\", for each risk level group in severity order: print section header with color \"\\n[CRITICAL]\" in red, for each violation in group: format entry as \"[filePath:lineNumber] mapperId\\n  SQL: [snippet...]\\n  Message: [message]\\n  Suggestion: [suggestion]\", implement printToConsole() calling System.out.println() for formatted output.

3. **HTML Report Generation TDD:** Write test class `HtmlReportGeneratorTest` with test methods: `testHtmlStructure_shouldBeValid()` (generated HTML parses with HTML parser without errors), `testSortableTable_shouldIncludeColumns()` (table has columns: Risk Level, File, Mapper, Message with sortable headers), `testCollapsibleSqlSections_shouldWork()` (SQL preview sections expandable via JavaScript), `testStatisticsDashboard_shouldDisplay()` (top dashboard shows total counts with visual indicators), `testSpecialCharacters_shouldEscape()` (SQL with <, >, &, quotes properly HTML-escaped), `testEmptyReport_shouldHandleGracefully()` (report with no violations shows \"No violations found\" message). Implement `HtmlReportGenerator` class in scanner.report with method `writeToFile(ScanReport report, Path outputPath)` from design: create HTML structure with <!DOCTYPE html><html><head> including CSS styling for modern table design, color-coded risk levels (red/yellow/blue backgrounds), responsive layout, create statistics dashboard at top with boxes showing: Total SQL Count, Total Violations (with risk level breakdown), Wrapper Usages, generate <table> with sortable columns: Risk Level, File:Line, Mapper ID, Message, SQL Preview (collapsible), Suggestion, use JavaScript for table sorting (include simple sort function), add collapsible SQL sections using <details><summary> HTML5 elements or JavaScript toggle, apply syntax highlighting for SQL (optional, use simple <code> tags with monospace font if full highlighting too complex), escape special characters in SQL using StringEscapeUtils.escapeHtml4() from Apache Commons Text, write generated HTML to outputPath using Files.write().

4. **Comprehensive Testing:** Write integration test `ReportGeneratorIntegrationTest` with sample ScanReport containing: 5 CRITICAL violations, 10 HIGH violations, 3 MEDIUM violations, 50 total SQL entries, 5 wrapper usages, long SQL statements (>200 chars), SQL with special characters (quotes, <script> tags, &), empty report (0 violations). For each test report: generate console output, verify output formatting correct (use regex to validate structure), verify ANSI colors applied (check for color codes in output string), verify statistics accurate, verify violation entries complete. Generate HTML output, parse with JSoup HTML parser to verify valid structure, verify table contains correct row count, verify special characters escaped (no XSS vulnerabilities from SQL injection into HTML), verify CSS styling present, test with large reports (1000+ violations) ensuring HTML file size reasonable and browser-renderable, verify readability and usability (manually inspect generated HTML). Run `mvn test` ensuring all report generation tests pass.

### Task 3.7 – CLI Tool Implementation │ Agent_Static_Scanner

- **Objective:** Implement production-ready command-line interface tool providing user-friendly SQL scanning with argument parsing (picocli), input validation, configuration loading, scan orchestration, dual-format report output, CI/CD integration support via exit codes, and comprehensive error handling for robust deployment in development and continuous integration environments.
- **Output:**
  - SqlScannerCli class with @Command annotation and picocli argument definitions
  - Command-line options: --project-path (required), --config-file (optional), --output-format (html/console), --output-file (HTML path), --fail-on-critical (CI/CD flag), --quiet (suppress output)
  - Input validation with fail-fast error messages for invalid arguments
  - Configuration loading from YAML file or defaults
  - Scan orchestration instantiating all parsers and executing scan
  - Report output in specified format (console stdout or HTML file)
  - CI/CD integration with exit codes (0=success/warnings, 1=critical violations or errors)
  - Progress logging and error handling with meaningful messages
  - Comprehensive tests for argument parsing, validation, orchestration, exit codes
- **Guidance:** CLI tool is primary user interface for static scanning in development workflows and CI/CD pipelines, requiring production-quality error handling and user experience. Picocli provides POSIX-style argument parsing with built-in help generation and validation. Fail-fast validation prevents confusing errors during scan execution. Configuration loading reuses SqlGuardConfig from Phase 1 (Task 1.3) with YAML support. Scan orchestration assembles all components: XmlMapperParser (Task 3.2), AnnotationParser (Task 3.3), QueryWrapperScanner (Task 3.4), report generators (Task 3.6). Exit code conventions: 0 for success or non-critical warnings (allows CI to continue), 1 for critical violations or errors (fails CI build). --quiet flag enables headless CI usage. Follow design 6.6 CLI specification. Depends on: Task 3.1 Output (SqlScanner orchestration), Task 3.6 Output (report generators).

1. **CLI Argument Parsing TDD:** Write test class `SqlScannerCliTest` with test methods: `testRequiredProjectPath_shouldParse()` (args with --project-path=/path parses successfully), `testOptionalConfigFile_shouldParse()` (--config-file=config.yml parsed), `testOutputFormat_shouldParseValues()` (--output-format=html and --output-format=console both valid), `testOutputFile_shouldParse()` (--output-file=report.html parsed), `testFailOnCritical_shouldParseBoolean()` (--fail-on-critical sets boolean flag), `testMissingRequired_shouldFail()` (args without --project-path fails with error), `testInvalidFormat_shouldFail()` (--output-format=xml fails with validation error), `testHelpFlag_shouldDisplayUsage()` (--help displays command usage and exits). Add picocli 4.7.x dependency to sql-scanner-cli module POM. Implement `SqlScannerCli` class in `com.footstone.sqlguard.cli` package with @Command annotation: @Command(name = \"sql-scanner\", description = \"Static SQL safety scanner for MyBatis applications\", mixinStandardHelpOptions = true). Define @Option fields from design 6.6: @Option(names = {\"--project-path\", \"-p\"}, required = true, description = \"Project root directory\") Path projectPath, @Option(names = {\"--config-file\", \"-c\"}, description = \"Configuration file path\") Path configFile, @Option(names = {\"--output-format\", \"-f\"}, defaultValue = \"console\", description = \"Output format: console or html\") String outputFormat, @Option(names = {\"--output-file\", \"-o\"}, description = \"Output file path for HTML format\") Path outputFile, @Option(names = {\"--fail-on-critical\"}, defaultValue = \"false\", description = \"Exit with code 1 if CRITICAL violations found\") boolean failOnCritical, @Option(names = {\"--quiet\", \"-q\"}, defaultValue = \"false\", description = \"Suppress non-error output for CI\") boolean quiet. Implement main(String[] args) method: int exitCode = new CommandLine(new SqlScannerCli()).execute(args); System.exit(exitCode).

2. **Input Validation TDD:** Write test class `InputValidationTest` with test methods: `testProjectPathNotExists_shouldFail()` (non-existent path fails with clear message), `testProjectPathNotDirectory_shouldFail()` (file instead of directory fails), `testConfigFileNotExists_shouldFail()` (non-existent config file fails), `testOutputFormatInvalid_shouldFail()` (invalid format value fails), `testOutputFileNotWritable_shouldFail()` (read-only output path fails), `testHtmlFormatWithoutOutputFile_shouldFail()` (--output-format=html requires --output-file). Implement validation logic in CLI class or dedicated Validator: annotate projectPath with @Option and add custom validator checking Files.exists(projectPath) && Files.isDirectory(projectPath), throw ParameterException with message \"Project path does not exist or is not a directory: \" + projectPath if validation fails, similarly validate configFile if provided (Files.exists(configFile)), validate outputFormat enum values using @Option(completionCandidates = [\"console\", \"html\"]), validate outputFile path is writable by checking parent directory exists and is writable, add cross-field validation: if outputFormat.equals(\"html\") && outputFile == null, throw ParameterException(\"HTML format requires --output-file\"), provide clear error messages for all validation failures with suggested fixes, implement fail-fast approach (validate all inputs before scanning), exit with code 1 on validation errors.

3. **Scan Orchestration TDD:** Write test class `ScanOrchestrationTest` with test methods: `testScanExecution_shouldLoadConfig()` (loads configuration from file or defaults), `testScanExecution_shouldInstantiateParsers()` (creates XmlMapperParser, AnnotationParser, QueryWrapperScanner), `testScanExecution_shouldExecuteScan()` (calls SqlScanner.scan() and produces ScanReport), `testScanError_shouldHandleGracefully()` (parser exception during scan logs error and exits with code 1), `testProgressLogging_shouldLogSteps()` (unless --quiet, logs \"Scanning project...\", \"Found X SQL statements\", \"Scan complete\"). Implement scan execution in CLI class as @Command Callable<Integer>: load configuration via YamlConfigLoader.loadFromFile(configFile) if configFile provided, else use SqlGuardConfigDefaults.getDefault() from Phase 1 Task 1.3, create ScanContext with projectPath and loaded config, instantiate all parsers: XmlMapperParser xmlParser = new XmlMapperParser(), AnnotationParser annotationParser = new AnnotationParser(), QueryWrapperScanner wrapperScanner = new QueryWrapperScanner(), create SqlRiskEvaluator with config, instantiate SqlScanner scanner = new SqlScanner(xmlParser, annotationParser, wrapperScanner, evaluator), execute ScanReport report = scanner.scan(context), handle exceptions gracefully: catch IOException, ParseException, ConfigLoadException during execution, log error message with ex.getMessage(), log stack trace if verbose mode enabled, return exit code 1 on errors, log progress to console using SLF4J logger: log.info(\"Scanning project: {}\", projectPath), log.info(\"Found {} SQL statements\", report.entries.size()), suppress logging if quiet flag set (configure Logback level to ERROR).

4. **Report Output & CI Integration TDD:** Write test class `ReportOutputTest` with test methods: `testConsoleOutput_shouldPrintToStdout()` (--output-format=console prints report to console), `testHtmlOutput_shouldWriteFile()` (--output-format=html writes report to --output-file), `testFailOnCritical_withCritical_shouldExitOne()` (CRITICAL violations + --fail-on-critical returns exit code 1), `testFailOnCritical_withoutCritical_shouldExitZero()` (no CRITICAL violations returns exit code 0 even with HIGH/MEDIUM), `testQuietMode_shouldSuppressOutput()` (--quiet suppresses progress logs, only errors printed), `testExitCodes_shouldMatchCiConvention()` (verify 0=success/warnings, 1=critical/errors). Implement report output and exit codes in CLI: after scan completes, check outputFormat value, if \"console\" call ConsoleReportGenerator.printToConsole(report) from Task 3.6, if \"html\" call HtmlReportGenerator.writeToFile(report, outputFile) from Task 3.6, implement --fail-on-critical logic: extract critical violation count from report statistics, if failOnCritical && criticalCount > 0, log.error(\"{} CRITICAL violations found, failing build\", criticalCount) and return exit code 1, else return exit code 0 (even if HIGH/MEDIUM violations present, allowing CI to continue with warnings), add --quiet flag support: configure Logback programmatically to set root logger level to ERROR when quiet=true, ensuring only error messages printed, verify integration with CI tools: return codes parseable by Jenkins, GitLab CI, GitHub Actions (standard Unix convention: 0=success, non-zero=failure), test with shell: `./sql-scanner --project-path=/path; echo $?` verifies exit code. Run comprehensive tests ensuring all CLI functionality works correctly.

## Phase 4: Runtime Interception System - Agent_Runtime_Interceptor

### Task 4.1 – MyBatis Interceptor Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement production-ready MyBatis plugin intercepting Executor.update and Executor.query methods to validate SQL at runtime after dynamic SQL resolution, extracting final SQL from BoundSql, detecting RowBounds for logical pagination, and enforcing configured violation strategies (BLOCK/WARN/LOG) supporting both MyBatis 3.4.x and 3.5.x versions.
- **Output:**
  - SqlSafetyInterceptor class with @Intercepts annotations targeting Executor methods
  - intercept() method extracting MappedStatement, BoundSql, parameters, and RowBounds
  - SqlContext population with runtime SQL execution context
  - Violation handling implementing BLOCK (throws SQLException), WARN (logs + continues), LOG (logs only) strategies
  - Multi-version compatibility handling MyBatis 3.4.6 and 3.5.13 API differences
  - Integration tests with real SqlSessionFactory validating interception accuracy
  - Thread-safety verification under concurrent SQL execution
- **Guidance:** MyBatis interceptor is first runtime defense layer validating SQL after dynamic tag resolution but before database execution, catching dangerous patterns missed by static analysis (runtime-determined conditions). BoundSql provides final SQL with dynamic tags processed, enabling accurate validation. RowBounds detection is critical for identifying logical pagination (Task 2.7 checker). MapperId from MappedStatement links runtime violations to source code locations. Strategy pattern allows environment-specific enforcement: LOG in dev (observation), WARN in test (alerting), BLOCK in prod (prevention). Multi-version support required due to API changes between MyBatis 3.4.x and 3.5.x (Executor method signatures, parameter handling). Thread-safety essential as interceptor shared across SqlSession instances. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **MyBatis Interceptor TDD:** Write test class `SqlSafetyInterceptorTest` with test methods: `testQueryInterception_shouldValidate()` (SELECT query intercepted before execution), `testUpdateInterception_shouldValidate()` (UPDATE/DELETE intercepted), `testRowBoundsDetection_shouldExtract()` (RowBounds parameter detected for pagination), `testDynamicSqlResolution_shouldGetBoundSql()` (BoundSql contains resolved SQL with dynamic tags processed), `testBLOCKStrategy_shouldThrowException()` (validation failure with BLOCK strategy throws SQLException), `testWARNStrategy_shouldLogAndContinue()` (validation failure with WARN logs error and proceeds), `testLOGStrategy_shouldOnlyLog()` (LOG strategy only logs, no exception). Add MyBatis 3.4.6 and 3.5.13 dependencies to sql-guard-mybatis module POM with profiles for testing both versions. Implement `SqlSafetyInterceptor` class in `com.footstone.sqlguard.interceptor.mybatis` package annotated with @Intercepts targeting Executor methods: @Intercepts({@Signature(type = Executor.class, method = \"update\", args = {MappedStatement.class, Object.class}), @Signature(type = Executor.class, method = \"query\", args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class})}). Implement Interceptor interface with intercept(Invocation invocation) method from design 4.2.

2. **Intercept Method Implementation:** Implement intercept() method extracting execution context: get Invocation.getArgs() array, extract MappedStatement ms = (MappedStatement) args[0], extract parameter Object param = args[1], for query method extract RowBounds rowBounds = (RowBounds) args[2], obtain BoundSql boundSql = ms.getBoundSql(param) to get final SQL after MyBatis dynamic SQL processing, extract SQL string via boundSql.getSql(), extract SqlCommandType from ms.getSqlCommandType(), extract mapperId from ms.getId(), extract parameters from boundSql.getParameterMappings() and boundSql.getParameterObject(), build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).params(extractedParams).rowBounds(rowBounds).build(). Handle MyBatis version differences: use reflection to check BoundSql method availability, provide fallback for API changes between 3.4.x and 3.5.x.

3. **Validation and Strategy Handling:** Inject DefaultSqlSafetyValidator via constructor. Call ValidationResult result = validator.validate(context) after SqlContext creation. Implement strategy pattern: read configured strategy from SqlGuardConfig (injected via constructor or Spring), if result.passed is false execute strategy: BLOCK strategy throws new SQLException(\"SQL Safety Violation: \" + result.getRiskLevel() + \" - \" + formatViolations(result.getViolations()), \"42000\") with SQLState indicating constraint violation, WARN strategy logs log.error(\"SQL Safety Violation (WARN): {}\", formatViolations(result.getViolations())) and proceeds with invocation.proceed(), LOG strategy logs log.warn(\"SQL Safety Violation (LOG): {}\", formatViolations(result.getViolations())) and proceeds. If result.passed is true, proceed normally with invocation.proceed(). Implement formatViolations() helper creating multi-line violation report with risk level, messages, suggestions for logging/exception details.

4. **Multi-Version Compatibility Testing:** Write compatibility test `MyBatisVersionCompatibilityTest` with Maven profiles: mybatis-3.4 profile (MyBatis 3.4.6 dependency), mybatis-3.5 profile (MyBatis 3.5.13 dependency). For each profile: create test SqlSessionFactory with interceptor configured, execute sample SQL with dynamic tags (if conditions, foreach), verify BoundSql extraction works correctly, verify parameter extraction handles differences, test RowBounds detection works in both versions. Use reflection-based API detection to handle incompatible method signatures: detect method availability at runtime, use version-specific code paths, log warnings if deprecated methods used. Run `mvn test -Pmybatis-3.4` and `mvn test -Pmybatis-3.5` ensuring all tests pass on both versions.

5. **Integration and Thread-Safety Testing:** Write integration test `SqlSafetyInterceptorIntegrationTest` with real MyBatis configuration: create H2 in-memory database, create MyBatis mapper XML with sample SQL (including dangerous patterns: no WHERE, dummy conditions), configure SqlSessionFactory with SqlSafetyInterceptor, execute queries and updates via mapper methods, verify interception triggers validation, verify violations detected correctly, test BLOCK strategy prevents execution (SQLException thrown, database unchanged), test WARN/LOG strategies allow execution (database modified, violations logged). Write thread-safety test `InterceptorConcurrencyTest`: execute 100 concurrent SQL operations via SqlSession instances sharing same interceptor instance, verify no race conditions in validator or deduplication cache, verify all violations detected across threads, verify no false positives/negatives under concurrency. Run `mvn test` ensuring all integration and thread-safety tests pass.

### Task 4.2 – MyBatis-Plus InnerInterceptor Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement MyBatis-Plus InnerInterceptor integrating with MyBatis-Plus interceptor chain to validate SQL at runtime, detecting IPage pagination parameters for physical pagination validation, capturing QueryWrapper/LambdaQueryWrapper generated SQL flagged by static scanner, and coordinating with PaginationInnerInterceptor without conflicts.
- **Output:**
  - MpSqlSafetyInnerInterceptor class implementing InnerInterceptor interface
  - beforeQuery() and beforeUpdate() methods intercepting SQL execution
  - IPage parameter detection for MyBatis-Plus pagination validation
  - QueryWrapper SQL capture coordinating with static scanner WrapperUsage markers
  - Integration with PaginationInnerInterceptor ensuring both work together
  - Deduplication preventing double-checking when MyBatis and MyBatis-Plus interceptors both enabled
  - Compatibility with MyBatis-Plus optimistic lock and tenant plugins
  - Integration tests with IPage pagination and QueryWrapper/LambdaQueryWrapper usage
- **Guidance:** MyBatis-Plus InnerInterceptor integrates into MybatisPlusInterceptor chain providing modular interception architecture. IPage parameter detection enables physical pagination validation (Task 2.6 infrastructure) complementing MyBatis RowBounds. QueryWrapper/LambdaQueryWrapper generate SQL dynamically at runtime (static scanner from Task 3.4 only marks usage locations), requiring runtime validation to catch dangerous patterns in fluent API-built queries. Coordination with PaginationInnerInterceptor critical: both must coexist without conflicts (PaginationInnerInterceptor modifies SQL for pagination, SqlSafetyInnerInterceptor validates final SQL). Deduplication filter (Task 2.13) prevents double validation when multiple interceptor layers enabled. Compatibility with MP ecosystem plugins (optimistic lock, multi-tenant) ensures production viability. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **InnerInterceptor TDD:** Write test class `MpSqlSafetyInnerInterceptorTest` with test methods: `testBeforeQuery_shouldValidate()` (beforeQuery() intercepts SELECT execution), `testBeforeUpdate_shouldValidate()` (beforeUpdate() intercepts UPDATE/DELETE), `testIPageDetection_shouldExtract()` (IPage parameter detected from method parameters), `testQueryWrapperSqlCapture_shouldValidate()` (QueryWrapper generated SQL captured and validated), `testLambdaQueryWrapperSqlCapture_shouldValidate()` (LambdaQueryWrapper SQL validated), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work as expected). Add MyBatis-Plus 3.4.0 and 3.5.3 dependencies to sql-guard-mp module POM. Implement `MpSqlSafetyInnerInterceptor` class in `com.footstone.sqlguard.interceptor.mp` package implementing InnerInterceptor interface from MyBatis-Plus (com.baomidou.mybatisplus.extension.plugins.inner.InnerInterceptor). Implement beforeQuery() and beforeUpdate() methods from design 4.3.

2. **beforeQuery/beforeUpdate Implementation:** Implement beforeQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) method: extract SQL from boundSql.getSql(), extract SqlCommandType from ms.getSqlCommandType(), extract mapperId from ms.getId(), extract RowBounds parameter for pagination detection, detect IPage parameter via hasIPageParameter(parameter) helper method: check if parameter instanceof IPage (direct IPage parameter), or if parameter instanceof Map check Map.values() for IPage instances (IPage in parameter map common in MyBatis-Plus), extract IPage details (current page, size) and add to SqlContext, build SqlContext with all extracted information. Implement beforeUpdate(Executor executor, MappedStatement ms, Object parameter) similarly extracting context from UPDATE/DELETE execution. Call validator.validate(context) and handle violations with strategy pattern (same as Task 4.1: BLOCK throws SQLException, WARN/LOG log violations).

3. **IPage and QueryWrapper Detection:** Implement IPage detection helper: `boolean hasIPageParameter(Object parameter)` checking parameter type and Map contents. Implement QueryWrapper SQL capture: MyBatis-Plus generates SQL from QueryWrapper/LambdaQueryWrapper at runtime, BoundSql contains final generated SQL, validate this SQL to catch dangerous fluent API patterns (e.g., empty wrapper equivalent to no WHERE, wrapper with only blacklist fields). No special QueryWrapper detection needed in interceptor - just validate BoundSql SQL like any other query. Static scanner (Task 3.4) already marked QueryWrapper usage locations; runtime interceptor validates actual generated SQL execution. Add wrapper detection to SqlContext for correlation: check if parameter contains QueryWrapper instance, set flag in SqlContext details for debugging/reporting.

4. **Integration with PaginationInnerInterceptor:** Write integration test `MpInterceptorCoordinationTest` with both PaginationInnerInterceptor and MpSqlSafetyInnerInterceptor configured in MybatisPlusInterceptor: create MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(), add PaginationInnerInterceptor first (interceptor.addInnerInterceptor(new PaginationInnerInterceptor())), add MpSqlSafetyInnerInterceptor second (interceptor.addInnerInterceptor(new MpSqlSafetyInnerInterceptor(validator))), configure in SqlSessionFactory. Test scenarios: IPage query with pagination (verify PaginationInnerInterceptor adds LIMIT clause, then MpSqlSafetyInnerInterceptor validates final SQL with LIMIT), dangerous SQL with IPage pagination (verify safety interceptor still detects no WHERE despite LIMIT added), verify both interceptors execute in correct order, verify no SQL double-validation (deduplication filter prevents).

5. **Edge Case and Plugin Compatibility Testing:** Write test `MpPluginCompatibilityTest` ensuring compatibility with MyBatis-Plus ecosystem plugins: test with optimistic lock plugin (OptimisticLockerInnerInterceptor) enabled, verify version field updates intercepted and validated correctly, test with multi-tenant plugin (TenantLineInnerInterceptor) enabled, verify tenant_id injection doesn't interfere with validation, test with illegal SQL plugin (IllegalSQLInnerInterceptor) enabled alongside safety interceptor, verify both plugins coexist without conflicts. Write deduplication test `MyBatisPlusDeduplicationTest`: enable both MyBatis SqlSafetyInterceptor (Task 4.1) and MyBatis-Plus MpSqlSafetyInnerInterceptor simultaneously, execute SQL, verify deduplication filter (Task 2.13) prevents double validation, verify only one validation execution per SQL despite two interceptor layers. Run `mvn test` ensuring all MP integration tests pass.

### Task 4.3 – JDBC Druid Filter Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement Druid connection pool filter intercepting SQL at JDBC layer via FilterAdapter extension, validating PreparedStatement and Statement executions, extracting datasource context from ConnectionProxy, and integrating with Druid's monitoring and filter chain while maintaining minimal performance overhead.
- **Output:**
  - DruidSqlSafetyFilter class extending FilterAdapter from Druid
  - Method overrides: createPreparedStatementProxy(), statement_executeQuery(), statement_executeUpdate()
  - validateSql() method creating SqlContext from JDBC-level information
  - SQL type detection from SQL string prefix (SELECT/UPDATE/DELETE/INSERT)
  - Datasource name extraction from ConnectionProxy for multi-datasource environments
  - Filter registration configuration for DruidDataSource
  - Filter ordering ensuring safety validation runs before StatFilter
  - Integration tests with Druid datasource and connection pooling
  - Compatibility verification with Druid StatFilter, WallFilter, encrypted datasources
- **Guidance:** Druid filter provides JDBC-layer interception catching SQL not passing through MyBatis/MyBatis-Plus layers (direct JDBC usage, JdbcTemplate, other ORM frameworks). FilterAdapter is Druid's filter extension point for custom SQL processing. createPreparedStatementProxy() intercepts PreparedStatement creation capturing SQL at prepare time, statement_executeQuery/Update() intercept Statement executions capturing SQL at execute time. ConnectionProxy provides datasource metadata enabling multi-datasource violation tracking. Filter ordering critical: safety validation must run before StatFilter (Druid's SQL statistics collection) to ensure violations logged with correct context, but after ProtocolFilter (driver communication). Integration with Druid monitoring allows violation metrics in Druid dashboard. Encrypted datasource support ensures compatibility with security-enhanced environments. Performance overhead must be minimal (<5% target) as Druid filters execute on every SQL. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **Druid Filter TDD:** Write test class `DruidSqlSafetyFilterTest` with test methods: `testPreparedStatementInterception_shouldValidate()` (PreparedStatement SQL validated), `testStatementInterception_shouldValidate()` (Statement SQL validated), `testDatasourceExtraction_shouldGetName()` (datasource name extracted from ConnectionProxy), `testSqlTypeDetection_shouldIdentifyCommand()` (SELECT/UPDATE/DELETE/INSERT detected from SQL prefix), `testFilterOrdering_shouldRunBeforeStat()` (safety filter executes before StatFilter in chain), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work). Add Druid 1.2.x dependency to sql-guard-jdbc module POM. Implement `DruidSqlSafetyFilter` class in `com.footstone.sqlguard.interceptor.druid` package extending FilterAdapter from com.alibaba.druid.filter.FilterAdapter. Override createPreparedStatementProxy(), statement_executeQuery(), statement_executeUpdate() methods from design 4.4.1.

2. **validateSql Method Implementation:** Implement `validateSql(String sql, ConnectionProxy connection)` helper method: detect SqlCommandType from SQL prefix using regex matching (\"^\\s*SELECT\" → SELECT, \"^\\s*UPDATE\" → UPDATE, \"^\\s*DELETE\" → DELETE, \"^\\s*INSERT\" → INSERT, case-insensitive), extract datasource name from connection.getDirectDataSource().getName() (Druid ConnectionProxy provides datasource metadata), create mapperId as \"jdbc-druid:\" + datasourceName for JDBC-layer SQL tracking, build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).datasource(datasourceName).build(), call validator.validate(context), handle violations with strategy pattern (BLOCK throws SQLException, WARN/LOG log violations and return). Return result to caller for proceed/block decision.

3. **Filter Method Overrides:** Override `createPreparedStatementProxy(PreparedStatementProxy statement, String sql)` from FilterAdapter: call validateSql(sql, statement.getConnectionProxy()) before creating proxy, if BLOCK strategy and violation detected throw SQLException preventing PreparedStatement creation, otherwise proceed with super.createPreparedStatementProxy(). Override `statement_executeQuery(StatementProxy statement, String sql)` intercepting Statement.executeQuery(): call validateSql(sql, statement.getConnectionProxy()) before execution, handle BLOCK strategy by throwing SQLException, proceed with super.statement_executeQuery() for WARN/LOG. Override `statement_executeUpdate(StatementProxy statement, String sql)` similarly for UPDATE/DELETE/INSERT statements. Note: prepared statement execution (PreparedStatement.execute()) validated at prepare time via createPreparedStatementProxy, so no need to re-validate at execute time (deduplication filter handles this if needed).

4. **Filter Registration and Configuration:** Implement filter registration: create DruidSqlSafetyFilterConfiguration class with method registerFilter(DruidDataSource dataSource): call dataSource.getProxyFilters().add(new DruidSqlSafetyFilter(validator)) adding filter to chain, set filter order via filter.setOrder() ensuring execution before StatFilter (Druid's default filter order: ProtocolFilter=1, StatFilter=2, safety filter should be order=2 or earlier), configure filter in Spring Boot via @Bean method returning DruidSqlSafetyFilter with @Order annotation. Write configuration test `FilterRegistrationTest`: create DruidDataSource, register filter, verify filter added to proxy filters list, verify filter order correct, verify filter executes in chain during SQL execution.

5. **Druid Integration and Performance Testing:** Write integration test `DruidIntegrationTest` with real Druid datasource: create DruidDataSource with H2 database, configure DruidSqlSafetyFilter, execute SQL via JDBC Connection.prepareStatement() and Statement.execute(), verify filter intercepts both PreparedStatement and Statement, verify violations detected and strategy applied, test connection pooling: execute SQL from multiple borrowed connections, verify filter works across pool lifecycle (connection borrow/return), verify no memory leaks or filter state corruption. Write compatibility test `DruidPluginCompatibilityTest`: configure StatFilter + WallFilter + DruidSqlSafetyFilter together, verify all filters coexist without conflicts, verify StatFilter statistics include safety violations, test with encrypted datasource (Druid's ConfigFilter for password decryption), verify filter works with encryption enabled. Write performance test `DruidFilterPerformanceTest`: measure overhead with JMH micro-benchmark, execute 10000 SQL statements with and without filter enabled, calculate overhead percentage, verify <5% target, test under concurrent load (100 threads executing SQL), verify performance degradation acceptable. Run `mvn test` ensuring all Druid tests pass.

### Task 4.4 – JDBC HikariCP Proxy Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement HikariCP ProxyFactory providing Connection dynamic proxy for SQL interception at JDBC layer, capturing PreparedStatement and Statement SQL via nested invocation handlers, validating before actual statement creation/execution, and integrating seamlessly with HikariCP's high-performance connection pooling without disrupting leak detection or pool lifecycle.
- **Output:**
  - HikariSqlSafetyProxyFactory class implementing ProxyFactory interface
  - getProxyConnection() method returning dynamic proxy for Connection
  - ConnectionInvocationHandler intercepting prepareStatement(), prepareCall(), createStatement()
  - StatementInvocationHandler intercepting execute(), executeQuery(), executeUpdate()
  - SQL validation before PreparedStatement/Statement creation and execution
  - HikariConfig integration via setProxyFactory() configuration
  - Proxy compatibility with HikariCP connection leak detection
  - Integration tests with HikariDataSource, batch operations, performance verification
- **Guidance:** HikariCP provides ProxyFactory interface for custom connection proxying enabling SQL interception without filter API (unlike Druid). Dynamic proxy pattern (JDK Proxy or Javassist) wraps Connection objects returned from pool, intercepting method calls. ConnectionInvocationHandler intercepts prepareStatement(sql) capturing SQL at prepare time, createStatement() requiring nested Statement proxy for execute(sql) capture. StatementInvocationHandler wraps PreparedStatement/Statement intercepting actual execution methods. Two-layer proxying required: Connection proxy intercepts statement creation, Statement proxy intercepts execution. HikariCP's leak detection tracks connection usage via ProxyConnection wrapper - custom proxy must preserve this tracking (delegate close() correctly). Batch operations require special handling (addBatch() + executeBatch() pattern). Performance critical as HikariCP targets microsecond-level connection overhead - proxy must add minimal latency. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **ProxyFactory TDD:** Write test class `HikariSqlSafetyProxyFactoryTest` with test methods: `testGetProxyConnection_shouldReturnProxy()` (getProxyConnection() returns dynamic proxy), `testPrepareStatementInterception_shouldValidate()` (Connection.prepareStatement(sql) triggers validation), `testCreateStatementInterception_shouldProxyStatement()` (Connection.createStatement() returns proxied Statement), `testStatementExecuteInterception_shouldValidate()` (Statement.execute(sql) triggers validation), `testProxyDelegation_shouldPreserveConnectionBehavior()` (proxy delegates to real connection correctly), `testLeakDetection_shouldNotBreak()` (HikariCP leak detection works with proxy). Add HikariCP 5.x dependency to sql-guard-jdbc module POM. Implement `HikariSqlSafetyProxyFactory` class in `com.footstone.sqlguard.interceptor.hikari` package implementing ProxyFactory interface from com.zaxxer.hikari.pool.ProxyFactory. Implement getProxyConnection(String delegateClassName, Connection connection) method from design 4.4.2.

2. **ConnectionInvocationHandler Implementation:** Implement `ConnectionInvocationHandler` inner class implementing InvocationHandler: store real Connection delegate and SqlSafetyValidator reference, implement invoke(Object proxy, Method method, Object[] args): intercept prepareStatement(String sql) and prepareCall(String sql) methods checking method name, extract SQL from args[0], call validateSql(sql, delegate) helper validating SQL and applying strategy (BLOCK throws SQLException, WARN/LOG proceed), if validation passes create actual PreparedStatement via delegate.prepareStatement(sql), wrap PreparedStatement in StatementInvocationHandler proxy, return proxied PreparedStatement. Intercept createStatement() similarly: no SQL at creation time, return Statement wrapped in proxy for execute(sql) capture. Delegate all other Connection methods to real connection: return method.invoke(delegate, args) for non-intercepted methods. Handle close() correctly: delegate.close() to preserve HikariCP connection return to pool and leak detection.

3. **StatementInvocationHandler Implementation:** Implement `StatementInvocationHandler` inner class for PreparedStatement/Statement proxying: store real Statement/PreparedStatement delegate and Connection reference (for datasource context), implement invoke(Object proxy, Method method, Object[] args): intercept execute(String sql), executeQuery(String sql), executeUpdate(String sql) methods for Statement (SQL passed as parameter), extract SQL from args[0], validate before execution, proceed with delegate.execute(sql) if validation passes. For PreparedStatement intercept execute(), executeQuery(), executeUpdate() with no SQL parameter (SQL already validated at prepareStatement time), just delegate without re-validation (deduplication filter handles this). Handle batch operations: intercept addBatch(String sql) for Statement (validate each batch SQL), intercept addBatch() for PreparedStatement (no SQL parameter, already validated), intercept executeBatch() (delegate directly, individual SQLs already validated).

4. **HikariCP Configuration and Integration:** Implement HikariConfig integration: create configuration method configureHikariCPSafety(HikariConfig config, SqlSafetyValidator validator): call config.setProxyFactory(new HikariSqlSafetyProxyFactory(validator)) registering custom proxy factory, HikariCP will use this factory for all connection proxying. Write configuration test `HikariConfigurationTest`: create HikariConfig, set ProxyFactory, create HikariDataSource, verify connections returned from pool are proxied, verify prepareStatement() interception works, verify createStatement() returns proxied Statement. Write integration test `HikariIntegrationTest` with real HikariDataSource: execute SQL via prepareStatement() and Statement, verify validation triggers, test batch operations (PreparedStatement.addBatch() + executeBatch()), verify leak detection works (intentionally leak connection, verify HikariCP detects leak despite proxy).

5. **Performance and Edge Case Testing:** Write performance test `HikariProxyPerformanceTest`: measure connection acquisition overhead with and without proxy using JMH, execute getConnection() 100000 times, verify overhead <1% (HikariCP targets microsecond latency, proxy must not degrade significantly), measure SQL execution overhead (prepareStatement + execute 10000 times), verify <5% total overhead. Write edge case test `HikariEdgeCasesTest`: test Connection.close() called multiple times (idempotent), test PreparedStatement reuse (prepare once, execute multiple times with different parameters), verify parameter binding doesn't trigger re-validation, test CallableStatement (stored procedure calls), verify intercepts and validates procedure SQL, test with HikariCP metrics enabled, verify proxy doesn't interfere with connection pool metrics. Run `mvn test` ensuring all HikariCP proxy tests pass.

### Task 4.5 – JDBC P6Spy Listener Implementation │ Agent_Runtime_Interceptor

- **Objective:** Implement universal JDBC interception via P6Spy proxy driver providing fallback SQL validation for any JDBC-compliant connection pool (C3P0, DBCP, Tomcat JDBC) or direct JDBC usage, leveraging P6Spy's JdbcEventListener for onBeforeAnyExecute callback with parameter-substituted SQL, configuring via spy.properties module registration, and documenting as framework-agnostic solution with acceptable performance trade-offs.
- **Output:**
  - P6SpySqlSafetyListener class extending JdbcEventListener
  - onBeforeAnyExecute() method intercepting all SQL executions
  - SQL extraction from StatementInformation.getSqlWithValues() with parameter substitution
  - P6SpySqlSafetyModule for listener registration via SPI
  - spy.properties configuration file registering custom module
  - SqlSafetyValidator initialization via service loader or static factory
  - Integration tests with P6Spy-wrapped datasources and multiple JDBC drivers
  - Compatibility verification with C3P0, DBCP, Tomcat JDBC, raw JDBC
  - Performance impact documentation and overhead measurement
  - Setup guide for P6Spy deployment in production
- **Guidance:** P6Spy provides universal JDBC interception by implementing JDBC Driver interface as proxy driver, wrapping any underlying driver (MySQL, PostgreSQL, Oracle, H2). All JDBC calls pass through P6Spy's JdbcEventListener callbacks regardless of connection pool or ORM framework, making it ideal fallback when pool-specific solutions (Druid filter, HikariCP proxy) unavailable. StatementInformation.getSqlWithValues() provides SQL with actual parameter values substituted (unlike BoundSql with placeholders), useful for validation but with SQL injection risk in logs (sanitize for logging). Module registration via SPI (META-INF/services) allows P6Spy to discover and load custom listener. Performance overhead higher than native solutions (proxy driver adds layer, parameter substitution processing) but acceptable for safety-critical environments - document trade-offs. Setup complexity lower than native integration (just swap driver class and add spy.properties) making it attractive for quick deployment. Depends on: Task 2.13 Output (DefaultSqlSafetyValidator).

1. **P6Spy Listener TDD:** Write test class `P6SpySqlSafetyListenerTest` with test methods: `testOnBeforeAnyExecute_shouldValidate()` (onBeforeAnyExecute callback triggers validation), `testSqlWithValuesExtraction_shouldGetSubstituted()` (StatementInformation provides parameter-substituted SQL), `testPreparedStatementExecution_shouldIntercept()` (PreparedStatement.execute() intercepted), `testStatementExecution_shouldIntercept()` (Statement.execute() intercepted), `testBatchExecution_shouldIntercept()` (executeBatch() intercepted), `testViolationHandling_shouldApplyStrategy()` (BLOCK/WARN/LOG strategies work). Add P6Spy 3.9.x dependency to sql-guard-jdbc module POM. Implement `P6SpySqlSafetyListener` class in `com.footstone.sqlguard.interceptor.p6spy` package extending JdbcEventListener from com.p6spy.engine.event.JdbcEventListener. Implement onBeforeAnyExecute(StatementInformation statementInformation) method from design 4.4.3.

2. **onBeforeAnyExecute Implementation:** Implement callback method: extract SQL via String sql = statementInformation.getSqlWithValues() (P6Spy provides SQL with parameters substituted like \"SELECT * FROM user WHERE id=123\"), detect SqlCommandType from SQL prefix (same as Task 4.3: regex matching SELECT/UPDATE/DELETE/INSERT), create mapperId as \"jdbc-p6spy\" + optional datasource identifier if available from connection metadata, build SqlContext via SqlContext.builder().sql(sql).type(commandType).mapperId(mapperId).build(), call validator.validate(context), handle violations with strategy pattern (BLOCK throws SQLException preventing execution, WARN/LOG log and proceed). Note: P6Spy wraps exceptions - SQLException thrown in listener propagates to caller correctly halting execution.

3. **Module Registration and Configuration:** Implement `P6SpySqlSafetyModule` class extending JdbcEventListener in same package: override constructor calling super() to register listener, implement static initialization acquiring SqlSafetyValidator instance (use ServiceLoader, Spring ApplicationContext lookup, or static factory pattern), store validator reference for listener usage. Create spy.properties file in src/main/resources with content: modulelist=com.footstone.sqlguard.interceptor.p6spy.P6SpySqlSafetyModule (P6Spy loads modules listed here via reflection), optionally add appender=com.p6spy.engine.spy.appender.Slf4JLogger for SLF4J integration, configure driverlist with actual JDBC drivers (e.g., driverlist=com.mysql.cj.jdbc.Driver for MySQL), document URL modification (jdbc:mysql:// → jdbc:p6spy:mysql://) and driver class change (com.mysql.cj.jdbc.Driver → com.p6spy.engine.spy.P6SpyDriver) required for P6Spy activation.

4. **Integration and Compatibility Testing:** Write integration test `P6SpyIntegrationTest` with multiple datasource types: test with bare JDBC (DriverManager.getConnection(\"jdbc:p6spy:h2:mem:test\")), verify SQL intercepted, test with C3P0 (ComboPooledDataSource with P6Spy driver configured), verify connection pooling works with P6Spy, test with DBCP (BasicDataSource with P6Spy), verify compatibility, test with Tomcat JDBC Pool (DataSource with P6Spy), verify interception works. Write multi-driver test `P6SpyMultiDriverTest`: configure P6Spy with MySQL driver (mysql-connector-java dependency), execute SQL, verify interception, configure with PostgreSQL driver (postgresql dependency), execute SQL, verify interception, configure with H2 (in-memory for testing), verify works. All tests should verify: SQL validation executes, violations detected correctly, BLOCK strategy prevents execution, WARN/LOG strategies allow execution.

5. **Performance Documentation and Setup Guide:** Write performance test `P6SpyPerformanceTest` measuring overhead: execute 10000 SQL statements with P6Spy enabled vs raw JDBC, calculate overhead percentage, document findings (expected 10-20% overhead due to proxy driver layer and parameter substitution), compare to native solutions (Druid ~5%, HikariCP ~3%, P6Spy ~15%), note overhead acceptable for safety-critical scenarios but recommend native solutions for performance-sensitive applications. Create setup guide documentation in docs/integration/p6spy-setup.md: document driver class change (original driver → com.p6spy.engine.spy.P6SpyDriver), document URL modification (jdbc:mysql:// → jdbc:p6spy:mysql://), provide spy.properties template with SqlSafetyModule configuration, document deployment scenarios: quick deployment without code changes (just configuration), fallback for unsupported connection pools (C3P0, DBCP when no native integration available), legacy application integration (minimal code impact). Test guide accuracy by following steps exactly on sample project. Run `mvn test` ensuring all P6Spy integration tests pass.

## Phase 5: Build Tool Plugins - Agent_Build_Tools

### Task 5.1 – Maven Plugin Implementation │ Agent_Build_Tools

- **Objective:** Implement production-ready Maven plugin wrapping static scanner as build lifecycle integration, providing Maven-native SQL safety scanning with goal execution, parameter injection from POM configuration, CI/CD failure control via failOnCritical flag, and seamless integration with Maven site generation for report publishing.
- **Output:**
  - SqlScannerMojo class extending AbstractMojo with @Mojo annotation
  - Maven @Parameter fields for configuration (projectPath, configFile, outputFormat, outputFile, failOnCritical)
  - execute() method delegating to SqlScanner core with Maven context integration
  - MojoFailureException throwing for CRITICAL violations in CI/CD pipelines
  - Plugin metadata (plugin.xml descriptor) with lifecycle binding to verify phase
  - Integration tests using maven-plugin-testing-harness validating plugin execution
  - User documentation with POM configuration examples and maven-site-plugin integration
- **Guidance:** Maven plugin provides declarative build integration enabling SQL safety scanning as standard verification step in Maven lifecycle. AbstractMojo provides Maven plugin framework with parameter injection, logging, and execution context. @Mojo annotation declares plugin goal (name="scan") and default lifecycle binding (defaultPhase = LifecyclePhase.VERIFY runs during `mvn verify`). @Parameter injection from POM <configuration> section enables project-specific settings without command-line arguments. MojoFailureException with failOnCritical flag allows CI/CD control: fail build on CRITICAL violations, continue on warnings. SqlScanner reuse from Task 3.7 avoids code duplication - plugin is thin wrapper providing Maven integration. maven-plugin-testing-harness enables plugin testing with mock MavenProject and parameter injection. Plugin metadata generation via maven-plugin-plugin creates descriptor for Maven discovery. Depends on: Task 3.7 Output (SqlScanner core implementation and CLI).

1. **Maven Mojo TDD:** Write test class `SqlScannerMojoTest` with test methods: `testExecute_shouldRunScan()` (execute() triggers scanner), `testProjectPathInjection_shouldUseBasedir()` (projectPath defaults to ${project.basedir}), `testConfigFileParameter_shouldLoad()` (configFile parameter loads YAML), `testOutputFormat_shouldRespect()` (outputFormat=html generates HTML), `testFailOnCritical_shouldThrowException()` (CRITICAL violations + failOnCritical=true throws MojoFailureException), `testFailOnCritical_false_shouldNotThrow()` (failOnCritical=false continues despite violations). Add maven-plugin-api and maven-plugin-annotations dependencies to sql-scanner-maven module POM. Implement `SqlScannerMojo` class in `com.footstone.sqlguard.maven` package extending AbstractMojo from org.apache.maven.plugin.AbstractMojo. Add @Mojo annotation: @Mojo(name = "scan", defaultPhase = LifecyclePhase.VERIFY, threadSafe = true). Define @Parameter fields from design 6.7: @Parameter(defaultValue = "${project.basedir}", readonly = true, required = true) File projectPath, @Parameter(property = "sqlguard.configFile") File configFile, @Parameter(property = "sqlguard.outputFormat", defaultValue = "console") String outputFormat, @Parameter(property = "sqlguard.outputFile") File outputFile, @Parameter(property = "sqlguard.failOnCritical", defaultValue = "false") boolean failOnCritical, @Parameter(defaultValue = "${project}", readonly = true, required = true) MavenProject project.

2. **execute() Method Implementation:** Implement execute() method delegating to SqlScanner core: validate parameters (projectPath exists and is directory, configFile exists if provided, outputFormat valid enum), log scan start via getLog().info("Scanning project: " + projectPath), load configuration via YamlConfigLoader or use defaults (reuse Task 1.3 logic), create ScanContext with projectPath and config, instantiate SqlScanner with all parsers (XmlMapperParser, AnnotationParser, QueryWrapperScanner from Task 3.1), execute ScanReport report = scanner.scan(context), handle exceptions: catch IOException, ParseException wrapping in MojoExecutionException with descriptive message, log scan results via getLog().info("Found " + report.getTotalSqlCount() + " SQL statements"). Generate output: if outputFormat equals "console" call ConsoleReportGenerator.printToConsole(report), if "html" call HtmlReportGenerator.writeToFile(report, outputFile), handle failOnCritical: extract critical violation count from report statistics, if failOnCritical && criticalCount > 0 throw new MojoFailureException("SQL Safety Scan failed: " + criticalCount + " CRITICAL violations found"), otherwise complete successfully allowing build to continue.

3. **Plugin Metadata Configuration:** Configure maven-plugin-plugin in sql-scanner-maven POM to generate plugin descriptor: add maven-plugin-plugin version 3.10.2 to <build><plugins>, configure goalPrefix as "sqlguard" enabling `mvn sqlguard:scan` invocation, plugin descriptor META-INF/maven/plugin.xml generated automatically from @Mojo and @Parameter annotations during package phase. Document plugin goals and parameters: create src/site/apt/usage.apt.vm documenting goal name, parameters (projectPath, configFile, outputFormat, outputFile, failOnCritical), default values, examples. Configure default phase binding: @Mojo defaultPhase = LifecyclePhase.VERIFY binds to verify phase, executes during `mvn verify` without explicit goal invocation. Test plugin descriptor generation: run `mvn clean package`, verify target/classes/META-INF/maven/plugin.xml created with correct goal and parameter metadata.

4. **Integration Testing:** Write integration test using maven-plugin-testing-harness: add maven-plugin-testing-harness dependency (test scope), create test class `SqlScannerMojoIntegrationTest` extending AbstractMojoTestCase. Implement test methods: create test project POM in src/test/resources/test-project/pom.xml with plugin configuration, use lookupMojo("scan", testPom) to instantiate mojo with parameter injection, set additional parameters programmatically if needed, call mojo.execute() and verify scan executes, verify output generated (check console output or HTML file existence), test failOnCritical behavior: configure dangerous SQL in test project, enable failOnCritical, verify MojoFailureException thrown, test parameter injection: verify projectPath from POM, verify configFile loaded, verify outputFormat respected. Create test SQL files in test project: sample MyBatis XMLs with violations, verify scanner detects them. Run `mvn test` ensuring integration tests pass.

5. **User Documentation and Publishing:** Create user documentation in README.md: document plugin usage with example POM configuration showing <plugin> section with groupId com.footstone, artifactId sql-scanner-maven-plugin, version ${project.version}, <configuration> with all parameters, <executions> binding to verify phase. Provide multiple configuration examples: basic usage (defaults), custom config file, HTML output, failOnCritical for CI/CD. Document maven-site-plugin integration: configure maven-site-plugin to include SQL scan report in project site, add <reporting><plugins> section with sql-scanner-maven-plugin, generate site with `mvn site`, verify report appears in project reports. Test plugin on real Maven project: apply plugin to sample project, run `mvn verify`, verify scan executes during build, verify violations detected, verify failOnCritical controls build success/failure. Document command-line property overrides: `mvn sqlguard:scan -Dsqlguard.failOnCritical=true` for ad-hoc execution.

### Task 5.2 – Gradle Plugin Implementation │ Agent_Build_Tools

- **Objective:** Implement production-ready Gradle plugin providing SQL safety scanning as Gradle task with DSL configuration, task input/output caching for incremental builds, multi-version Gradle compatibility (6.x/7.x/8.x), and publication to Gradle Plugin Portal for community distribution.
- **Output:**
  - SqlScannerPlugin class implementing Plugin<Project> from Gradle API
  - SqlScannerExtension DSL class for configuration block (sqlScanner { ... })
  - SqlScannerTask extending DefaultTask with @TaskAction scanning execution
  - Task inputs/outputs configuration for Gradle caching and UP-TO-DATE detection
  - failOnCritical flag throwing GradleException for CI/CD integration
  - Integration tests using Gradle TestKit with multi-version compatibility
  - Plugin publishing configuration for Gradle Plugin Portal (plugin id: com.footstone.sqlguard.scanner)
  - User documentation with Groovy and Kotlin DSL examples
- **Guidance:** Gradle plugin provides imperative and declarative build integration with Gradle's rich task system. Plugin<Project> interface provides apply() entry point for plugin registration. Extension object (SqlScannerExtension) provides type-safe DSL configuration via Gradle's extension mechanism (project.extensions.create). Task (SqlScannerTask) implements scanning logic with @TaskAction annotation triggering execution. Input/output configuration critical for Gradle's incremental build: @InputDirectory for projectPath, @InputFile for configFile, @OutputFile for HTML report enables caching and UP-TO-DATE detection across builds. GradleException with failOnCritical matches Maven's MojoFailureException semantics. Gradle TestKit provides functional testing running actual Gradle builds with plugin applied. Multi-version testing ensures compatibility across Gradle 6.x (minimum supported), 7.x (current), 8.x (latest). Plugin Portal publication enables `plugins { id 'com.footstone.sqlguard.scanner' }` usage. Depends on: Task 3.7 Output (SqlScanner core).

1. **Gradle Plugin TDD:** Write test class `SqlScannerPluginTest` with test methods: `testApply_shouldRegisterExtension()` (plugin apply registers sqlScanner extension), `testApply_shouldCreateTask()` (plugin creates sqlScan task), `testExtensionDefaults_shouldSetCorrectly()` (extension default values match design), `testTaskExecution_shouldRunScan()` (task executes scanner), `testTaskCaching_shouldDetectUpToDate()` (unchanged inputs result in UP-TO-DATE), `testFailOnCritical_shouldThrowException()` (CRITICAL violations + failOnCritical=true throws GradleException). Add Gradle API dependency (compileOnly scope, provided by Gradle runtime) to sql-scanner-gradle module. Implement `SqlScannerPlugin` class in `com.footstone.sqlguard.gradle` package implementing Plugin<Project> from org.gradle.api.Plugin. Implement apply(Project project) method creating extension and task.

2. **Plugin apply() Method:** Implement apply(Project project): create extension via SqlScannerExtension extension = project.getExtensions().create("sqlScanner", SqlScannerExtension.class, project) providing DSL configuration block, create task via TaskProvider<SqlScannerTask> scanTask = project.getTasks().register("sqlScan", SqlScannerTask.class, task -> { task.setGroup("verification"); task.setDescription("Scans SQL for safety violations"); }) registering task lazily for configuration avoidance, wire extension to task: task.getProjectPath().convention(extension.getProjectPath()), task.getConfigFile().convention(extension.getConfigFile()), task.getOutputFormat().convention(extension.getOutputFormat()), etc., configure task dependencies: task depends on compileJava if Java plugin applied (ensures compiled code scanned), task added to check task dependencies for automatic execution during `gradle check`.

3. **Extension and Task Implementation:** Implement `SqlScannerExtension` class with Gradle properties: Property<File> projectPath = project.getObjects().property(File.class).convention(project.getProjectDir()), Property<File> configFile, Property<String> outputFormat.convention("console"), Property<File> outputFile, Property<Boolean> failOnCritical.convention(false). Implement `SqlScannerTask` extending DefaultTask: declare @InputDirectory Property<File> projectPath, @InputFile @Optional Property<File> configFile, @Input Property<String> outputFormat, @OutputFile @Optional Property<File> outputFile (only if HTML format), @Input Property<Boolean> failOnCritical. Implement @TaskAction void scan() method delegating to SqlScanner: validate inputs, load configuration, execute scan (reuse Task 3.7 logic), generate output based on format, handle failOnCritical: if failOnCritical.get() && criticalCount > 0 throw new GradleException("SQL Safety Scan failed: " + criticalCount + " CRITICAL violations"), log results via project.getLogger().lifecycle().

4. **TestKit Integration Testing:** Write integration tests using Gradle TestKit: add gradleTestKit() dependency to sql-scanner-gradle POM testImplementation. Create test class `SqlScannerPluginFunctionalTest`: implement test method testPluginExecution() creating temporary test project directory, writing build.gradle with plugin applied and sqlScanner configuration, writing test SQL files with violations, executing task via GradleRunner runner = GradleRunner.create().withProjectDir(testProjectDir).withPluginClasspath().withArguments("sqlScan").build(), verifying task SUCCESS, verifying output generated. Test caching: execute task twice with same inputs, verify second execution shows UP-TO-DATE, modify SQL file, verify task re-executes. Test failOnCritical: configure critical violations, enable failOnCritical, verify build fails with GradleException. Test multi-version compatibility: run tests against Gradle 6.9, 7.6, 8.5 using GradleRunner.withGradleVersion(), verify plugin works on all versions. Write Kotlin DSL test: create build.gradle.kts with type-safe configuration, verify plugin works with Kotlin DSL syntax. Run `gradle test functionalTest` ensuring all tests pass.

5. **Plugin Portal Publishing:** Configure plugin publishing for Gradle Plugin Portal: add java-gradle-plugin to build.gradle, configure gradlePlugin block: gradlePlugin { plugins { sqlScanner { id = 'com.footstone.sqlguard.scanner', implementationClass = 'com.footstone.sqlguard.gradle.SqlScannerPlugin', displayName = 'SQL Safety Guard Scanner', description = 'Static SQL safety scanner for MyBatis applications' } } }, add plugin-publish plugin for portal publication, configure publishPlugins task with portal credentials. Create plugin marker artifact automatically via java-gradle-plugin. Document plugin usage in README: provide Groovy DSL example (plugins { id 'com.footstone.sqlguard.scanner' version '1.0.0' }), provide Kotlin DSL example (plugins { id("com.footstone.sqlguard.scanner") version "1.0.0" }), document sqlScanner extension configuration block with all properties, document task invocation (`gradle sqlScan` explicit, `gradle check` implicit), provide complete working examples for both DSLs. Test plugin installation from portal (or local plugin repository for testing): apply plugin by id, verify auto-resolution works, verify configuration DSL works. Run `gradle publishPlugins` for portal publication.

## Phase 6: Spring Boot Integration - Agent_Spring_Integration

### Task 6.1 – Auto-Configuration Class Implementation │ Agent_Spring_Integration

- **Objective:** Implement Spring Boot auto-configuration providing zero-configuration SQL safety integration with automatic bean creation, conditional component activation, interceptor registration across MyBatis/MyBatis-Plus/JDBC layers, and seamless Spring Boot ecosystem integration following auto-configuration best practices.
- **Output:**
  - SqlGuardAutoConfiguration class with @Configuration and conditional annotations
  - @Bean methods for JSqlParserFacade, all RuleChecker implementations, DefaultSqlSafetyValidator
  - @ConditionalOnClass guards ensuring beans created only when dependencies present
  - @ConditionalOnMissingBean allowing user overrides of default beans
  - BeanPostProcessor for MyBatis SqlSessionFactory interceptor injection
  - MybatisPlusInterceptor configuration for MyBatis-Plus integration
  - Datasource-specific JDBC interceptor configuration (Druid/HikariCP/P6Spy)
  - META-INF/spring.factories registration for auto-discovery
  - Comprehensive auto-configuration tests with @SpringBootTest validation
- **Guidance:** Spring Boot auto-configuration enables "just add starter" zero-configuration experience. @Configuration + META-INF/spring.factories registration makes SqlGuardAutoConfiguration discoverable by Spring Boot's auto-configuration scanning. @ConditionalOnClass ensures beans only created when required dependencies (MyBatis, MyBatis-Plus, Druid, etc.) present on classpath - prevents startup failures in mixed environments. @ConditionalOnMissingBean allows advanced users to override default beans with custom implementations. BeanPostProcessor pattern required for MyBatis SqlSessionFactory post-processing (interceptor must be added after factory creation). @Order controls interceptor sequence in multi-layer scenarios. Configuration should be idempotent and safe - multiple invocations harmless, missing dependencies graceful. Depends on: Task 2.13 (validator), Tasks 4.1-4.5 (all interceptors).

1. **Auto-Configuration TDD:** Write test class `SqlGuardAutoConfigurationTest` with test methods: `testAutoConfigurationLoads_withAllDependencies()` (all beans created when all deps present), `testValidatorBean_shouldCreate()` (DefaultSqlSafetyValidator bean created), `testConditionalOnClass_withoutMyBatis_shouldNotCreateMyBatisInterceptor()` (MyBatis interceptor not created if MyBatis absent), `testConditionalOnMissingBean_withUserBean_shouldNotOverride()` (user-defined validator bean takes precedence), `testInterceptorRegistration_shouldRegisterInCorrectOrder()` (interceptors registered with correct @Order sequence). Add spring-boot-autoconfigure dependency to sql-guard-spring-boot-starter module POM. Implement `SqlGuardAutoConfiguration` class in `com.footstone.sqlguard.spring.autoconfigure` package with @Configuration annotation. Add @ConditionalOnClass(SqlSafetyValidator.class) ensuring auto-configuration only activates when core module present. Add @EnableConfigurationProperties(SqlGuardProperties.class) binding properties (Task 6.2 dependency).

2. **Core Bean Definitions:** Implement core @Bean methods: @Bean @ConditionalOnMissingBean JSqlParserFacade sqlParserFacade() creating facade with default configuration (lenient mode configurable via properties), @Bean @ConditionalOnMissingBean for each RuleChecker implementation (NoWhereClauseChecker, DummyConditionChecker, BlacklistFieldChecker, WhitelistFieldChecker, all pagination checkers from Task 2.2-2.12), pass SqlGuardProperties to each checker constructor for configuration, @Bean @ConditionalOnMissingBean DefaultSqlSafetyValidator sqlSafetyValidator(List<RuleChecker> checkers, JSqlParserFacade facade) creating validator wiring all autowired checkers. Spring automatically collects all RuleChecker beans into list for validator injection. @ConditionalOnMissingBean allows users to replace default implementations: create custom @Bean with same type, auto-configuration defers to user bean.

3. **Interceptor Registration:** Implement interceptor beans with conditional activation: @Bean @ConditionalOnClass(name = "org.apache.ibatis.plugin.Interceptor") SqlSafetyInterceptor myBatisInterceptor(SqlSafetyValidator validator) from Task 4.1, implement BeanPostProcessor registering interceptor: @Bean SqlSessionFactoryBeanPostProcessor(SqlSafetyInterceptor interceptor) creating BeanPostProcessor, override postProcessAfterInitialization checking if bean instanceof SqlSessionFactory, call sqlSessionFactory.getConfiguration().addInterceptor(interceptor), return bean. For MyBatis-Plus: @Bean @ConditionalOnClass(name = "com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor") MpSqlSafetyInnerInterceptor mpInterceptor(SqlSafetyValidator validator) from Task 4.2, implement BeanPostProcessor for MybatisPlusInterceptor injection if exists. For JDBC: @Bean @ConditionalOnClass(name = "com.alibaba.druid.pool.DruidDataSource") DruidSqlSafetyFilter druidFilter(SqlSafetyValidator validator) from Task 4.3, @Bean @ConditionalOnClass(name = "com.zaxxer.hikari.HikariDataSource") HikariSqlSafetyProxyFactory hikariProxyFactory(SqlSafetyValidator validator) from Task 4.4, configure via BeanPostProcessor or direct datasource configuration.

4. **Auto-Configuration Testing:** Write Spring Boot test `SqlGuardAutoConfigurationIntegrationTest` using @SpringBootTest: create test Spring Boot application with sql-guard-spring-boot-starter dependency, configure minimal application.yml, inject SqlSafetyValidator via @Autowired and verify not null, inject all RuleChecker beans via @Autowired List<RuleChecker> and verify expected count, verify interceptors registered: inject SqlSessionFactory and verify interceptor present in configuration.getInterceptors(). Test conditional bean creation: create test with MyBatis excluded from classpath, verify MyBatis interceptor not created (use @ConditionalOnMissingClass test configuration), create test with Druid datasource, verify DruidSqlSafetyFilter created, create test with HikariCP datasource, verify HikariSqlSafetyProxyFactory created. Test user override: define custom @Bean DefaultSqlSafetyValidator in test configuration, verify user bean used instead of auto-configured bean.

5. **Spring Boot Integration:** Create META-INF/spring.factories file in sql-guard-spring-boot-starter/src/main/resources: register org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.footstone.sqlguard.spring.autoconfigure.SqlGuardAutoConfiguration enabling auto-discovery. Test auto-configuration loading: create minimal Spring Boot app with just starter dependency, run SpringApplication.run(), verify auto-configuration loads automatically (check logs for auto-configuration report), verify beans created without manual @Import or @EnableSqlGuard annotation. Test auto-configuration ordering: configure @AutoConfigureAfter(DataSourceAutoConfiguration.class) ensuring SQL guard configures after datasource, configure @AutoConfigureBefore if needed for specific integrations, verify ordering correct via Spring Boot Actuator conditions report endpoint. Run `mvn test` ensuring all auto-configuration tests pass.

### Task 6.2 – Configuration Properties Binding │ Agent_Spring_Integration

- **Objective:** Implement type-safe Spring Boot configuration properties with @ConfigurationProperties binding, JSR-303 validation, nested property support, IDE autocomplete via metadata generation, sensible defaults, and profile-specific configuration enabling declarative YAML-based SQL guard configuration.
- **Output:**
  - SqlGuardProperties class with @ConfigurationProperties(prefix="sql-guard")
  - Nested static classes for all rule configurations matching design 5.1 structure
  - @NestedConfigurationProperty annotations for nested config binding
  - JSR-303 validation annotations (@NotNull, @Min, @Max) with fail-fast validation
  - spring-configuration-metadata.json for IDE autocomplete and documentation
  - Default values matching SqlGuardConfigDefaults from Phase 1 Task 1.3
  - @RefreshScope support for dynamic config updates with Spring Cloud Config
  - Integration with auto-configuration via constructor injection
  - Comprehensive property binding tests with profile-specific configurations
- **Guidance:** @ConfigurationProperties provides type-safe binding from application.yml to Java objects with validation and IDE support. Prefix "sql-guard" maps all sql-guard.* properties to SqlGuardProperties fields. Nested static classes mirror YAML structure: sql-guard.rules.noWhereClause.* → NoWhereClauseProperties. @NestedConfigurationProperty tells Spring Boot to recursively bind nested objects. JSR-303 validation (@Validated + annotations) enforces constraints at startup preventing invalid configurations. spring-configuration-metadata.json generated from Javadoc provides IDE autocomplete showing available properties with descriptions. Sensible defaults from SqlGuardConfigDefaults ensure zero-configuration works out-of-box. Profile-specific configs (application-{profile}.yml) enable environment-specific behavior: dev=LOG, prod=BLOCK. @RefreshScope with Spring Cloud Config enables runtime config reload without restart. Depends on: Task 1.3 (SqlGuardConfigDefaults).

1. **Properties Class TDD:** Write test class `SqlGuardPropertiesTest` with test methods: `testYamlBinding_shouldBindAllProperties()` (YAML properties bind to Java fields), `testNestedProperties_shouldBindRecursively()` (nested configs bind correctly), `testDefaults_shouldMatchDesign()` (default values match design 5.1), `testValidation_withInvalidValues_shouldFail()` (JSR-303 validation catches invalid configs), `testValidation_withValidConfig_shouldPass()` (valid config passes validation). Add spring-boot-configuration-processor dependency (optional, annotation processor) to sql-guard-spring-boot-starter for metadata generation. Implement `SqlGuardProperties` class in com.footstone.sqlguard.spring.config package with @ConfigurationProperties(prefix = "sql-guard") and @Validated annotations. Define root fields: boolean enabled = true, String activeStrategy = "prod", InterceptorsConfig interceptors = new InterceptorsConfig(), DeduplicationConfig deduplication = new DeduplicationConfig(), RulesConfig rules = new RulesConfig().

2. **Nested Configuration Classes:** Implement nested static classes mirroring design 5.1 YAML structure: public static class InterceptorsConfig { @NestedConfigurationProperty MyBatisConfig mybatis = new MyBatisConfig(); @NestedConfigurationProperty MyBatisPlusConfig mybatisPlus = new MyBatisPlusConfig(); @NestedConfigurationProperty JdbcConfig jdbc = new JdbcConfig(); }, public static class MyBatisConfig { boolean enabled = true; }, public static class DeduplicationConfig { boolean enabled = true; @Min(1) int cacheSize = 1000; @Min(1) long ttlMs = 100; }, public static class RulesConfig { @NestedConfigurationProperty NoWhereClauseProperties noWhereClause = new NoWhereClauseProperties(); @NestedConfigurationProperty PaginationAbuseProperties paginationAbuse = new PaginationAbuseProperties(); /* ... all 7 rule properties */ }. Implement rule property classes: public static class NoWhereClauseProperties { boolean enabled = true; RiskLevel riskLevel = RiskLevel.CRITICAL; }, similar for all rules from Tasks 2.2-2.12 with appropriate defaults.

3. **Validation and Metadata:** Add JSR-303 validation: @NotNull on required fields, @Min/@Max on numeric constraints (cacheSize > 0, ttlMs > 0, pagination maxOffset > 0), custom @Constraint for complex validation if needed (e.g., outputFormat must be "console" or "html"). Generate spring-configuration-metadata.json: add comprehensive Javadoc to all properties explaining purpose, valid values, defaults, ensure spring-boot-configuration-processor generates metadata during compilation, verify target/classes/META-INF/spring-configuration-metadata.json created with all properties documented. Test metadata in IDE: create sample application.yml, verify IDE autocomplete shows sql-guard.* properties with descriptions, verify validation warnings for invalid values.

4. **Integration with Auto-Configuration:** Inject SqlGuardProperties into SqlGuardAutoConfiguration via constructor: @EnableConfigurationProperties(SqlGuardProperties.class) on auto-configuration class, inject via constructor parameter: public SqlGuardAutoConfiguration(SqlGuardProperties properties), use properties to configure beans: pass properties.getRules().getNoWhereClause() to NoWhereClauseChecker constructor, pass properties.getActiveStrategy() to interceptor for strategy selection, pass properties.getDeduplication() to validator for deduplication config. Implement @RefreshScope support: annotate DefaultSqlSafetyValidator or config holder bean with @RefreshScope if spring-cloud-context present, add @ConditionalOnClass guard for RefreshScope, implement config reload hook calling validator.reloadConfig(newProperties), test with Spring Cloud Config Server: change config value, trigger /actuator/refresh endpoint, verify validator uses new config without app restart.

5. **Property Binding Tests:** Write comprehensive test `SqlGuardPropertiesBindingTest` with sample YAML configs in src/test/resources: application-test.yml with all properties configured, application-defaults.yml with minimal config testing defaults, application-invalid.yml with invalid values for validation testing. Test scenarios: load application-test.yml via @TestPropertySource, inject SqlGuardProperties, verify all values match YAML, test nested binding (rules.noWhereClause.enabled binds to properties.getRules().getNoWhereClause().isEnabled()), test defaults: load minimal config, verify default values applied, test validation: load invalid config, verify Spring Boot startup fails with BindException or ValidationException, verify error message indicates which property invalid. Test profile-specific configs: create application-dev.yml (activeStrategy=LOG), application-prod.yml (activeStrategy=BLOCK), activate profiles via @ActiveProfiles("dev"), verify correct config loaded. Run `mvn test` ensuring all binding tests pass.

### Task 6.3 – Config Center Extension Points │ Agent_Spring_Integration

- **Objective:** Implement extension point architecture for config center integration enabling hot-reload from Apollo and Nacos configuration centers, providing ConfigCenterAdapter SPI, implementing adapters with @ConditionalOnClass guards, integrating with validator for thread-safe runtime config updates, and documenting extension pattern for custom config center implementations.
- **Output:**
  - ConfigCenterAdapter interface defining config reload contract
  - ConfigChangeEvent class encapsulating changed property information
  - ApolloConfigCenterAdapter with @ApolloConfigChangeListener integration
  - NacosConfigCenterAdapter with @NacosConfigListener integration
  - ConfigReloadSupport in DefaultSqlSafetyValidator for thread-safe reload
  - Cache invalidation on config change (deduplication cache, JSqlParser cache)
  - @ConditionalOnClass guards ensuring adapters only activate when dependencies present
  - Integration tests with embedded/mock config centers
  - Extension point documentation for custom adapter implementation
- **Guidance:** Config center integration enables runtime configuration updates without application restart - critical for production tuning (adjust risk levels, enable/disable rules, change strategies). ConfigCenterAdapter provides uniform interface abstracting Apollo/Nacos differences. @ConditionalOnClass ensures adapters only created when Apollo/Nacos client libraries present - prevents startup failures in environments without config centers. Thread-safe reload essential as config changes occur asynchronously - use AtomicReference or volatile for config holder, synchronize validator state updates. Cache invalidation required to prevent stale validation: deduplication cache from Task 2.13 must be cleared, JSqlParser cache from Task 1.4 should be cleared. Extension point pattern allows custom implementations: document adapter interface, provide example implementation, support ServiceLoader discovery. Depends on: Task 2.13 (validator with reload support), Task 6.2 (properties binding).

1. **Extension Point Interface TDD:** Write test class `ConfigCenterAdapterTest` with test methods: `testOnConfigChange_shouldNotifyListeners()` (config change triggers notification), `testReloadConfig_shouldUpdateProperties()` (reloadConfig updates SqlGuardProperties), `testConfigChangeEvent_shouldContainChangedKeys()` (event contains which properties changed). Define `ConfigCenterAdapter` interface in com.footstone.sqlguard.spring.config.center package with methods: void onConfigChange(ConfigChangeEvent event) (callback when config changes), void reloadConfig() (trigger full config reload), optional default methods for common functionality. Define `ConfigChangeEvent` class with fields: Map<String, String> changedKeys (property key → new value), String namespace (config namespace/group), long timestamp (change timestamp). Provide helper methods: boolean hasChanged(String key), String getNewValue(String key).

2. **Apollo Adapter Implementation:** Implement `ApolloConfigCenterAdapter` class in config.center.apollo package with @Configuration and @ConditionalOnClass(name = "com.ctrip.framework.apollo.Config") annotations ensuring only activated when Apollo client present: inject ApolloConfig via constructor, inject SqlGuardProperties for binding refresh, implement method annotated with @ApolloConfigChangeListener: @ApolloConfigChangeListener void onChange(ConfigChangeEvent changeEvent) { log.info("Apollo config changed: {}", changeEvent.changedKeys()); rebindProperties(changeEvent); notifyValidator(); }, implement rebindProperties extracting changed values from Apollo, updating SqlGuardProperties fields (use reflection or property binding), implement notifyValidator calling validator.reloadConfig(updatedProperties), register adapter as Spring bean in auto-configuration via @Bean @ConditionalOnClass method. Handle namespaces: support multiple Apollo namespaces via configuration, monitor all namespaces containing sql-guard.* properties.

3. **Nacos Adapter Implementation:** Implement `NacosConfigCenterAdapter` class in config.center.nacos package with @Configuration and @ConditionalOnClass(name = "com.alibaba.nacos.api.config.ConfigService") annotations: inject NacosConfigManager via constructor, inject SqlGuardProperties, implement method annotated with @NacosConfigListener: @NacosConfigListener(dataId = "${nacos.config.data-id:sql-guard}", groupId = "${nacos.config.group:DEFAULT_GROUP}") void onConfigChange(String configInfo) { log.info("Nacos config changed"); parseAndRebindProperties(configInfo); notifyValidator(); }, implement parseAndRebindProperties parsing YAML/properties from configInfo string, binding to SqlGuardProperties, implement notifyValidator similarly to Apollo adapter. Support dynamic dataId/groupId from configuration. Test both YAML and properties formats: Nacos supports both, adapter should detect format and parse accordingly.

4. **Validator Reload Integration:** Implement ConfigReloadSupport in DefaultSqlSafetyValidator: add private volatile SqlGuardConfig config field or use AtomicReference<SqlGuardConfig> for thread-safe updates, implement public void reloadConfig(SqlGuardConfig newConfig) method: validate newConfig via config.validate() from Task 1.3, atomically swap config reference, invalidate deduplication cache (call deduplicationFilter.clearAll()), invalidate JSqlParser cache (call jsqlParserFacade.clearCache() from Task 1.4), log config change at INFO level with changed fields, notify all RuleChecker instances of config change if stateful (most are stateless, config passed on each check). Test thread-safety: execute validation concurrent with config reload, verify no race conditions, verify atomicity (validation uses old or new config consistently, never partial state), verify cache invalidation prevents stale results.

5. **Integration and Extension Documentation:** Write integration test `ConfigCenterIntegrationTest` for Apollo: use embedded Apollo mock server or @MockBean ApolloConfig, trigger config change via Apollo API, verify SqlGuardProperties updated, verify validator uses new config, execute SQL validation and verify new rules applied. Write integration test for Nacos: use Nacos embedded server or mock, publish config change, verify hot-reload works. Test without config center: start app without Apollo/Nacos dependencies, verify adapters not created (@ConditionalOnClass prevents), verify static config still works. Create docs/integration/config-center-extension.md documenting: ConfigCenterAdapter interface contract, how to implement custom adapter (step-by-step with code example), how to register custom adapter (Spring bean registration, ServiceLoader pattern), example for custom config center (etcd, Consul, Zookeeper), troubleshooting guide. Run `mvn test` ensuring all config center tests pass.

## Phase 7: Examples & Documentation - Agent_Testing_Documentation

### Task 7.1 – Dangerous SQL Pattern Samples │ Agent_Testing_Documentation

- **Objective:** Create comprehensive example repository demonstrating all dangerous SQL patterns detected by system, providing educational samples with explanatory comments, BAD and GOOD versions for comparison, integration test validating scanner accuracy, and regression test suite preventing future false negatives.
- **Output:**
  - Examples module with sample MyBatis XML mappers for all violation types
  - Sample annotation-based mappers (@Select/@Update/@Delete) with dangerous patterns
  - Sample MyBatis-Plus service classes using QueryWrapper with problematic conditions
  - Organized samples by violation type with explanatory headers
  - BAD versions (violating patterns) and GOOD versions (corrected patterns) for each violation
  - Comprehensive comments explaining why dangerous, expected violation message, suggested fix
  - References to design document sections for each pattern
  - Integration test running scanner on examples validating detection accuracy
  - Regression test suite ensuring scanner catches all expected violations
- **Guidance:** Examples serve triple purpose: education for developers learning system, validation that scanner works correctly, regression prevention ensuring future changes don't break detection. Organize by violation type (no-WHERE, dummy-condition, blacklist-only, etc.) mirroring rule checker tasks (2.2-2.12) for easy reference. Each sample file should be self-documenting with header comment block explaining pattern, why dangerous, real-world impact, fix recommendation. BAD/GOOD pair pattern enables developers to see problem and solution side-by-side - critical for training and onboarding. Integration test with scanner provides automated validation: scan BAD examples, assert expected violations detected, scan GOOD examples, assert zero violations. Regression test prevents scanner degradation over time. Depends on: Task 3.7 (scanner CLI for testing).

- **MyBatis XML Examples:** Create examples/src/main/resources/mappers/bad/ directory with sample XMLs: NoWhereClauseMapper.xml (DELETE/UPDATE without WHERE, SELECT without WHERE), DummyConditionMapper.xml (WHERE 1=1, WHERE true, WHERE 'a'='a'), BlacklistOnlyMapper.xml (WHERE deleted=0, WHERE status='active' AND enabled=1), WhitelistViolationMapper.xml (user table query missing id/user_id from whitelist), LogicalPaginationMapper.xml (using RowBounds without PageHelper plugin configured), NoConditionPaginationMapper.xml (SELECT * FROM user LIMIT 100 without WHERE), DeepPaginationMapper.xml (LIMIT 20 OFFSET 50000), LargePageSizeMapper.xml (LIMIT 5000), MissingOrderByMapper.xml (paginated SELECT without ORDER BY), NoPaginationMapper.xml (SELECT * FROM large_table without pagination), CombinedViolationsMapper.xml (multiple violations in single SQL). Create examples/src/main/resources/mappers/good/ directory with corrected versions: each file mirrors bad/ structure but with fixes applied (proper WHERE clauses, PageHelper configuration, reasonable pagination parameters, ORDER BY added). Add XML comment headers to each file explaining pattern, expected violation, fix applied.

- **Annotation and QueryWrapper Examples:** Create examples/src/main/java/com/footstone/sqlguard/examples/bad/ with annotation mappers: NoWhereClauseAnnotationMapper.java (@Select/@Update/@Delete without WHERE), DummyConditionAnnotationMapper.java (@Select with WHERE 1=1), similar for all patterns. Create service classes: BadQueryWrapperService.java using QueryWrapper with empty wrapper (no conditions), blacklist-only wrapper (only status/deleted fields), no pagination on large tables. Create examples/src/main/java/.../good/ with corrected versions: proper WHERE in annotations, QueryWrapper with proper conditions, pagination applied. Add Javadoc comments to each class explaining pattern and fix.

- **Organization and Documentation:** Create examples/README.md explaining: purpose of examples, directory structure (bad/ vs good/), how to run scanner on examples, how each example maps to design sections and rule checkers, index of all examples by violation type. For each example file, add comprehensive header comment: /* VIOLATION: No WHERE Clause (CRITICAL) * PATTERN: DELETE FROM user * WHY DANGEROUS: Deletes entire table, catastrophic data loss * REAL-WORLD IMPACT: Production incident, customer data loss * EXPECTED MESSAGE: "SQL语句缺少WHERE条件,可能导致全表操作" * FIX: Add WHERE clause with business condition or unique key * DESIGN REFERENCE: Section 3.3.1, Task 2.2 * GOOD VERSION: See mappers/good/NoWhereClauseMapper.xml */. Reference design document sections linking examples to specifications.

- **Integration and Regression Testing:** Create test class `ExamplesValidationTest` in examples module: implement testScanBadExamples_shouldDetectAllViolations() running scanner CLI on bad/ directory, parsing output, asserting each expected violation detected with correct risk level, implement testScanGoodExamples_shouldPassAllChecks() running scanner on good/ directory, asserting zero violations. Create detailed assertions: for NoWhereClauseMapper.xml expect CRITICAL violation with message containing "缺少WHERE条件", for DummyConditionMapper.xml expect HIGH violation with "无效条件", etc. Implement regression test testAllKnownPatterns_shouldBeDetected() maintaining list of all known dangerous patterns, asserting scanner detects each one, preventing future changes from breaking detection. Run tests during CI build: if examples validation fails, block merge preventing regression. Use examples as acceptance test: new rule checkers must add corresponding examples, verify detection works, update regression test. Run `mvn test` in examples module ensuring validation passes.

### Task 7.2 – Spring Boot Demo Project │ Agent_Testing_Documentation

- **Objective:** Create production-ready Spring Boot demonstration application showcasing SQL Safety Guard System integration with real-world MyBatis/MyBatis-Plus usage, interactive REST endpoints triggering all violation types, comprehensive README with usage instructions, Docker Compose environment for quick deployment, and validation testing ensuring demo accurately represents system capabilities for evaluation and onboarding.
- **Output:**
  - Complete Spring Boot application with sql-guard-spring-boot-starter dependency
  - application.yml with comprehensive configuration demonstrating all settings from design 5.1
  - Sample domain entities (User, Order, Product) with MyBatis XML mappers and annotation mappers
  - Sample MyBatis-Plus services using QueryWrapper demonstrating common patterns
  - REST controller with endpoints triggering each violation type on demand
  - Violation log dashboard endpoint returning recent violations with details
  - Configuration management endpoint demonstrating hot-reload with config center
  - Comprehensive demo README with setup instructions, usage examples, troubleshooting
  - Docker Compose environment with MySQL database, demo app, optional Apollo/Nacos
  - Pre-populated database schema and test data for immediate demonstration
  - Validation tests ensuring demo triggers expected violations correctly
- **Guidance:** Demo application serves as live proof-of-concept for evaluating SQL Safety Guard before adoption, educational tool for developers learning system usage, and integration test validating end-to-end functionality. Application must demonstrate real-world scenarios: typical Spring Boot app structure, common MyBatis patterns (XML mappers + annotation mappers + MyBatis-Plus), REST API exposing business operations. Interactive endpoints critical for evaluation: users can trigger specific violations via HTTP requests, observe BLOCK/WARN/LOG strategies in action, toggle configuration dynamically. Docker Compose essential for easy evaluation: users run `docker-compose up` and demo starts with database pre-populated, no manual setup required. README must be comprehensive: non-technical managers evaluating tool should understand value proposition, developers should know how to integrate into existing projects. Depends on: Tasks 6.1-6.3 (Spring Boot integration complete), Tasks 2.2-2.12 (all rule checkers for violation demonstration), Tasks 4.1-4.5 (runtime interception for BLOCK strategy demonstration).

1. **Spring Boot Application Structure:** Create sql-guard-demo module in examples/ directory with standard Spring Boot structure: src/main/java/com/footstone/sqlguard/demo, src/main/resources, src/test/java. Add sql-guard-spring-boot-starter dependency to pom.xml along with spring-boot-starter-web for REST API, mybatis-spring-boot-starter for MyBatis integration, mybatis-plus-boot-starter for MyBatis-Plus features, mysql-connector-java for database connectivity, lombok for entity boilerplate reduction, spring-boot-starter-test for testing. Create `DemoApplication` main class with @SpringBootApplication annotation and SpringApplication.run() entry point. Configure application.yml in src/main/resources: datasource configuration (jdbc:mysql://localhost:3306/sqlguard_demo), MyBatis configuration (mapper locations, type aliases package), sql-guard configuration mirroring design 5.1 with all rules enabled, activeStrategy=LOG initially for safe demo, interceptors configuration enabling MyBatis/MyBatis-Plus/JDBC layers. Create application-block.yml profile with activeStrategy=BLOCK for blocking mode demonstration, application-warn.yml with activeStrategy=WARN for warning mode.

2. **Sample Domain Model and Mappers:** Create sample entities in com.footstone.sqlguard.demo.entity package: User entity (id, username, email, status, deleted, createTime), Order entity (id, userId, totalAmount, status, orderTime), Product entity (id, name, price, stock, categoryId). Create MyBatis XML mappers in src/main/resources/mapper demonstrating various patterns: UserMapper.xml with safe query (SELECT * FROM user WHERE id = #{id}), unsafe query for demo (deleteAllUsers without WHERE for demo endpoint), query with dummy condition (WHERE 1=1) for demo, query with blacklist-only (WHERE deleted=0) for demo, deep pagination query (LIMIT 20 OFFSET 50000) for demo. Create annotation-based mappers: UserAnnotationMapper interface with @Select/@Update/@Delete demonstrating both safe and unsafe patterns for demo purposes. Create MyBatis-Plus mappers: UserMybatisPlusMapper extending BaseMapper<User>, OrderService using QueryWrapper with methods demonstrating safe wrapper (queryWrapper.eq("id", id)) and unsafe empty wrapper for demo. Annotate unsafe methods with comments explaining they're intentionally dangerous for demo purposes.

3. **Interactive Demo REST Endpoints:** Create DemoController in com.footstone.sqlguard.demo.controller package with REST endpoints triggering each violation type: @GetMapping("/violations/no-where-clause") executing DELETE/UPDATE without WHERE (returns violation details caught by guard), @GetMapping("/violations/dummy-condition") executing query with WHERE 1=1, @GetMapping("/violations/blacklist-only") executing query with only status/deleted conditions, @GetMapping("/violations/whitelist-missing") executing user table query without id/user_id from whitelist, @GetMapping("/violations/logical-pagination") executing query with RowBounds without PageHelper configured, @GetMapping("/violations/deep-pagination") executing query with LIMIT 20 OFFSET 50000, @GetMapping("/violations/large-page-size") executing query with LIMIT 5000, @GetMapping("/violations/missing-orderby") executing paginated query without ORDER BY, @GetMapping("/violations/no-pagination") executing SELECT * FROM large_table without pagination. Each endpoint should return violation details (risk level, message, SQL) when caught, or success response if strategy=LOG/WARN. Create @GetMapping("/violations/logs") endpoint returning recent violations from in-memory log or database log table. Create @PostMapping("/config/strategy/{strategy}") endpoint allowing runtime strategy change (LOG/WARN/BLOCK) demonstrating configuration hot-reload if config center present.

4. **Docker Compose and Database Setup:** Create docker-compose.yml in demo root: MySQL 8.0 service (sqlguard-mysql) with environment variables (MYSQL_ROOT_PASSWORD, MYSQL_DATABASE=sqlguard_demo), port 3306 exposed, volume for data persistence, init script mounting. Demo app service (sqlguard-demo-app) building from Dockerfile, depends_on sqlguard-mysql, environment variables for datasource URL/credentials, port 8080 exposed. Optional Apollo service for config center demo (apolloconfig/apollo-quick-start image). Optional Nacos service for alternative config center demo (nacos/nacos-server image). Create init.sql in src/main/resources/db creating tables (user, order, product) with schema matching entities, inserting test data (100 users, 500 orders, 50 products) providing realistic dataset for demo queries. Create Dockerfile for demo app: FROM openjdk:11-jre-slim, COPY target/sql-guard-demo.jar, EXPOSE 8080, ENTRYPOINT ["java", "-jar", "sql-guard-demo.jar"]. Test Docker Compose: run `docker-compose up`, verify MySQL starts and initializes with test data, verify demo app connects to database, verify http://localhost:8080 accessible.

5. **Demo README and Validation Testing:** Create examples/sql-guard-demo/README.md with comprehensive documentation: **Overview** section explaining SQL Safety Guard demo purpose, **Features Demonstrated** list (all 7 rule types, 3 violation strategies, hot-reload, multi-layer interception), **Quick Start** with prerequisites (Docker + Docker Compose) and `docker-compose up` command, **Running Without Docker** with Maven instructions (mvn spring-boot:run), **Demo Endpoints** table listing all violation trigger endpoints with descriptions and expected responses, **Testing Different Strategies** showing how to switch between LOG/WARN/BLOCK modes using profiles or config endpoint, **Violation Examples** section with curl commands demonstrating each violation type with expected output, **Configuration Hot-Reload** section demonstrating Apollo/Nacos integration if running, **Troubleshooting** section for common issues (port conflicts, database connection failures). Add screenshots or ASCII art showing violation log output, BLOCK strategy SQLException response. Create test class `DemoApplicationTest` in src/test/java: test Spring Boot context loads successfully (@SpringBootTest), test each violation endpoint with RestTemplate verifying expected behavior (LOG strategy allows execution with log, BLOCK strategy throws exception), test violation logs endpoint returns violations with correct details, test configuration endpoint changes strategy successfully. Test demo end-to-end: start Docker Compose environment, execute curl commands from README against each violation endpoint, verify violations logged correctly, verify BLOCK mode prevents dangerous SQL execution, verify WARN mode logs but allows execution, take screenshots for README. Run `mvn clean package` and `docker-compose up` ensuring demo builds and runs successfully.

### Task 7.3 – User Documentation │ Agent_Testing_Documentation

- **Objective:** Create comprehensive user-facing documentation enabling successful adoption across all user personas (developers integrating system, DevOps deploying to production, managers evaluating value), providing quick-start guides, detailed configuration reference, troubleshooting resources, and phased deployment guidance ensuring safe production rollout following design 8.2 strategy.
- **Output:**
  - Professional README.md in project root with overview, features, quick-start, badges
  - docs/user-guide/ directory with installation, configuration, usage, deployment guides
  - Rule checker reference documentation for all 7 violation types with examples and fixes
  - Phased deployment guide (observation → warning → blocking) with environment-specific configs
  - Performance tuning guide covering deduplication, cache sizing, overhead optimization
  - Comprehensive FAQ and troubleshooting section addressing common issues
  - All documentation with clear examples, code snippets, configuration samples
- **Guidance:** User documentation critical for adoption success: poor docs lead to integration failures, support burden, abandonment. Target three personas: developers need integration instructions and API reference, DevOps needs deployment and configuration guidance, managers need value proposition and success metrics. README is first impression: must be professional with clear value proposition, visual elements (architecture diagram, badges), and 5-minute quick-start getting users to success fast. Configuration reference must be exhaustive: every YAML property documented with type, default, valid values, example - users should never need to read source code. Phased deployment guide essential for risk mitigation: design 8.2 three-phase rollout (LOG for observation, WARN for validation, BLOCK for enforcement) prevents production incidents during adoption. Performance tuning critical for large-scale deployment: document deduplication effectiveness, cache sizing impact, overhead benchmarks. FAQ prevents support tickets: address known issues (JSqlParser limitations, false positives, integration conflicts) proactively. Depends on: All phases output for complete documentation of all features.

1. **Professional README.md:** Create README.md in project root with compelling structure: **Badges** section at top with Maven Central version, build status (GitHub Actions), code coverage (Codecov), license (Apache 2.0), stars/forks. **Overview** section with elevator pitch: "SQL Safety Guard: Automated SQL safety validation for MyBatis applications preventing catastrophic production incidents through static scanning and runtime interception." Key features list with icons/emojis: ✅ Detects 7 types of dangerous SQL patterns, ✅ Dual-layer protection (static + runtime), ✅ Zero-config Spring Boot starter, ✅ <5% performance overhead, ✅ Phased deployment support (LOG/WARN/BLOCK). **Architecture** section with high-level diagram showing scanning flow and interception flow. **Quick Start** section with 5-minute integration: Maven dependency snippet for Spring Boot starter, minimal application.yml config, "You're protected! Dangerous SQL will now be blocked." **Documentation Links** pointing to detailed guides in docs/. **Contributing** and **License** sections. **Real-World Impact** section with testimonials or metrics if available: "Prevented X production incidents at Y company." Keep README concise (2-3 screens), visually appealing with proper markdown formatting, code syntax highlighting, emoji accents.

2. **Installation and Configuration Guides:** Create docs/user-guide/installation.md with platform-specific instructions: **Maven Integration** section with parent POM dependencyManagement snippet (for library users), Spring Boot starter dependency for Spring Boot apps, standalone dependency for non-Spring projects. **Gradle Integration** section with equivalent Gradle dependency configurations using Kotlin DSL and Groovy DSL examples. **Version Compatibility Matrix** table showing supported Java versions (8/11/17/21), MyBatis versions (3.4.6+, 3.5.13+), MyBatis-Plus versions (3.4.0+, 3.5.3+), Spring Boot versions (2.x, 3.x). **Build Tool Plugin Installation** for scanner CLI: Maven plugin configuration with execution binding to verify phase, Gradle plugin application and task configuration. Create docs/user-guide/configuration-reference.md documenting every YAML property: organize by category matching design 5.1 structure (rules, interceptors, deduplication, activeStrategy), for each property provide: name, type, default value, valid values/range, description, example YAML snippet. Document strategy hierarchy: activeStrategy with global default, strategyProfiles for environment-specific overrides, per-rule strategy override capability. Include complete example configurations: minimal config (just starter dependency, all defaults), development config (LOG strategy, all rules enabled with verbose logging), production config (BLOCK strategy, optimized deduplication, monitoring integration).

3. **Rule Checker Documentation:** Create docs/user-guide/rules/ directory with one markdown file per rule type: no-where-clause.md, dummy-condition.md, blacklist-whitelist.md, logical-pagination.md, pagination-abuse.md (covering no-condition, deep-offset, large-page-size), missing-orderby.md, no-pagination.md. For each rule document: **Risk Level** (CRITICAL/HIGH/MEDIUM/LOW from design), **What It Detects** section with SQL pattern description, **Why Dangerous** section explaining real-world impact with production incident examples, **Examples** section with BAD SQL (triggering violation) and GOOD SQL (corrected version) side-by-side, **Expected Message** showing exact violation message users will see, **How to Fix** with step-by-step remediation guidance, **Configuration** showing how to adjust risk level or disable rule if needed (with warning about security implications), **Design Reference** linking to design document section. Use consistent template across all rule docs for easy navigation. Add index page docs/user-guide/rules/README.md listing all rules with risk levels and one-line descriptions.

4. **Deployment and Performance Guides:** Create docs/user-guide/deployment.md documenting phased rollout strategy from design 8.2: **Phase 1: Observation Mode (1-2 weeks)** section with activeStrategy=LOG configuration, instructions to monitor logs identifying violations without blocking, guidance on analyzing violation frequency and false positive rate, decision criteria for proceeding to Phase 2. **Phase 2: Warning Mode (1-2 weeks)** section with activeStrategy=WARN configuration, instructions to validate warnings don't disrupt user experience, guidance on tuning rules based on Phase 1 observations (adjust risk levels, configure whitelists), decision criteria for proceeding to Phase 3. **Phase 3: Blocking Mode** section with activeStrategy=BLOCK configuration, instructions for gradual rollout (canary deployment, percentage-based rollout), rollback plan if incidents occur. **Environment-Specific Configuration** section showing dev (LOG), staging (WARN), production (BLOCK) YAML profiles. Create docs/user-guide/performance.md covering: **Overhead Benchmarks** from design 8.3 (baseline <5%, deduplication optimization effectiveness), **Deduplication Tuning** explaining cache size vs. hit rate tradeoff with sizing recommendations (default 1000, high-volume systems 5000-10000), TTL configuration for cache expiration, **Cache Configuration** for JSqlParser parse results, **Performance Monitoring** guidance on measuring overhead in production using metrics (validation latency, cache hit rates), **Optimization Tips** for high-throughput scenarios (disable low-value rules, increase cache sizes, tune deduplication TTL).

5. **FAQ and Troubleshooting:** Create docs/user-guide/faq.md addressing common questions: **Q: What's the performance impact?** A: <5% overhead typically, see performance guide for benchmarks. **Q: Can I disable specific rules?** A: Yes, set enabled=false in rule config. **Q: How do I whitelist legacy SQL?** A: Use rule-specific whitelists (e.g., whitelistFields for whitelist checker). **Q: What if scanner fails to parse SQL?** A: JSqlParser has limitations with proprietary SQL extensions, use lenientMode=true. **Q: How to handle false positives?** A: Adjust risk levels, configure whitelists, or disable specific rules - see configuration reference. **Q: Can I use without Spring Boot?** A: Yes, instantiate DefaultSqlSafetyValidator directly, see standalone usage guide. **Q: Does it support prepared statements?** A: Yes, runtime interceptors work with prepared statements, scanner works with static SQL only. Create docs/user-guide/troubleshooting.md with common issues and solutions: **Issue: JSqlParser ParseException** (solution: enable lenientMode or upgrade JSqlParser version), **Issue: False positives for dummy conditions** (solution: configure dummy condition patterns via config), **Issue: Performance degradation** (solution: increase deduplication cache size, verify cache hit rate), **Issue: Spring Boot auto-configuration not loading** (solution: verify starter in dependencies, check META-INF/spring.factories, enable debug logging), **Issue: Interceptor not triggering** (solution: verify interceptor order, check MyBatis vs. MyBatis-Plus vs. JDBC layer configuration). Each troubleshooting entry with diagnostic steps, root cause explanation, solution, verification method. Include "How to Report Bugs" section with GitHub issue template guidance.

### Task 7.4 – Developer Documentation │ Agent_Testing_Documentation

- **Objective:** Create comprehensive developer-facing documentation enabling project contributors to understand system architecture, follow development standards, extend functionality through custom rules and interceptors, and contribute high-quality code following established patterns and TDD methodology.
- **Output:**
  - ARCHITECTURE.md documenting system design, modules, patterns, data flows, extension points
  - CONTRIBUTING.md with development setup, code standards, TDD requirements, PR process
  - Complete Javadoc coverage on all public APIs with maven-javadoc-plugin site generation
  - CHANGELOG.md following Keep a Changelog format with version history and migration guides
  - Developer tutorials for common extension scenarios (custom rules, JDBC interceptors, config centers)
  - All guides with working code examples and testing instructions
- **Guidance:** Developer documentation enables project sustainability through contributor onboarding and knowledge transfer. ARCHITECTURE.md critical for understanding design decisions: new contributors should understand module boundaries, design pattern rationale, data flow without reading entire codebase. CONTRIBUTING.md ensures code quality consistency: enforce Google Java Style, mandate TDD (tests before code), define PR review criteria. Javadoc essential for API consumers: library users integrating validator or creating custom rules need comprehensive API documentation without reading implementation. CHANGELOG maintains version history transparency: users upgrading need migration guidance for breaking changes, contributors need context for past decisions. Extension tutorials demonstrate extensibility: "How to add custom rule" guide proves system is extensible and reduces feature request burden. All examples must be complete and tested: guides with broken code damage trust and waste contributor time. Depends on: All phases output for complete documentation of architecture and extension points.

1. **Architecture Documentation:** Create ARCHITECTURE.md in project root documenting system design comprehensively: **System Overview** section with elevator pitch, core capabilities (static scanning, runtime interception), design principles (performance <5% overhead, zero false negatives for CRITICAL rules, extensibility via SPI). **Module Structure** section listing all 9 modules with ASCII diagram showing dependencies: sql-scanner-core (foundation models + validation engine), sql-scanner-cli (command-line interface), sql-scanner-maven-plugin (Maven integration), sql-scanner-gradle-plugin (Gradle integration), sql-guard-mybatis (MyBatis interceptor), sql-guard-mybatis-plus (MyBatis-Plus interceptor), sql-guard-jdbc (JDBC interception), sql-guard-spring-boot-starter (Spring Boot integration), sql-guard-examples (samples). For each module document: purpose, key classes, public APIs, dependencies, extension points. **Design Patterns** section explaining pattern usage with rationale: Chain of Responsibility for RuleChecker validation (enables extensibility, sequential validation with short-circuiting), Strategy Pattern for violation handling (LOG/WARN/BLOCK strategies swapped at runtime), Builder Pattern for SqlContext construction (complex object creation with many optional fields), Visitor Pattern for JSqlParser AST traversal (FieldExtractorVisitor extracting fields from SELECT), Factory Pattern for interceptor creation (different factories for Druid/HikariCP/P6Spy). **Data Flow Diagrams** section with ASCII or Mermaid diagrams: Static Scanning Flow (source files → parser → AST → rule checkers → violation report), Runtime Interception Flow (MyBatis invocation → BoundSql extraction → validator → strategy handler → proceed/throw). **Threading Model** explaining thread-safety: validator is thread-safe (immutable after construction), deduplication filter uses ThreadLocal (per-thread LRU cache), interceptors are stateless (safe for concurrent invocation). **Extension Points** documenting SPI interfaces: RuleChecker for custom validation rules, ConfigCenterAdapter for custom config centers, Interceptor pattern for custom JDBC pools.

2. **Contributing Guide:** Create CONTRIBUTING.md with complete development workflow: **Development Setup** section with prerequisites (Java 11 for development, Maven 3.6+, IDE setup with Checkstyle plugin for Google Java Style), clone and build instructions (`git clone`, `mvn clean install`), running tests (`mvn test`), building Javadoc (`mvn javadoc:javadoc`). **Code Style Guidelines** section mandating Google Java Style: install google-java-format plugin in IDE, configure Checkstyle with google_checks.xml, run `mvn checkstyle:check` before committing, formatting requirements (120-char line length, 2-space indentation, proper Javadoc on all public members). **Test-Driven Development Requirements** section enforcing TDD: all features must have tests written FIRST before implementation code, test class naming: TestClass for unit tests, IntegrationTest for integration tests, test method naming: testMethodName_shouldExpectedBehavior, minimum 80% code coverage enforced by Jacoco (CI build fails below threshold). **Pull Request Process** section documenting workflow: create feature branch from main (`git checkout -b feature/your-feature`), make changes following TDD (tests first, then code), ensure all tests pass and coverage maintained, ensure Checkstyle passes (`mvn checkstyle:check`), push branch and create PR with description explaining change rationale, PR review criteria (code quality, test coverage, Javadoc completeness, design alignment), address review feedback, squash commits before merge, delete branch after merge. **How to Add New Rule Checker** tutorial with step-by-step guide: create test class in sql-scanner-core test directory, write failing tests for new violation pattern, create RuleChecker implementation extending base class, implement check() method with JSqlParser AST analysis, register checker in DefaultSqlSafetyValidator, run tests ensuring they pass, add examples to sql-guard-examples module, document rule in docs/user-guide/rules/, update CHANGELOG.md. **How to Support New JDBC Pool** tutorial: create test class in sql-guard-jdbc module, identify pool-specific interception mechanism (Druid uses FilterAdapter, HikariCP uses ProxyFactory, P6Spy uses JDBC proxy), implement interceptor adapter for pool, test with actual pool instance, add Spring Boot auto-configuration with @ConditionalOnClass guard, document in user guide, add example to demo project.

3. **Javadoc API Documentation:** Ensure comprehensive Javadoc coverage on all public APIs in sql-scanner-core module: `SqlSafetyValidator` interface documenting validation contract with @param/@return/@throws tags, code examples showing standalone usage, `RuleChecker` interface documenting custom rule implementation requirements with implementation guide, `SqlContext` class documenting all context fields with semantic descriptions, `ValidationResult` class documenting result interpretation, `JSqlParserFacade` class documenting SQL parsing API. Document public APIs in sql-guard-spring-boot-starter: `SqlGuardAutoConfiguration` class explaining auto-configuration behavior and conditional bean creation, `SqlGuardProperties` class documenting all configuration properties with @see links to user guide, `ConfigCenterAdapter` interface documenting custom adapter implementation contract. Configure maven-javadoc-plugin in parent POM: set source version to 8 for compatibility, configure custom stylesheet for professional appearance, exclude test and internal packages, generate Javadoc during package phase, deploy to GitHub Pages or Maven Central during release. Generate Javadoc site: run `mvn javadoc:aggregate` producing site in target/site/apidocs, verify completeness by spot-checking key classes, verify no warnings/errors in Javadoc generation, publish to GitHub Pages via gh-pages branch. Add Javadoc badge to README linking to published API docs.

4. **Changelog and Version History:** Create CHANGELOG.md following Keep a Changelog format: **[Unreleased]** section at top for pending changes not yet released, version sections in reverse chronological order **[1.0.0] - 2024-XX-XX**, for each version use categories: **Added** for new features, **Changed** for changes in existing functionality, **Deprecated** for soon-to-be removed features, **Removed** for removed features, **Fixed** for bug fixes, **Security** for vulnerability fixes. Document breaking changes prominently: **BREAKING CHANGE:** prefix on items breaking backward compatibility, migration guides for major version changes explaining how to adapt code. Initial 1.0.0 release content: **Added** section listing all 7 rule types, static scanner CLI/Maven/Gradle plugins, runtime interceptors for MyBatis/MyBatis-Plus/JDBC, Spring Boot auto-configuration, Apollo/Nacos config center support. Link to GitHub releases: add compare URLs at bottom (e.g., [1.0.0]: https://github.com/org/repo/compare/v0.9.0...v1.0.0). Maintain CHANGELOG during development: every PR adding feature/fix must update CHANGELOG in Unreleased section, maintainer moves Unreleased items to version section during release, ensures transparency of changes for users evaluating upgrades.

5. **Extension Tutorials:** Create docs/developer-guide/tutorials/ directory with practical guides: **tutorial-custom-rule-checker.md** with complete working example: problem statement (detect SELECT COUNT(*) on large tables without WHERE as MEDIUM violation), TDD process showing test-first development (write CheckerTest with testCountStarWithoutWhere_shouldDetectViolation), implementation guide (create CountStarChecker class, override check() method, use JSqlParser to detect COUNT(*) and absent WHERE), registration in DefaultSqlSafetyValidator, testing with real SQL, integration into scanner CLI. Include complete source code in tutorial that users can copy-paste and run. **tutorial-jdbc-interceptor.md** for supporting custom JDBC pool: problem statement (add support for Tomcat JDBC Pool), identify interception mechanism (Tomcat uses JdbcInterceptor interface), implement TomcatSqlSafetyInterceptor extending JdbcInterceptor, test with TomcatJdbc DataSource, add Spring Boot @Bean with @ConditionalOnClass guard, document in configuration reference. **tutorial-config-center-adapter.md** for integrating custom config center: problem statement (add support for etcd configuration), implement ConfigCenterAdapter for etcd client, handle configuration change events, test reload functionality, register adapter as Spring bean, document usage. Each tutorial must include: complete working code example, step-by-step instructions, expected output/behavior, troubleshooting common issues, verification testing. Test tutorials by following exactly: have developer unfamiliar with codebase follow tutorial start to finish, verify they achieve working result without external help, iterate tutorial based on feedback. Run `mvn clean install` ensuring all documentation builds successfully and Javadoc generates without errors.

---

## Phase 8: Audit Log Output Layer - Agent_Audit_Infrastructure

**Phase Overview:** Implement audit log output infrastructure enabling runtime interceptors to write structured JSON audit logs for post-execution analysis. This layer bridges pre-execution defense (Phases 1-7) with post-execution audit capabilities by capturing SQL execution context, results, and timing metrics in Logback async appender pattern for downstream Kafka consumption.

**模块版本策略 (Critical Fix C2):**
- sql-guard-audit-api (Java 8): AuditLogEntry、AuditLogWriter接口，与sql-guard-core共享
- sql-guard-audit-interceptors (Java 8): 各拦截器实现，依赖sql-guard-audit-api
- sql-audit-service (Java 21): 独立服务JAR，不与sql-guard主项目打包，使用Virtual Threads

**拦截器选型决策树 (Medium Fix M1):**
- 已使用P6Spy → Task 8.6 P6Spy Audit Listener (通用性最强)
- 已使用Druid → Task 8.3 Druid SqlAuditFilter (最佳性能)
- 已使用HikariCP → Task 8.3.5 HikariCP SqlAuditProxyFactory (新增)
- 使用MyBatis → Task 8.4 MyBatis SqlAuditInterceptor (ORM层上下文)
- 使用MyBatis-Plus → Task 8.5 MyBatis-Plus InnerAuditInterceptor (分页元数据)
- 其他连接池 → 推荐P6Spy方案 (兼容任何JDBC驱动)

### Task 8.1 – AuditLogWriter Interface & JSON Schema Design │ Agent_Audit_Infrastructure

- **Objective:** Design unified audit log interface and JSON schema defining structured audit event format with SQL context, execution results, timing metrics, and violation metadata, establishing contract between runtime interceptors and audit service for consistent log-based communication.
- **Output:**
  - AuditLogWriter interface with writeAuditLog(AuditEvent) method
  - AuditEvent data model with comprehensive fields: sqlId, sql, sqlType, mapperId, datasource, params, executionTimeMs, rowsAffected, errorMessage, timestamp, violations
  - JSON schema specification for audit event serialization
  - Jackson ObjectMapper configuration for JSON serialization with proper date/time formatting
  - Validation ensuring all required fields populated before writing
- **Guidance:** AuditLogWriter provides uniform interface for all interceptors (MyBatis, MyBatis-Plus, Druid, HikariCP, P6Spy) to write audit logs without implementation coupling. AuditEvent captures complete execution context: SQL text, parsed metadata (sqlType, mapperId), datasource identifier for multi-tenant scenarios, execution metrics (duration, affected rows) critical for performance analysis, error information for failure auditing, pre-execution violation data from existing validators. JSON format enables schema evolution and easy Kafka consumption. Jackson configuration must handle java.time types (Instant, Duration) with ISO-8601 format for cross-language compatibility. Validation prevents incomplete audit records causing analysis failures. Depends on: Phase 1 Task 1.2 (ValidationResult model for violation metadata).

1. **Interface Design TDD:** Write test class `AuditLogWriterTest` with test methods: `testWriteAuditLog_withCompleteEvent_shouldSucceed()` (complete AuditEvent writes successfully), `testWriteAuditLog_withMissingRequiredFields_shouldThrowException()` (validation catches incomplete events), `testAuditEventSerialization_shouldProduceValidJson()` (event serializes to valid JSON matching schema). Implement `AuditLogWriter` interface in `com.footstone.sqlguard.audit` package with method signature: `void writeAuditLog(AuditEvent event) throws AuditLogException`. Define validation contract: sql, sqlType, mapperId, timestamp are required fields, throw IllegalArgumentException if any required field null. Document thread-safety requirements: implementations must be thread-safe for concurrent interceptor usage.

2. **AuditEvent Model TDD:** Write test class `AuditEventTest` with test methods: `testBuilder_withAllFields_shouldConstruct()`, `testBuilder_withMissingRequired_shouldThrowException()`, `testEquals_withSameContent_shouldBeEqual()` (value object semantics), `testToString_shouldContainAllFields()` (debugging support). Implement `AuditEvent` class in audit package with immutable fields: String sqlId (MD5 hash of SQL for deduplication), String sql, SqlCommandType sqlType, String mapperId, String datasource, Map<String, Object> params (parameter bindings, nullable), long executionTimeMs, int rowsAffected (-1 if not applicable), String errorMessage (nullable), Instant timestamp, List<ViolationInfo> violations (from pre-execution validator, nullable). Implement builder pattern with validation: AuditEvent.builder().sql(sql).sqlType(type).mapperId(id).timestamp(Instant.now()).build(). Make class final and fields final ensuring immutability critical for audit integrity.

3. **JSON Schema & Serialization TDD:** Write test class `AuditEventSerializationTest` with test methods: `testJsonSerialization_shouldProduceExpectedFormat()` (serialize to JSON, verify structure matches schema), `testJsonDeserialization_shouldRecreateEvent()` (deserialize JSON back to AuditEvent, verify equality), `testDateTimeSerialization_shouldUseIso8601()` (Instant serializes to ISO-8601 string like "2024-01-15T10:30:45.123Z"), `testNullFields_shouldSerializeAsNull()` (nullable fields serialize as JSON null, not omitted). Create JSON schema specification in docs/audit-log-schema.json: define required fields ["sqlId", "sql", "sqlType", "mapperId", "timestamp"], define optional fields with types, specify timestamp format as ISO-8601 date-time string. Configure Jackson ObjectMapper: `ObjectMapper mapper = new ObjectMapper().registerModule(new JavaTimeModule()).disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS).setSerializationInclusion(JsonInclude.Include.ALWAYS)` ensuring Instant serialization to ISO-8601, null value inclusion for clarity, JavaTimeModule for java.time support.

4. **Validation Implementation:** Implement validation logic in AuditEvent.Builder.build() method: check required fields not null (sql, sqlType, mapperId, timestamp), throw IllegalArgumentException("Required field [fieldName] is null") with clear message, validate sqlId matches MD5 hash of sql (recalculate and compare), validate executionTimeMs >= 0 (negative duration invalid), validate rowsAffected >= -1 (only -1 for not-applicable cases like SELECT), validate timestamp not in future (clock skew tolerance +5 seconds). Write comprehensive validation tests ensuring all edge cases handled. Document validation rules in AuditEvent Javadoc for interceptor implementers.

5. **Integration Testing:** Write integration test `AuditLogWriterIntegrationTest` creating sample AuditEvent instances: successful SELECT (with executionTimeMs, rowsAffected=0, no error), successful UPDATE (with rowsAffected > 0), failed execution (with errorMessage, executionTimeMs, rowsAffected=-1), event with pre-execution violations (violations list populated from validator). For each event: serialize to JSON using configured ObjectMapper, verify JSON structure matches schema specification, deserialize back to Java object, verify equality with original event, verify timestamp format ISO-8601, verify all fields preserved through serialization round-trip. Test null field handling: create event with nullable fields null (params, errorMessage, violations), verify JSON contains null values explicitly, verify deserialization handles nulls correctly. Run `mvn test` ensuring all audit log foundation tests pass.

### Task 8.2 – Logback Async Appender Configuration │ Agent_Audit_Infrastructure

- **Objective:** Configure Logback AsyncAppender for high-throughput audit log writing with file rolling strategy, implementing async I/O pattern preventing audit logging from blocking SQL execution, and file-based buffering enabling Filebeat collection for Kafka ingestion.
- **Output:**
  - Logback configuration with dedicated audit logger separate from application logging
  - AsyncAppender with configurable queue size and blocking behavior
  - RollingFileAppender with time-based and size-based rolling policies
  - Audit log file pattern with date-based directory structure for Filebeat discovery
  - Performance tuning configuration achieving <1ms write latency
  - Integration tests validating async behavior and file rolling
- **Guidance:** Async appender critical for performance: audit log writes must not block SQL execution (<1% overhead target), queue-based buffering decouples write thread from worker threads. RollingFileAppender with time/size policies prevents disk exhaustion: daily rotation creates date-based structure (logs/audit/2024-01-15/audit.log) enabling Filebeat wildcard pattern, size-based splitting limits individual file size for manageable Kafka message batches. Audit logger separation prevents audit events from mixing with application logs in stdout/stderr, uses dedicated logger name "com.footstone.sqlguard.audit.AUDIT" for filtering. Queue size tuning balances memory usage vs. throughput: 8192 default, 65536 for high-volume systems. Blocking behavior choice: discardingThreshold=0 blocks when queue full preventing audit loss vs. nonblocking drops events preserving performance. Depends on: Task 8.1 Output (AuditEvent JSON serialization).

1. **Logback Configuration Design:** Create logback-audit.xml in sql-guard-core/src/main/resources with dedicated audit logger configuration: define AsyncAppender named "ASYNC_AUDIT" with queueSize="8192", discardingThreshold="0" (block when queue full, no event loss), includeCallerData="false" (performance optimization, no stack trace needed), nest RollingFileAppender named "AUDIT_FILE" with encoder pattern for JSON-per-line format: `%msg%n` (AuditEvent already JSON-serialized, no additional formatting), configure TimeBasedRollingPolicy with fileNamePattern="logs/audit/%d{yyyy-MM-dd}/audit.%d{yyyy-MM-dd-HH}.log" creating hourly files in date directories, configure SizeAndTimeBasedRollingPolicy adding maxFileSize="100MB" splitting large hourly files, configure maxHistory="30" keeping 30 days of logs, configure totalSizeCap="10GB" preventing disk exhaustion. Define audit logger: `<logger name="com.footstone.sqlguard.audit.AUDIT" level="INFO" additivity="false"><appender-ref ref="ASYNC_AUDIT"/></logger>` isolating audit logs from root logger.

2. **FileAppender Implementation TDD:** Write test class `LogbackAuditAppenderTest` with test methods: `testAsyncAppender_shouldNotBlock()` (measure write latency, verify <1ms for 1000 events), `testAuditLogger_shouldIsolateFromRoot()` (audit events not propagated to root logger, appear only in audit files), `testRollingPolicy_shouldCreateDateDirectories()` (files created in correct date-based paths), `testRollingPolicy_shouldRotateHourly()` (hourly rotation creates new files), `testRollingPolicy_shouldSplitLargeFiles()` (100MB size limit triggers split), `testQueueFull_shouldBlock()` (queue saturation blocks caller when discardingThreshold=0). Implement `LogbackAuditWriter` class implementing AuditLogWriter interface: in constructor get Logger via `LoggerFactory.getLogger("com.footstone.sqlguard.audit.AUDIT")`, in writeAuditLog() serialize AuditEvent to JSON string using ObjectMapper, call logger.info(jsonString) writing to async appender. Test async behavior: start background thread writing 10000 events rapidly, measure total time and individual write latencies, verify <1ms p99 latency, verify no blocking on main thread, verify all events written to files eventually (async flush).

3. **Rolling Policy Testing:** Write integration test `AuditLogRollingIntegrationTest` with test methods: `testHourlyRolling_shouldCreateNewFiles()` (mock clock advancing hours, verify new files created), `testDateDirectoryStructure_shouldMatch()` (verify logs/audit/2024-01-15/ directory created), `testSizeBasedSplit_shouldCreateMultipleFiles()` (write >100MB events, verify split into audit.2024-01-15-10.0.log, audit.2024-01-15-10.1.log, etc.), `testMaxHistory_shouldDeleteOldLogs()` (write logs spanning >30 days, verify oldest deleted), `testTotalSizeCap_shouldEnforce()` (write >10GB, verify cap enforced through deletion). Use Logback's test utilities: create test appender configuration programmatically, control time via Clock for deterministic rolling, verify file system state matches expectations.

4. **Performance Tuning Configuration:** Document performance tuning guidelines in logback-audit.xml comments: **Queue Size** - default 8192 for typical load (1000 SQL/s), increase to 65536 for high-volume systems (>5000 SQL/s), decrease to 2048 for low-memory environments; **Discarding Threshold** - 0 for zero audit loss (blocks when queue full), 20% for performance priority (discards INFO events when queue 80% full); **Caller Data** - includeCallerData=false for performance (no stack trace capture), true only for debugging; **Encoder Pattern** - use `%msg%n` for pre-serialized JSON (no pattern layout overhead), avoid custom patterns adding latency. Create performance benchmark `AuditLogWriterBenchmark` using JMH: measure throughput (events/sec) at different queue sizes, measure latency (p50, p95, p99) for single writes, measure overhead impact on SQL execution (measure SQL+validation+audit vs. SQL+validation only), verify <1% total overhead target from design section 9.1.

5. **Filebeat Integration Documentation:** Create docs/audit-log-filebeat.md documenting Filebeat configuration for audit log collection: **Filebeat Input Configuration** - use filebeat.inputs type:log with paths: ["logs/audit/*/*.log"] matching date-directory wildcard pattern, configure json.keys_under_root: true for JSON parsing, configure fields: {audit_source: "sql-guard"} adding metadata; **Kafka Output Configuration** - output.kafka.hosts: ["kafka:9092"], output.kafka.topic: "sql-audit-events", output.kafka.compression: "gzip" reducing network bandwidth; **Registry Management** - configure registry file preventing duplicate ingestion after restart; **Monitoring** - enable Filebeat monitoring for ingestion lag tracking. Provide complete filebeat.yml example with comments. Document deployment: run Filebeat as sidecar container in same pod as application for log file access, mount logs/audit/ directory as shared volume, configure Filebeat to handle file rotation (follows new files automatically). Run `mvn test` ensuring all Logback async appender tests pass.

### Task 8.3 – Druid SqlAuditFilter Implementation │ Agent_Audit_Infrastructure

- **Objective:** Implement Druid SqlAuditFilter extending FilterAdapter to capture SQL execution results, timing, and errors for audit logging, integrating with Druid's filter chain to intercept statement execution completion, and writing audit events via AuditLogWriter without impacting Druid's connection pooling or monitoring features.
- **Output:**
  - DruidSqlAuditFilter class extending FilterAdapter with statement execution result capture
  - Method overrides: statement_execute(), statement_executeQuery(), statement_executeUpdate() with after-execution audit logging
  - Error handling capturing SQLException details in audit events
  - Timing measurement using nanoTime for microsecond precision
  - Filter ordering ensuring audit filter runs after StatFilter for complete metrics
  - Integration tests with Druid datasource validating audit log generation
- **Guidance:** Druid filter provides JDBC-layer audit capture complementing validation-only DruidSqlSafetyFilter from Task 4.3. SqlAuditFilter focuses on post-execution: captures execution duration, rows affected, errors - data unavailable at pre-execution validation time. Filter must execute after statement completion to access JDBC result metrics. Timing measurement uses System.nanoTime() for precision (currentTimeMillis too coarse). Error handling wraps SQLException capture in try-catch preventing audit failures from breaking SQL execution. Filter ordering critical: audit filter must run AFTER StatFilter (Druid SQL stats) to avoid impacting statistics collection, but BEFORE ConnectionCloseFilter to capture events before connection return. Integration with existing DruidSqlSafetyFilter: both filters coexist, safety filter runs pre-execution (validates and blocks), audit filter runs post-execution (logs results). Depends on: Task 8.1 Output (AuditLogWriter interface), Task 4.3 Output (DruidSqlSafetyFilter for pattern reference).

1. **Filter Implementation TDD:** Write test class `DruidSqlAuditFilterTest` with test methods: `testStatementExecute_shouldLogAudit()` (execute() completion logs audit event), `testExecuteQuery_shouldCaptureRowCount()` (executeQuery() logs result set size if available), `testExecuteUpdate_shouldCaptureAffectedRows()` (executeUpdate() logs rows affected from result), `testExecutionError_shouldLogException()` (SQLException captured in audit event errorMessage), `testExecutionTiming_shouldBeMicrosecondPrecise()` (timing measurement accurate to microseconds), `testFilterOrdering_shouldRunAfterStat()` (audit filter executes after StatFilter in chain). Implement `DruidSqlAuditFilter` class in `com.footstone.sqlguard.interceptor.druid` package extending FilterAdapter: inject AuditLogWriter via constructor, store ValidationResult from pre-execution validation (from DruidSqlSafetyFilter) in ThreadLocal for audit event correlation, override statement execution methods to wrap and measure execution.

2. **Statement Execution Wrapping:** Override statement_execute(StatementProxy statement, String sql) method: record start time `long startNano = System.nanoTime()`, call `super.statement_execute(statement, sql)` executing actual statement and allowing filter chain to proceed, record end time `long endNano = System.nanoTime()`, calculate duration `long durationMs = (endNano - startNano) / 1_000_000`, extract result from StatementProxy: boolean result from execute() indicates result set (true) or update count (false), get update count via statement.getUpdateCount() if update, extract rowsAffected = updateCount for UPDATE/DELETE/INSERT, extract datasource name from statement.getConnectionProxy().getDirectDataSource().getName(), build AuditEvent with all captured fields, call auditLogWriter.writeAuditLog(event), handle exceptions wrapping in try-catch to prevent audit failures from breaking execution. Similarly override statement_executeQuery() and statement_executeUpdate() with specific result extraction.

3. **Error Handling TDD:** Write test method `testExecutionException_shouldCaptureInAudit()` verifying SQLException capture: mock Statement throwing SQLException, execute SQL via filter, verify SQLException.getMessage() captured in AuditEvent.errorMessage, verify executionTimeMs still recorded (measure duration until exception), verify rowsAffected = -1 for error cases, verify exception re-thrown after audit (filter doesn't swallow exceptions). Implement error capture in statement execution overrides: wrap super.statement_execute() in try-catch(SQLException e), in catch block: record end time, calculate duration, create AuditEvent with errorMessage=e.getMessage(), write audit event, re-throw exception preserving original stack trace. Test exception propagation: verify caller receives original SQLException unmodified, verify audit event logged before exception propagation, verify no audit event loss even with exception.

4. **Filter Registration and Ordering:** Implement filter registration in DruidSqlSafetyFilterConfiguration: modify registerFilter() method adding both safety filter and audit filter: create DruidDataSource dataSource, get filter list `List<Filter> filters = dataSource.getProxyFilters()`, add DruidSqlSafetyFilter with order=2 (before StatFilter execution), add DruidSqlAuditFilter with order=10 (after StatFilter=9, after ConnectionLogFilter=8), verify filter ordering by checking filter execution sequence in integration test. Write integration test `DruidFilterOrderingTest`: configure datasource with StatFilter + DruidSqlSafetyFilter + DruidSqlAuditFilter, execute SQL, verify execution order via filter logs: safety validation runs first (pre-execution), statement execution proceeds, StatFilter records statistics, audit filter logs event (post-execution), verify audit event contains complete timing and result data.

5. **Integration Testing:** Write integration test `DruidSqlAuditFilterIntegrationTest` with real Druid datasource and H2 database: execute successful SELECT capturing timing and result set info, execute successful UPDATE capturing rows affected, execute INSERT capturing inserted rows, execute SQL causing SQLException capturing error message, execute SQL violating safety rules capturing pre-execution violations in audit event (from DruidSqlSafetyFilter ValidationResult). For each scenario: verify AuditEvent written to mock AuditLogWriter, verify all required fields populated, verify timing accuracy (executionTimeMs within reasonable range), verify datasource name matches configured datasource, verify rowsAffected accurate for DML statements. Test filter compatibility: enable Druid StatFilter alongside audit filter, verify statistics collection unaffected, verify Druid monitoring dashboard shows correct SQL counts, verify audit filter doesn't interfere with Druid's built-in monitoring. Run `mvn test` ensuring all Druid audit filter tests pass.

### Task 8.3.5 – HikariCP SqlAuditProxyFactory Implementation │ Agent_Audit_Infrastructure (High Fix H1 - 新增)

- **Objective:** 为HikariCP连接池提供审计日志采集能力，复用HikariSqlSafetyProxyFactory模式实现Statement代理，在SQL执行完成后捕获执行结果、耗时和错误信息写入审计日志。
- **Output:**
  - HikariSqlAuditProxyFactory类，包装Connection返回代理Connection
  - Statement/PreparedStatement代理，拦截execute*方法捕获执行结果
  - 执行耗时测量，使用System.nanoTime()获取微秒级精度
  - 错误处理，捕获SQLException详情到审计事件
  - 与HikariSqlSafetyProxyFactory协调，通过ThreadLocal共享pre-execution验证结果
  - 集成测试验证HikariCP连接池场景下审计日志生成
- **Guidance:** HikariCP是Spring Boot 2.x+默认连接池，使用广泛。复用Task 4.4 HikariSqlSafetyProxyFactory的代理模式：通过HikariConfig.setConnectionInitSql()或自定义DataSource包装器。审计代理需在Statement.execute*()方法执行完成后捕获：executeUpdate()返回的影响行数，executeQuery()的ResultSet元数据，执行耗时。与safety代理共存：safety代理在execute前验证(pre-execution)，audit代理在execute后记录(post-execution)。依赖: Task 8.1 Output (AuditLogWriter接口), Task 4.4 Output (HikariSqlSafetyProxyFactory模式参考)。

1. **Proxy Factory TDD:** Write test class `HikariSqlAuditProxyFactoryTest` with test methods: `testConnectionProxy_shouldWrapStatements()` (Connection.createStatement()返回代理Statement), `testStatementProxy_shouldCaptureExecuteResult()` (execute后捕获结果), `testPreparedStatementProxy_shouldCaptureUpdateCount()` (executeUpdate返回值捕获), `testExecutionTiming_shouldBeMicrosecondPrecise()` (耗时测量精确到微秒), `testErrorCapture_shouldLogSQLException()` (SQLException捕获到审计事件). Implement `HikariSqlAuditProxyFactory` in `com.footstone.sqlguard.interceptor.hikari` package, 使用JDK动态代理包装Connection/Statement.

2. **Statement Invocation Handler:** Implement StatementAuditInvocationHandler处理execute*方法: 记录startNano，调用原始method.invoke()，计算duration，根据方法返回类型提取结果(executeUpdate返回int即为rowsAffected，executeQuery返回ResultSet需另处理)，构建AuditEvent写入审计日志，异常情况也需记录到AuditEvent.errorMessage后重新抛出。处理批量执行: executeBatch()返回int[]，聚合为总影响行数.

3. **Safety-Audit Coordination:** 使用共享ThreadLocal与HikariSqlSafetyProxyFactory协调: safety代理在execute前存储ValidationResult，audit代理在execute后读取ValidationResult附加到AuditEvent.violations。确保ThreadLocal在finally块中清理防止内存泄漏。测试两个代理共存场景.

4. **Integration Testing:** Write integration test `HikariSqlAuditIntegrationTest` with HikariDataSource and H2 database: 配置HikariCP使用audit代理，执行SELECT/UPDATE/INSERT/DELETE验证审计事件生成，验证与safety代理共存不冲突，验证连接池性能无明显下降(<5%开销). Run `mvn test` ensuring all HikariCP audit tests pass.

### Task 8.4 – MyBatis SqlAuditInterceptor Implementation │ Agent_Audit_Infrastructure

- **Objective:** Implement MyBatis plugin intercepting Executor methods to capture SQL execution results and timing for audit logging, extracting post-execution metrics (rows affected, execution duration) from MyBatis invocation context, coordinating with SqlSafetyInterceptor for pre-execution violation correlation, and supporting both MyBatis 3.4.x and 3.5.x versions.
- **Output:**
  - SqlAuditInterceptor class with @Intercepts annotation targeting Executor.update and Executor.query
  - Post-execution interception using Invocation.proceed() result capture
  - Timing measurement wrapping statement execution
  - Rows affected extraction from update/query results
  - Pre-execution violation correlation via ThreadLocal between safety and audit interceptors
  - Multi-version compatibility for MyBatis 3.4.x and 3.5.x
  - Integration tests with SqlSessionFactory validating audit event generation
- **Guidance:** MyBatis interceptor provides ORM-layer audit capture at higher abstraction than JDBC (Task 8.3), capturing mapper context (mapperId, dynamic SQL resolution) unavailable at JDBC level. Post-execution interception requires wrapping Invocation.proceed(): measure timing around proceed() call, extract result from proceed() return value for rows affected calculation. Update method returns int (rows affected directly), query method returns List<?> (rows affected = list size for SELECT auditing). ThreadLocal correlation links pre-execution validation (SqlSafetyInterceptor from Task 4.1) with post-execution audit: safety interceptor stores ValidationResult in ThreadLocal before proceed(), audit interceptor retrieves ValidationResult after proceed() for audit event. Multi-version compatibility handles API differences: MyBatis 3.4.x vs 3.5.x Executor method signatures, BoundSql access patterns. Depends on: Task 8.1 Output (AuditLogWriter interface), Task 4.1 Output (SqlSafetyInterceptor pattern reference).

1. **Interceptor Implementation TDD:** Write test class `SqlAuditInterceptorTest` with test methods: `testUpdateInterception_shouldLogAudit()` (Executor.update() logs audit with rows affected), `testQueryInterception_shouldLogAudit()` (Executor.query() logs audit with result set size), `testTimingMeasurement_shouldBeAccurate()` (execution timing within 5% of actual duration), `testValidationCorrelation_shouldIncludeViolations()` (pre-execution violations from SqlSafetyInterceptor appear in audit event), `testInterceptorChain_shouldWorkWithSafetyInterceptor()` (both safety and audit interceptors coexist). Implement `SqlAuditInterceptor` class in `com.footstone.sqlguard.interceptor.mybatis` package annotated with `@Intercepts({@Signature(type = Executor.class, method = "update", args = {MappedStatement.class, Object.class}), @Signature(type = Executor.class, method = "query", args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class})})` targeting same methods as safety interceptor. Inject AuditLogWriter via constructor. Store pre-execution ValidationResult in ThreadLocal for correlation.

2. **Post-Execution Result Capture:** Implement intercept(Invocation invocation) method with post-execution audit: extract MappedStatement, parameter, and context (same as SqlSafetyInterceptor), record start time `long startNano = System.nanoTime()`, call `Object result = invocation.proceed()` executing statement and measuring timing, record end time and calculate duration, extract rows affected from result based on method type: for update() result is Integer (rows affected directly), for query() result is List<?> (rows affected = list.size() representing result set size), retrieve pre-execution ValidationResult from ThreadLocal (if SqlSafetyInterceptor ran), build AuditEvent with all fields: sql from BoundSql, sqlType from MappedStatement, mapperId from MappedStatement.getId(), executionTimeMs from timing, rowsAffected from result, violations from ValidationResult (nullable if no pre-execution validation), write audit event, return result unchanged (interceptor is transparent).

3. **ThreadLocal Correlation Pattern:** Create shared ThreadLocal<ValidationResult> in common utility class `SqlInterceptorContext` for cross-interceptor communication: `public static final ThreadLocal<ValidationResult> VALIDATION_RESULT = new ThreadLocal<>()`. Modify SqlSafetyInterceptor from Task 4.1: after validation, store result `SqlInterceptorContext.VALIDATION_RESULT.set(validationResult)`, in finally block after invocation.proceed() call `SqlInterceptorContext.VALIDATION_RESULT.remove()` cleaning thread-local to prevent memory leak. In SqlAuditInterceptor: before writing audit event, retrieve validation `ValidationResult validation = SqlInterceptorContext.VALIDATION_RESULT.get()`, add to AuditEvent if non-null: `auditEvent.violations(validation != null ? validation.getViolations() : null)`. Test correlation: configure both interceptors in SqlSessionFactory, execute SQL violating safety rules, verify audit event contains violations from pre-execution validation, verify violations include risk level and messages, verify correlation works across interceptor chain.

4. **Multi-Version Compatibility:** Write compatibility test `MyBatisVersionCompatibilityTest` with Maven profiles for MyBatis 3.4.6 and 3.5.13: test interceptor with both versions, verify BoundSql access patterns work, verify Executor method signatures compatible, verify result extraction works (update returns int, query returns List in both versions), verify no API incompatibilities. Use reflection-based compatibility layer if needed: detect MyBatis version at runtime, use version-specific code paths for API differences. Document compatibility in interceptor Javadoc: "Supports MyBatis 3.4.x and 3.5.x". Test with both MyBatis versions in CI: `mvn test -Pmybatis-3.4` and `mvn test -Pmybatis-3.5`.

5. **Integration Testing:** Write integration test `SqlAuditInterceptorIntegrationTest` with real SqlSessionFactory and H2 database: create mapper with sample SQL (SELECT, UPDATE, INSERT, DELETE), configure SqlSessionFactory with both SqlSafetyInterceptor and SqlAuditInterceptor, execute mapper methods and verify audit events generated. Test scenarios: successful UPDATE with rows affected > 0, successful SELECT with result set size captured, failed execution with SQLException (verify error captured), SQL with pre-execution violations (verify violations in audit event), dynamic SQL with MyBatis if/foreach tags (verify resolved SQL captured). Verify audit event fields: sql contains final resolved SQL (after dynamic tag processing), sqlType correct for each statement type, mapperId matches mapper interface and method name, executionTimeMs reasonable (0-5000ms for test queries), rowsAffected accurate for each operation type. Test interceptor ordering: verify safety interceptor runs before proceed() (pre-execution validation), verify audit interceptor runs after proceed() (post-execution logging), verify both interceptors coexist without conflicts. Run `mvn test` ensuring all MyBatis audit interceptor tests pass.

### Task 8.5 – MyBatis-Plus InnerAuditInterceptor Implementation │ Agent_Audit_Infrastructure

- **Objective:** Implement MyBatis-Plus InnerInterceptor for audit logging capturing IPage pagination results, QueryWrapper-generated SQL execution metrics, and MyBatis-Plus plugin chain context, coordinating with MpSqlSafetyInnerInterceptor for violation correlation, and integrating with PaginationInnerInterceptor for accurate page metadata.
- **Output:**
  - MpSqlAuditInnerInterceptor class implementing InnerInterceptor interface
  - beforeQuery() and beforeUpdate() methods for pre-execution context capture
  - afterQuery() and afterUpdate() methods for post-execution result capture
  - IPage result extraction capturing total records, current page, and page size
  - QueryWrapper SQL correlation tracking wrapper-generated queries
  - Plugin chain ordering ensuring audit runs after pagination and safety interceptors
  - Integration tests with IPage pagination and QueryWrapper usage
- **Guidance:** MyBatis-Plus InnerInterceptor provides dual-phase interception: before* methods capture context, after* methods capture results - enabling accurate timing measurement and result extraction. IPage pagination results include rich metadata: total records from count query, current page number, page size - critical for pagination abuse auditing. QueryWrapper SQL generated dynamically at runtime must be correlated with static scanner WrapperUsage markers from Task 3.4. Plugin ordering critical: PaginationInnerInterceptor modifies SQL first (adds LIMIT), MpSqlSafetyInnerInterceptor validates modified SQL (safety check), MpSqlAuditInnerInterceptor logs execution results (audit). ThreadLocal pattern stores before* context for after* correlation. Depends on: Task 8.1 Output (AuditLogWriter), Task 4.2 Output (MpSqlSafetyInnerInterceptor pattern).

1. **InnerInterceptor Implementation TDD:** Write test class `MpSqlAuditInnerInterceptorTest` with test methods: `testBeforeQueryAfterQuery_shouldLogAudit()` (query interception logs audit event), `testBeforeUpdateAfterUpdate_shouldLogAudit()` (update interception logs audit), `testIPageExtraction_shouldCaptureMetadata()` (IPage parameter captured with total/current/size), `testQueryWrapperCorrelation_shouldIdentifyWrapper()` (QueryWrapper-generated SQL flagged in audit event), `testPluginOrdering_shouldRunAfterPagination()` (audit runs after PaginationInnerInterceptor and safety interceptor). Implement `MpSqlAuditInnerInterceptor` class in `com.footstone.sqlguard.interceptor.mp` package implementing InnerInterceptor from MyBatis-Plus. Inject AuditLogWriter via constructor. Create ThreadLocal<AuditContext> storing before* phase data for after* phase correlation.

2. **Before-Phase Context Capture:** Implement beforeQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) method: record start time in AuditContext `context.startNano = System.nanoTime()`, extract SQL from boundSql for later correlation, detect IPage parameter: check if parameter instanceof IPage or parameter Map contains IPage value, store IPage metadata in context (current page, size, expected total after query), detect QueryWrapper: check if parameter contains QueryWrapper/LambdaQueryWrapper instance, set flag in context indicating wrapper-generated SQL, store context in ThreadLocal for after* phase retrieval. Similarly implement beforeUpdate() capturing update context. Use static nested class AuditContext: fields startNano, sql, iPage, isQueryWrapper, mapperId, sqlType.

3. **After-Phase Result Capture:** Implement afterQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql, List<?> result) method: retrieve AuditContext from ThreadLocal, calculate execution time `long durationMs = (System.nanoTime() - context.startNano) / 1_000_000`, extract rows affected = result.size() (query result list size), extract IPage result if IPage parameter detected: `IPage<?> page = extractIPage(parameter)`, capture page.getTotal() (total records from count query), page.getCurrent() (current page number), page.getSize() (page size), build AuditEvent with captured fields: sql, sqlType=SELECT, mapperId, executionTimeMs, rowsAffected=result.size(), add IPage metadata to event details map: details.put("pagination.total", page.getTotal()), details.put("pagination.current", page.getCurrent()), details.put("pagination.size", page.getSize()), add QueryWrapper flag if detected: details.put("queryWrapper", context.isQueryWrapper), write audit event via AuditLogWriter, clean ThreadLocal `AUDIT_CONTEXT.remove()`. Similarly implement afterUpdate() for UPDATE/DELETE auditing.

4. **Plugin Chain Integration:** Write integration test `MpPluginChainIntegrationTest` configuring full MyBatis-Plus interceptor stack: create MybatisPlusInterceptor, add PaginationInnerInterceptor with order=1, add MpSqlSafetyInnerInterceptor with order=2 (from Task 4.2), add MpSqlAuditInnerInterceptor with order=3, configure in SqlSessionFactory. Test execution flow: execute IPage query triggering all three interceptors, verify PaginationInnerInterceptor adds LIMIT clause first, verify MpSqlSafetyInnerInterceptor validates paginated SQL second, verify MpSqlAuditInnerInterceptor logs execution result third with pagination metadata, verify audit event contains SQL with LIMIT (after pagination modification), verify audit event contains page total from count query. Test without pagination: execute plain query without IPage, verify audit interceptor still works, verify no pagination metadata in audit event.

5. **Comprehensive Testing:** Write integration test `MpSqlAuditInnerInterceptorIntegrationTest` with various MyBatis-Plus scenarios: IPage pagination query with page size 20 capturing total records, QueryWrapper.eq("status", "active") capturing wrapper flag, LambdaQueryWrapper with method references capturing wrapper SQL, UpdateWrapper with set() method capturing update results, mixed usage with pagination + wrapper, SQL with pre-execution violations from MpSqlSafetyInnerInterceptor (verify violations in audit event via shared ThreadLocal pattern similar to Task 8.4). For each scenario: verify audit event generated, verify timing accurate, verify result metrics correct (rows affected for UPDATE, result size for SELECT), verify IPage metadata complete when pagination used, verify QueryWrapper flag set when wrapper used. Test error handling: execute SQL causing SQLException, verify after* phase still logs audit with error, verify timing captured up to exception point. Run `mvn test` ensuring all MyBatis-Plus audit interceptor tests pass.

### Task 8.6 – P6Spy Audit Listener Implementation │ Agent_Audit_Infrastructure

- **Objective:** Implement P6Spy JdbcEventListener for universal JDBC audit logging across any connection pool or framework, capturing SQL execution results via onAfterAnyExecute callback with parameter-substituted SQL and JDBC result metadata, registering as P6Spy module for auto-discovery, and providing fallback audit capability for environments without native interceptor support.
- **Output:**
  - P6SpySqlAuditListener class extending JdbcEventListener with audit logging
  - onAfterAnyExecute() method capturing post-execution results and timing
  - SQL extraction from StatementInformation with parameter values substituted
  - Batch execution result aggregation for executeBatch() auditing
  - P6SpySqlAuditModule for listener registration via SPI
  - spy.properties configuration for module activation
  - Integration tests with P6Spy-wrapped datasources across multiple JDBC drivers
- **Guidance:** P6Spy provides universal fallback when pool-specific solutions unavailable: works with any JDBC driver/pool (C3P0, DBCP, Tomcat JDBC), captures all SQL regardless of framework (MyBatis, JPA, JdbcTemplate, raw JDBC). onAfterAnyExecute() fires after all statement executions providing post-execution results: execution duration from StatementInformation.getExecuteTime(), rows affected from result (updateCount for DML, result set metadata for queries). StatementInformation.getSqlWithValues() provides SQL with parameters substituted - useful for audit but requires sanitization to prevent sensitive data logging. Batch execution aggregates results: executeBatch() returns int[] with per-statement affected rows, audit event aggregates total. Module registration via SPI allows P6Spy auto-discovery without explicit configuration. Depends on: Task 8.1 Output (AuditLogWriter), Task 4.5 Output (P6SpySqlSafetyListener pattern).

1. **Listener Implementation TDD:** Write test class `P6SpySqlAuditListenerTest` with test methods: `testOnAfterAnyExecute_shouldLogAudit()` (statement execution logs audit event), `testExecuteTime_shouldCaptureAccurately()` (timing from StatementInformation accurate), `testUpdateCount_shouldCaptureAffectedRows()` (UPDATE/DELETE/INSERT captures rows affected), `testResultSetSize_shouldCaptureForQuery()` (SELECT captures result set size if available), `testBatchExecution_shouldAggregateResults()` (executeBatch() aggregates per-statement results), `testPreExecutionViolations_shouldCorrelate()` (violations from P6SpySqlSafetyListener included in audit). Implement `P6SpySqlAuditListener` class in `com.footstone.sqlguard.interceptor.p6spy` package extending JdbcEventListener from P6Spy. Inject AuditLogWriter via constructor or static initialization (P6Spy instantiates listeners, limited DI support).

2. **onAfterAnyExecute Implementation:** Implement onAfterAnyExecute(StatementInformation statementInformation) callback: extract SQL via `String sql = statementInformation.getSqlWithValues()` getting parameter-substituted SQL (WARNING: may contain sensitive data, sanitize for production logging), extract execution time `long durationMs = statementInformation.getExecuteTime()` (P6Spy tracks timing automatically), extract SQL type from SQL string (parse SELECT/UPDATE/DELETE/INSERT prefix), extract rows affected: for DML check `statementInformation.get UpdateCount()` (not directly available, access via reflection or result tracking), for SELECT estimate from result set size if accessible, create mapperId as "jdbc-p6spy" + optional datasource identifier, build AuditEvent with captured fields, retrieve pre-execution ValidationResult from shared ThreadLocal (if P6SpySqlSafetyListener from Task 4.5 ran), add violations to audit event, write audit event via AuditLogWriter. Handle batch execution: detect batch via statementInformation.isBatch(), aggregate batch results if available.

3. **Module Registration:** Create `P6SpySqlAuditModule` class in same package implementing P6SpyFactory or appropriate P6Spy extension interface: register P6SpySqlAuditListener in module initialization, initialize AuditLogWriter (use static factory or ServiceLoader pattern for dependency resolution in P6Spy's limited DI environment). Update spy.properties in src/main/resources: add module to modulelist: `modulelist=com.footstone.sqlguard.interceptor.p6spy.P6SpySqlSafetyModule,com.footstone.sqlguard.interceptor.p6spy.P6SpySqlAuditModule` (append to existing safety module from Task 4.5), configure logging: `appender=com.p6spy.engine.spy.appender.Slf4JLogger` for SLF4J integration, configure drivers: `driverlist=com.mysql.cj.jdbc.Driver` (example for MySQL). Document configuration in docs/integration/p6spy-audit-setup.md: explain module registration, provide spy.properties template with audit module enabled, document deployment.

4. **Integration Testing:** Write integration test `P6SpyAuditIntegrationTest` with P6Spy-wrapped datasource: configure DriverManager with P6Spy driver (com.p6spy.engine.spy.P6SpyDriver), configure spy.properties with audit module enabled, execute SQL via JDBC Connection: successful SELECT capturing timing and result size, successful UPDATE capturing rows affected, failed execution capturing exception, batch UPDATE with executeBatch() capturing aggregated results. For each scenario: verify audit event written to mock AuditLogWriter, verify SQL captured with parameters (expect parameter values substituted), verify execution timing accurate (within reasonable range), verify rows affected correct for DML. Test multi-driver compatibility: run tests with MySQL driver, PostgreSQL driver, H2 driver wrapped by P6Spy, verify audit logging works across all drivers. Test coordination with P6SpySqlSafetyListener: enable both safety and audit listeners, execute SQL violating safety rules (e.g., no WHERE clause), verify audit event includes violations from pre-execution validation (via ThreadLocal correlation pattern), verify safety listener and audit listener coexist.

5. **Performance and Documentation:** Write performance test `P6SpyAuditPerformanceTest` measuring overhead: execute 10000 SQL statements with P6Spy audit enabled vs raw JDBC, calculate overhead percentage, document findings (expected 12-18% overhead combining safety validation + audit logging vs 10-15% for safety only from Task 4.5), compare to native solutions (Druid audit ~7%, MyBatis audit ~5%). Document P6Spy audit limitations: parameter substitution exposes data in logs (sanitize sensitive fields for production), higher overhead than native interceptors (universal compatibility tradeoff), batch result aggregation may not provide per-statement detail, limited DI support complicates configuration. Update p6spy-audit-setup.md with: when to use P6Spy audit (fallback for unsupported pools, unified audit across mixed frameworks), when to use native solutions (performance-critical scenarios, feature-rich environments), configuration examples for common scenarios (Spring Boot integration, standalone usage, Docker deployment). Run `mvn test` ensuring all P6Spy audit tests pass.

---

## Phase 9: Audit-Specific Checker Layer - Agent_Audit_Analysis

**Phase Overview:** Implement audit-specific checkers leveraging post-execution context (execution results, timing, error information) for advanced SQL analysis impossible at pre-execution time. These checkers provide precise risk assessment using actual impact metrics, enabling discovery-based auditing complementing prevention-focused runtime checkers from Phases 1-7.

### Task 9.1 – AbstractAuditChecker Base Class & ExecutionResult Context │ Agent_Audit_Analysis

- **Objective:** Design AbstractAuditChecker base class providing execution result access and multi-dimensional risk scoring framework for audit checkers, establishing architectural foundation enabling context-aware analysis with execution metrics (rows affected, duration, errors) unavailable during pre-execution validation.
- **Output:**
  - AbstractAuditChecker abstract class with check() method accepting ExecutionResult parameter
  - ExecutionResult data model containing execution metrics: rowsAffected, executionTimeMs, errorMessage, resultSetSize
  - Multi-dimensional risk scoring model: RiskScore class with severity (LOW/MEDIUM/HIGH/CRITICAL), confidence (0-100), impact metrics
  - Template method pattern for consistent checker lifecycle: pre-check validation, core analysis, post-check scoring
  - Performance baseline: audit checkers have relaxed performance requirements vs runtime (<50ms acceptable vs <5ms for runtime)
  - Comprehensive test suite validating base class behavior and extension points
- **Guidance:** ExecutionResult provides post-execution context enabling precise analysis: rows affected reveals actual data impact (0 rows vs 10000 rows for same SQL), execution time identifies slow queries, error messages capture failures for error rate analysis, result set size detects large data transfers. Multi-dimensional scoring replaces binary pass/fail from runtime validation: severity indicates risk level, confidence reflects certainty of assessment (100% for concrete metrics like row count, lower for heuristics), impact metrics quantify potential damage enabling prioritized remediation. Template method ensures consistent checker structure: validate input completeness, perform core audit logic, calculate risk score with justification, return AuditResult with actionable recommendations. Performance tradeoff: audit runs asynchronously in separate service (sql-audit-service), <50ms acceptable per checker vs <5ms runtime requirement, enables complex analysis (statistical aggregation, pattern matching, anomaly detection). Depends on: Task 8.1 Output (AuditEvent model containing execution context).

1. **ExecutionResult Model TDD:** Write test class `ExecutionResultTest` with test methods: `testBuilder_withAllMetrics_shouldConstruct()` (complete execution result construction), `testBuilder_withErrorOnly_shouldConstructFailureResult()` (error execution without success metrics), `testRowsAffected_forDifferentOperations_shouldReflectActual()` (SELECT returns result set size, UPDATE returns affected count), `testExecutionTime_shouldSupportMicrosecondPrecision()` (duration captured accurately), `testEquals_withSameMetrics_shouldBeEqual()` (value object semantics). Implement `ExecutionResult` class in `com.footstone.sqlguard.audit.model` package with immutable fields: int rowsAffected (actual rows from SQL execution, -1 if not applicable), long executionTimeMs (actual execution duration from interceptor timing), String errorMessage (SQLException message if execution failed, nullable), int resultSetSize (for SELECT queries, nullable), Instant executionTimestamp (when execution completed), Map<String, Object> additionalMetrics (extensibility for custom metrics like cache hit rate). Implement builder pattern with validation: ExecutionResult.builder().rowsAffected(count).executionTimeMs(duration).build(), validate rowsAffected >= -1, executionTimeMs >= 0, timestamp not null.

2. **RiskScore Model TDD:** Write test class `RiskScoreTest` with test methods: `testBuilder_withAllDimensions_shouldConstruct()`, `testSeverity_shouldEnforceValidLevels()` (only LOW/MEDIUM/HIGH/CRITICAL allowed), `testConfidence_shouldEnforceRange()` (0-100 range validation), `testImpactMetrics_shouldBeImmutable()` (defensive copy of metrics map), `testCompareTo_shouldSortBySeverityThenConfidence()` (CRITICAL > HIGH regardless of confidence, within same severity sort by confidence descending). Implement `RiskScore` class in audit.model package with fields: RiskLevel severity (enum LOW/MEDIUM/HIGH/CRITICAL matching existing ValidationResult), int confidence (0-100, represents assessment certainty: 100 for concrete metrics, 80 for statistical analysis, 50 for heuristics), Map<String, Number> impactMetrics (quantified impact: data_volume_affected, query_cost_estimate, risk_score_points), String justification (human-readable explanation of why this score assigned), List<String> recommendations (actionable steps for remediation). Implement Comparable interface for risk prioritization in audit reports.

3. **AbstractAuditChecker Template TDD:** Write test class `AbstractAuditCheckerTest` with test methods: `testCheck_withValidInput_shouldInvokeTemplate()` (template method calls pre/core/post in sequence), `testCheck_withNullExecutionResult_shouldThrowException()` (input validation), `testCheck_withIncompleteResult_shouldHandleGracefully()` (partial metrics don't crash checker), `testPerformance_shouldMeetRelaxedRequirements()` (check() completes in <50ms for typical input). Implement `AbstractAuditChecker` abstract class in `com.footstone.sqlguard.audit.checker` package with template method: `public final AuditResult check(String sql, ExecutionResult result)` calling sequence: validateInput(sql, result) - throws IllegalArgumentException if required fields null, performAudit(sql, result) - abstract method for subclass implementation returning RiskScore, buildAuditResult(sql, result, score) - creates AuditResult with checker metadata. Provide utility methods for subclasses: extractTable(sql) - JSqlParser extraction, extractWhereClause(sql) - condition analysis, calculateImpactScore(rowsAffected) - standard impact calculation, isSlowQuery(executionTimeMs, threshold) - performance assessment.

4. **AuditResult Model TDD:** Write test class `AuditResultTest` with test methods: `testBuilder_withCompleteData_shouldConstruct()`, `testBuilder_withMultipleRisks_shouldAggregate()` (single checker may identify multiple risks), `testToJson_shouldSerializeForStorage()` (audit results stored in ClickHouse), `testEquals_shouldCompareAllFields()`. Implement `AuditResult` class in audit.model package with fields: String checkerId (checker identifier for tracking), String sql (audited SQL), ExecutionResult executionResult (original execution context), List<RiskScore> risks (multiple risks possible from single check), Instant auditTimestamp (when audit performed), Map<String, Object> checkerMetadata (checker-specific context: thresholds used, baselines compared). Implement serialization support for database storage: Jackson annotations for JSON, ensure all fields serializable.

5. **Integration Testing & Base Behavior:** Write integration test `AbstractAuditCheckerIntegrationTest` creating concrete test checker implementations: SimpleAuditChecker detecting queries returning >1000 rows with HIGH severity, SlowQueryTestChecker detecting >1000ms execution with CRITICAL severity, ErrorAuditChecker analyzing error messages for specific failure patterns. For each test checker: implement performAudit() with specific logic, test with various ExecutionResult scenarios (success with high impact, success with low impact, failure with error, edge cases like 0 rows affected), verify RiskScore severity matches expected level, verify confidence calculation appropriate (100% for row count-based, lower for heuristics), verify justification provides actionable information, verify recommendations relevant to detected risk. Test template method enforcement: attempt to override final check() method (should be impossible), verify pre-check validation called before performAudit(), verify error handling propagates to AuditResult. Benchmark performance: run checkers with 1000 different ExecutionResults, measure p95/p99 latencies, verify <50ms p99 threshold met, compare to runtime checker performance (<5ms requirement) confirming relaxed audit requirements. Run `mvn test` ensuring all AbstractAuditChecker foundation tests pass.

### Task 9.2 – High-Value Audit Checkers (P0) │ Agent_Audit_Analysis

- **Objective:** Implement P0 audit checkers providing highest-value insights from execution data: SlowQueryChecker identifying performance bottlenecks, ActualImpactNoWhereChecker assessing real data impact, FullTableScanChecker detecting expensive scans, and ErrorRateChecker tracking failure patterns - these checkers deliver immediate ROI justifying audit platform investment.
- **Output:**
  - SlowQueryChecker with configurable thresholds and percentile tracking
  - ActualImpactNoWhereChecker correlating missing WHERE with rows affected
  - FullTableScanChecker analyzing execution plans for table scans **[复杂-建议第二迭代] (Medium Fix M2)**
  - ErrorRateChecker aggregating failure statistics **[复杂-需状态管理] (Medium Fix M2)**
  - 35+ tests per checker following TDD test matrix pattern
  - Performance benchmarks validating <50ms per check
  - Integration with ExecutionResult context
- **Guidance:** **Medium Fix M2 - 复杂度说明:** SlowQueryChecker和ActualImpactNoWhereChecker相对简单(直接使用ExecutionResult数据)，建议优先实现；FullTableScanChecker需要数据库特定的执行计划解析(EXPLAIN语法各数据库不同)，建议第二迭代实现或使用启发式降级方案；ErrorRateChecker需要跨请求状态聚合(时间窗口统计)，完整实现依赖Task 10.3的审计引擎，初始版本提供单次执行错误分类。P0 checkers target high-impact, high-confidence scenarios requiring execution results: slow queries impossible to detect pre-execution (need actual timing), actual impact assessment requires rows affected (same SQL different data), full table scans require execution plan analysis (EXPLAIN unavailable pre-execution), error rates need aggregated failure statistics. Each checker implements multi-level severity: SlowQueryChecker uses tiered thresholds (>1s MEDIUM, >5s HIGH, >10s CRITICAL), ActualImpactNoWhereChecker considers row scale (10 rows MEDIUM, 100 rows HIGH, 1000+ CRITICAL), FullTableScanChecker weighs table size vs scan necessity. Confidence scoring: 100% for concrete metrics (timing, row count), 90% for execution plan analysis (depends on database optimizer), 80% for statistical error rates (depends on sample size). Depends on: Task 9.1 Output (AbstractAuditChecker base class, ExecutionResult, RiskScore).

1. **SlowQueryChecker TDD Implementation:** Write comprehensive test class `SlowQueryCheckerTest` with 35+ tests covering: **Functional Tests (12)** - testSlowQuery_above1Second_shouldDetectMedium() (1000-5000ms → MEDIUM), testSlowQuery_above5Seconds_shouldDetectHigh() (5000-10000ms → HIGH), testSlowQuery_above10Seconds_shouldDetectCritical() (>10000ms → CRITICAL with 100% confidence), testFastQuery_below1Second_shouldPass() (<1000ms → no risk), testSlowSelect_shouldIncludePlan() (SELECT queries suggest index), testSlowUpdate_shouldSuggestBatch() (UPDATE queries suggest batching), testSlowJoin_shouldAnalyzeJoinConditions() (JOIN complexity analysis); **Configuration Tests (8)** - testCustomThresholds_shouldOverrideDefaults() (user-defined thresholds), testPercentileTracking_shouldCalculateP95P99() (track distribution for baseline), testDifferentSqlTypes_shouldUseSeparateThresholds() (SELECT vs UPDATE thresholds); **Edge Cases (10)** - testZeroExecutionTime_shouldHandle() (clock precision), testNegativeTime_shouldReject() (invalid input), testVeryLongQuery_shouldStillAnalyze() (10-minute queries); **Performance Tests (5)** - testCheckPerformance_shouldCompleteFast() (verify <10ms check time). Implement `SlowQueryChecker` class extending AbstractAuditChecker: in performAudit() extract executionTimeMs from ExecutionResult, compare against configurable thresholds (default: 1000/5000/10000ms for MEDIUM/HIGH/CRITICAL), calculate confidence = 100 (concrete timing metric), build RiskScore with severity based on threshold exceeded, add impactMetrics: query_duration_ms, threshold_exceeded_by_ms, percentile_rank (if baseline available), generate justification: "Query executed in {duration}ms exceeding {threshold}ms threshold", provide recommendations based on SQL type and duration: for SELECT suggest indexing fields in WHERE/JOIN, for UPDATE suggest batching or smaller transactions, for complex JOIN suggest query optimization or materialized views. Support configuration: customizable thresholds per SQL type, percentile baseline tracking for anomaly detection (flag queries >2σ from p95), whitelist for expected slow queries (reporting queries, batch jobs).

2. **ActualImpactNoWhereChecker TDD Implementation:** Write test class `ActualImpactNoWhereCheckerTest` with 30+ tests: **Functional Tests** - testNoWhere_zeroRows_shouldDetectLow() (0 rows affected → LOW, may be intentional check query), testNoWhere_10Rows_shouldDetectMedium() (1-100 rows → MEDIUM), testNoWhere_100Rows_shouldDetectHigh() (100-1000 rows → HIGH), testNoWhere_1000PlusRows_shouldDetectCritical() (>1000 rows → CRITICAL), testWithWhere_anyRows_shouldPass() (WHERE present regardless of rows), testDeleteNoWhere_shouldEscalate() (DELETE without WHERE more severe than SELECT); **Context Analysis** - testDummyCondition_highImpact_shouldDetectCritical() (WHERE 1=1 with 1000+ rows), testSelectNoWhere_zeroResults_shouldExplain() (empty table, LOW with explanation), testUpdateNoWhere_productionTable_shouldCritical() (production datasource escalation); **Integration** - testPreExecutionViolation_correlation_shouldCombine() (correlate runtime NoWhereClauseChecker violation with actual impact). Implement `ActualImpactNoWhereChecker` extending AbstractAuditChecker: in performAudit() parse SQL to detect WHERE clause absence (reuse JSqlParser from pre-execution checker), extract rowsAffected from ExecutionResult, calculate severity based on row scale and SQL type: DELETE/UPDATE more severe than SELECT at same row count, scale thresholds: 0 rows=LOW, 1-100=MEDIUM, 100-1000=HIGH, >1000=CRITICAL, confidence = 100 (concrete row count metric), build impactMetrics: rows_affected, table_estimated_size (if available from statistics), risk_score_points = rows * severity_multiplier, generate contextual justification explaining both missing WHERE and actual impact, recommendations: rewrite query with WHERE conditions limiting scope, for UPDATE/DELETE suggest soft delete or staged execution, for production alert DBA for review. Support correlation with pre-execution validation: check ThreadLocal for ValidationResult from runtime checker, combine violation flags in audit result.

3. **FullTableScanChecker TDD Implementation:** Write test class `FullTableScanCheckerTest` with 30+ tests covering execution plan analysis: testFullScan_largeTable_shouldDetectHigh() (table >100k rows + full scan → HIGH), testFullScan_smallTable_shouldDetectLow() (table <1000 rows acceptable), testIndexUsed_anyTable_shouldPass() (index usage detected), testSeqScan_withoutWhere_shouldExplain() (sequential scan correlation with missing WHERE), testMultiTableJoin_cartesianProduct_shouldDetectCritical() (join without condition). Implement `FullTableScanChecker` extending AbstractAuditChecker: NOTE - this checker requires execution plan access which varies by database and may need asynchronous EXPLAIN execution in audit service rather than inline checking, for initial implementation: in performAudit() use execution metrics as proxy: high executionTimeMs + high rowsAffected suggests scan, parse SQL for WHERE clause and index hints, if execution plan available (from database-specific interceptor extension): parse plan for "Seq Scan", "TABLE ACCESS FULL", "INDEX FULL SCAN" indicators, extract table row estimates from plan, calculate severity: large table (>100k rows) + full scan = HIGH, very large table (>1M rows) + full scan = CRITICAL, confidence varies: 90% with execution plan, 60% with proxy metrics (duration + row count heuristic), impactMetrics: table_size, scan_cost_estimate, index_candidates, justification explaining scan type and table scale, recommendations: suggest indexes on WHERE/JOIN fields, consider query rewrite or materialized view for complex analytics, whitelist for intentional full scans (daily batch aggregations). Document limitation: full plan analysis requires database-specific implementation in audit service (Task 10.3), initial version uses heuristics with lower confidence.

4. **ErrorRateChecker TDD Implementation:** Write test class `ErrorRateCheckerTest` with 25+ tests covering statistical aggregation: testSingleError_shouldTrack() (individual error logged), testHighErrorRate_shouldDetectCritical() (>10% error rate in 5min window → CRITICAL), testIntermittentErrors_shouldDetectMedium() (1-10% error rate → MEDIUM), testSpecificError_shouldCategorize() (syntax error vs constraint violation vs deadlock), testErrorPattern_shouldIdentifyRoot() (same error repeated suggests systemic issue). Implement `ErrorRateChecker` extending AbstractAuditChecker: NOTE - this checker requires aggregation state across multiple audit events, implement in audit service (Task 10.3) with windowed statistics, for initial version: in performAudit() analyze single execution error, extract errorMessage from ExecutionResult, categorize error type using pattern matching: SQLException SQLState codes (23000=integrity, 40001=deadlock, 42000=syntax), error message patterns (timeout, connection refused, OOM), calculate preliminary severity: syntax error LOW (developer fix), constraint violation MEDIUM (data issue), deadlock HIGH (concurrency problem), connection error CRITICAL (infrastructure issue), confidence = 70 for single-execution analysis (increases to 95 with aggregated statistics in service), impactMetrics: error_type, error_code, affected_operations=1 (increases with aggregation), justification explaining error category and potential root cause, recommendations based on error type: syntax → code review, constraint → data validation, deadlock → transaction scope reduction, connection → infrastructure check. Document enhancement: full error rate analysis implemented in audit service with time-window aggregation (Task 10.3), initial version provides per-execution error classification.

5. **Integration Testing & Performance:** Write integration test `P0AuditCheckersIntegrationTest` with comprehensive scenarios combining all P0 checkers: slow query without WHERE with high impact (triggers SlowQuery + ActualImpactNoWhere + possible FullTableScan), fast query with low impact (all checkers pass), query with error after long execution (SlowQuery + ErrorRate), production scenario with mixed workload (batch of queries with various characteristics). For each scenario: create realistic ExecutionResult with actual metrics, run all P0 checkers sequentially, verify appropriate RiskScores generated, verify risk aggregation in combined AuditResult, verify no false positives (fast query with WHERE should pass all checks), verify recommendations actionable and non-conflicting. Benchmark performance: create dataset of 10000 varied ExecutionResults (distribution: 80% normal, 15% slow, 5% error), run all P0 checkers on each, measure total audit time per execution, verify <50ms p99 for all checkers combined (SlowQuery <5ms, ActualImpact <10ms, FullTableScan <20ms, ErrorRate <5ms), verify memory usage stable across 10k iterations (no memory leaks in aggregation logic). Run `mvn test` ensuring all P0 audit checker tests pass with 100% coverage of edge cases.

### Task 9.3 – Performance Optimization Audit Checkers (P1) │ Agent_Audit_Analysis

- **Objective:** Implement P1 audit checkers focusing on query performance optimization and resource efficiency: IndexMissingChecker suggesting index improvements, LargeResultSetChecker detecting excessive data transfers, MustParameterizedAuditChecker tracking dynamic SQL patterns, and SelectAllColumnsAuditChecker assessing projection efficiency - these checkers enable proactive performance tuning based on production workload analysis.
- **Output:**
  - IndexMissingChecker with query pattern analysis and index recommendations
  - LargeResultSetChecker with configurable thresholds for result set sizes
  - MustParameterizedAuditChecker correlating dynamic SQL with execution frequency
  - SelectAllColumnsAuditChecker detecting SELECT * usage with large result sets
  - 30+ tests per checker with TDD methodology
  - Configuration support for environment-specific thresholds
  - Integration with historical execution data for trend analysis
- **Guidance:** P1 checkers provide optimization opportunities discovered through execution analysis: index recommendations require actual query patterns (cannot predict pre-execution which WHERE fields are performance-critical), large result sets detected via actual resultSetSize (not predictable from SQL text), dynamic SQL impact measured via execution frequency (single-use dynamic SQL acceptable, high-frequency dynamic SQL suggests caching opportunity), SELECT * overhead quantified by actual column count vs used columns. These checkers operate with lower confidence than P0: index recommendations 70-80% confidence (depends on query frequency and selectivity estimates), large result set detection 90% confidence (concrete metric but threshold subjective), dynamic SQL assessment 60% confidence (requires usage pattern analysis over time). Checkers support configuration: environment-specific thresholds (dev vs staging vs production), table-specific overrides (reporting tables expected large results), whitelist for known patterns (admin queries, analytics exports). Depends on: Task 9.1 Output (AbstractAuditChecker), Task 9.2 patterns for similar implementation structure.

1-4. **[Implementation details for IndexMissingChecker, LargeResultSetChecker, MustParameterizedAuditChecker, SelectAllColumnsAuditChecker following similar TDD pattern as Task 9.2 with 30+ tests each, detailed performAudit() implementation, multi-dimensional risk scoring, and specific recommendations]**

5. **Integration Testing:** [Integration tests combining all P1 checkers, performance benchmarks, configuration validation, ensuring <50ms combined execution time]

### Task 9.4 – Behavioral Analysis Audit Checkers (P2) │ Agent_Audit_Analysis

- **Objective:** Implement P2 audit checkers for behavioral anomaly detection and access pattern analysis: FrequencyAnomalyChecker identifying unusual query patterns, DataAccessPatternChecker tracking temporal access trends, ZeroImpactQueryChecker detecting wasteful queries, and SensitiveDataAccessChecker monitoring sensitive field access - these checkers enable advanced security and efficiency auditing through statistical analysis of execution history.
- **Output:**
  - FrequencyAnomalyChecker with statistical anomaly detection algorithms
  - DataAccessPatternChecker with temporal pattern recognition
  - ZeroImpactQueryChecker identifying queries with consistently zero results
  - SensitiveDataAccessChecker tracking PII field access patterns
  - 25+ tests per checker covering statistical edge cases
  - Integration with time-series database (ClickHouse) for historical analysis
  - Baseline establishment and drift detection mechanisms
  - **降级模式支持 (High Fix H3 新增):** 若Task 10.4历史数据分析能力未就绪，以警告模式运行
- **Guidance:** **High Fix H3 - 显式依赖声明:** P2 Checkers强依赖Task 10.4历史数据分析能力。若Task 10.4未完成，P2 Checkers以降级模式运行: 不执行统计分析，仅输出WARN级别日志"P2 checker {name} skipped: historical data service unavailable"，不返回RiskScore(跳过评分)，通过HealthIndicator暴露降级状态供监控。P2 checkers require historical context and statistical analysis: frequency anomalies detected via baseline comparison (queries normally run 10/hour suddenly 1000/hour), access patterns analyzed via time-series clustering (unusual late-night access), zero impact queries identified via consistent 0-row results (cache miss or business logic issue), sensitive data access tracked via field-level monitoring (accessing salary, SSN fields). These checkers have lowest confidence: 50-70% (statistical inference, false positives possible), require tuning period for baseline establishment (minimum 7 days data), operate asynchronously in audit service aggregating execution history. Configuration supports: baseline update frequency, anomaly detection sensitivity (sigma thresholds), sensitive field definitions per table, temporal pattern definitions (business hours, weekend, holiday patterns). Depends on: Task 9.1 Output (AbstractAuditChecker), Task 10.4 Output (time-series storage for historical data) - **必须依赖**.

1-4. **[Implementation details for FrequencyAnomalyChecker, DataAccessPatternChecker, ZeroImpactQueryChecker, SensitiveDataAccessChecker with statistical algorithms, baseline management, and temporal analysis]**

5. **Integration Testing:** [Statistical validation, baseline establishment testing, anomaly detection accuracy measurement, false positive rate validation]

---

## Phase 10: SQL Audit Service (Java 21 with Virtual Threads) - Agent_Audit_Service

**Phase Overview:** Build centralized sql-audit-service as standalone Spring Boot 3.2+ application leveraging Java 21 Virtual Threads for high-concurrency Kafka consumption, executing all audit checkers against SQL execution logs, persisting audit results to PostgreSQL (metadata) and ClickHouse (time-series data), and exposing REST API for query, statistics, and reporting.

### Task 10.1 – Project Foundation & Architecture Setup │ Agent_Audit_Service

- **Objective:** Establish sql-audit-service project structure as independent Spring Boot 3.2+ application with Java 21 baseline, configure Maven multi-module layout separating audit-service-core (business logic), audit-service-web (REST API), and audit-service-consumer (Kafka integration), and establish Virtual Thread executor configuration for high-concurrency audit processing.
- **Output:**
  - Maven multi-module project: audit-service-parent POM with Java 21 configuration
  - audit-service-core module: domain models, audit engine, checker orchestration
  - audit-service-web module: Spring MVC REST API, API documentation (OpenAPI)
  - audit-service-consumer module: Kafka consumer with Virtual Thread executor
  - Docker Compose: Kafka, PostgreSQL, ClickHouse, audit service containers
  - application.yml with environment profiles (dev/staging/prod)
  - Virtual Thread executor configuration: structured concurrency for audit tasks
- **Guidance:** Java 21 enablers: Virtual Threads eliminate thread pool management for Kafka consumers (can create thread-per-message), Record classes for immutable domain models reduce boilerplate, Pattern Matching simplifies SQL type switching, Structured Concurrency coordinates parallel checker execution per audit event. Maven structure follows domain separation: core = pure business logic (no Spring, no Kafka), web = HTTP concerns only, consumer = messaging concerns only, enables independent testing and deployment flexibility. Virtual Thread configuration: spring.threads.virtual.enabled=true for automatic Virtual Thread usage in @Async, custom Executor for Kafka listener: `Executors.newVirtualThreadPerTaskExecutor()` creates unlimited virtual threads without memory overhead vs platform threads. Docker Compose provides local development environment: Kafka for message queue, PostgreSQL for audit metadata (audit results, checker config, user info), ClickHouse for time-series SQL execution data (high-volume, columnar storage), audit service with health checks. Depends on: Phase 9 Output (all audit checkers compiled as library JAR dependency).

1-5. **[Implementation details: Maven POM configuration, module structure, Virtual Thread setup, Docker Compose configuration, Spring Boot 3.2+ baseline with comprehensive testing]**

### Task 10.2 – Kafka Consumer with Virtual Threads │ Agent_Audit_Service

- **Objective:** Implement Kafka consumer subscribing to sql-audit-events topic with Virtual Thread-based message processing achieving 10,000 msg/s throughput target, deserializing AuditEvent JSON from audit log interceptors, routing to audit engine for checker execution, handling backpressure and error scenarios, and providing monitoring metrics for consumption lag and processing rates.
- **Output:**
  - KafkaAuditEventConsumer with @KafkaListener using Virtual Threads
  - AuditEvent deserialization from JSON using Jackson configuration from Task 8.1
  - Virtual Thread executor managing concurrency without thread limits
  - Backpressure handling: dynamic concurrency adjustment based on processing latency
  - Error handling: retry logic for transient failures, dead letter queue for poison messages
  - Monitoring: Micrometer metrics for throughput, lag, processing time distribution
  - Performance tests validating 10,000 msg/s throughput with <100ms p99 latency
- **Guidance:** Virtual Threads eliminate traditional consumer pool sizing: create thread-per-message without memory concerns (1M virtual threads possible vs ~1000 platform threads), structured concurrency coordinates audit checker execution within message handler. Kafka consumer configuration: high max.poll.records (500) for batch efficiency, manual offset commit after successful audit (at-least-once guarantee), consumer group for horizontal scaling (multiple service instances). Backpressure management: monitor audit processing time, reduce max.poll.records dynamically if p99 >200ms, increase when latency low, prevents consumer lag during load spikes. Error handling strategy: transient errors (database timeout, checker exception) → retry with exponential backoff max 3 attempts, poison messages (JSON deserialization failure) → send to DLQ after logging, permanent failures (invalid SQL) → log and skip with metric increment. Monitoring integration: Micrometer gauge for consumer lag, timer for processing duration, counter for processed/failed/retried messages, export to Prometheus for Grafana dashboards. Depends on: Task 8.1 Output (AuditEvent JSON schema), Task 9.1 Output (audit checkers to invoke).

1-5. **[Implementation details: Kafka consumer configuration, Virtual Thread integration, error handling, backpressure management, performance testing achieving 10k msg/s]**

### Task 10.3 – Audit Engine & Checker Orchestration │ Agent_Audit_Service

- **Objective:** Implement audit engine orchestrating execution of all Phase 9 checkers against each consumed AuditEvent, coordinating parallel checker execution using CompletableFuture (Critical Fix C1: Structured Concurrency is Preview feature in Java 21), aggregating RiskScore results into comprehensive AuditReport, applying checker configuration and whitelisting rules, and persisting final audit results to storage layer for query and reporting.
- **Output:**
  - AuditEngine interface with executeAudit(AuditEvent) method
  - DefaultAuditEngine implementation orchestrating all checkers
  - CompletableFuture.allOf() coordination: parallel checker execution with timeout (替代Structured Concurrency)
  - Checker registry: auto-discovery of audit checkers via Spring component scan
  - Configuration management: per-checker thresholds, enabled/disabled flags, whitelist rules
  - Result aggregation: combines multiple RiskScores into prioritized AuditReport
  - Integration tests validating all Phase 9 checkers execute correctly
- **Guidance:** **Critical Fix C1**: 使用CompletableFuture.allOf()替代Structured Concurrency(JEP 453)，因为Structured Concurrency在Java 21中仍是Preview特性，不建议用于生产环境。实现方案: 为每个checker创建CompletableFuture.supplyAsync()任务，使用Virtual Thread Executor，通过allOf().orTimeout(200, TimeUnit.MILLISECONDS)设置超时，handle()处理单个checker异常(部分结果可接受)。Checker registry uses Spring's component scanning: all AbstractAuditChecker implementations auto-discovered, registered in CheckerRegistry by checkerId, enabled/disabled via configuration (yaml or database). Configuration layering: default thresholds in code, override via application.yml, runtime override via database (for dynamic tuning without deployment), whitelist rules stored in PostgreSQL (SQL patterns exempted from specific checkers). Result aggregation algorithm: collect all RiskScores from checkers, prioritize by severity (CRITICAL first) then confidence (higher confidence first), generate AuditReport with top N risks (configurable, default 5), include checker metadata (which checkers ran, execution times, any failures), attach original AuditEvent for correlation, calculate aggregate risk score (weighted sum of individual scores). 添加Virtual Threads监控和回退机制(Medium Fix M10): 通过Micrometer暴露virtual thread指标，若检测到问题可回退至传统线程池。Error handling: individual checker exception → log warning + continue other checkers, total timeout (>200ms) → return partial results + warning, zero checkers enabled → skip event + metric, all checkers fail → DLQ + alert. Depends on: Task 9.2/9.3/9.4 Output (all audit checkers), Task 10.2 Output (Kafka consumer integration).

1-5. **[Implementation details: AuditEngine orchestration, Structured Concurrency usage, checker registry, configuration management, result aggregation with comprehensive testing]**

### Task 10.4 – Storage Layer: PostgreSQL & ClickHouse Integration │ Agent_Audit_Service

- **Objective:** Implement dual-database storage strategy with PostgreSQL for audit metadata (AuditReport, checker configuration, user management) and ClickHouse for high-volume time-series SQL execution data (raw AuditEvents, execution metrics, trends), providing JPA repositories for PostgreSQL and ClickHouse JDBC client for time-series inserts, and optimizing schema for query performance and storage efficiency.
- **Output:**
  - PostgreSQL schema: audit_reports table with JPA entity mapping
  - ClickHouse schema: sql_executions table with MergeTree engine for time-series
  - AuditReportRepository (JPA) for audit result CRUD operations
  - ClickHouseExecutionLogger for high-volume raw event storage
  - **PostgreSQL-Only模式 (High Fix H2 新增):** 可选纯PostgreSQL部署，适合中小规模(<1M条/天)
  - Data retention policies: ClickHouse TTL for 90-day raw data, PostgreSQL for 365-day aggregates
  - Query optimization: indexes on common query patterns, partitioning for large tables
  - Integration tests with Testcontainers for PostgreSQL and ClickHouse
- **Guidance:** Dual storage rationale: PostgreSQL for ACID-compliant metadata (audit reports queried by risk level, time range, SQL pattern), ClickHouse for analytical queries on raw executions (time-series aggregations, percentile calculations, trend detection). **High Fix H2 - PostgreSQL-Only模式:** 提供纯PostgreSQL部署选项，使用BRIN索引优化时序查询，TimescaleDB扩展可选(自动分区)，适合日审计量<1M条的中小规模场景，通过配置sql-audit.storage.mode=postgresql-only启用，降低运维复杂度(无需维护ClickHouse集群)。PostgreSQL schema: audit_reports table with columns (id, audit_timestamp, sql_hash, severity, confidence, risks_json, event_json, created_at), risks_json stores List<RiskScore> as JSONB for flexible querying, indexes on (audit_timestamp, severity) for report queries, (sql_hash) for deduplication checks, partition by month for large installations. ClickHouse schema: sql_executions table with columns (execution_timestamp, sql_hash, mapper_id, datasource, execution_time_ms, rows_affected, error_message, violations_count) using MergeTree engine sorted by (datasource, execution_timestamp), TTL for automatic 90-day deletion, materialized views for pre-aggregated statistics (hourly/daily execution counts, p95/p99 latencies by mapper). Repository implementation: AuditReportRepository extends JpaRepository with custom query methods (findBySeverity, findByTimestampBetween, findBySqlHashContaining), ClickHouseExecutionLogger uses JDBC batch inserts (batch size 10000) for throughput, async writes to prevent blocking Kafka consumer. Testcontainers integration: PostgreSQLContainer for PostgreSQL 15, ClickHouseContainer for ClickHouse 23.x, test data fixtures for realistic query testing. Depends on: Task 10.3 Output (AuditReport model), Task 8.1 Output (AuditEvent model).

1-5. **[Implementation details: PostgreSQL JPA entities, ClickHouse JDBC integration, data retention, query optimization, Testcontainers testing]**

### Task 10.5 – REST API & Monitoring Endpoints │ Agent_Audit_Service

- **Objective:** Expose REST API for querying audit results, accessing execution statistics, generating compliance reports, and managing checker configuration, implementing Spring MVC controllers with pagination support, comprehensive error handling, API documentation via SpringDoc OpenAPI, and monitoring endpoints for service health and Kafka consumer metrics.
- **Output:**
  - AuditReportController: GET /api/v1/audits with filtering, pagination, sorting
  - StatisticsController: GET /api/v1/statistics for aggregated metrics (top risky SQL, slow query trends, error rates)
  - ConfigurationController: PUT /api/v1/checkers/{id}/config for dynamic threshold updates
  - OpenAPI documentation: Swagger UI at /swagger-ui.html with API examples
  - Health endpoints: /actuator/health with Kafka connectivity, database status
  - Metrics endpoints: /actuator/prometheus for Grafana integration (consumer lag, processing rates, audit queue depth)
  - Integration tests using MockMvc validating all endpoints
- **Guidance:** Query API design: GET /api/v1/audits supports filtering (severity, dateFrom, dateTo, sqlPattern, datasource), pagination (page, size defaulting to 0, 20), sorting (timestamp DESC default), returns Page<AuditReportDto> with risk summary. Statistics API aggregations: top 10 risky SQL by aggregate score, slow query trends (hourly p95/p99 over last 7 days), error rate by category (syntax, constraint, deadlock), datasource comparison (production vs staging audit findings). Configuration API: GET /api/v1/checkers lists all checkers with current config, PUT /api/v1/checkers/{id}/config updates thresholds (requires validation), persists to PostgreSQL for runtime application without restart, audit log captures config changes for compliance. OpenAPI integration: SpringDoc annotations (@Operation, @ApiResponse) document all endpoints, example requests/responses for developer reference, security schema for future authentication. Health checks: Kafka consumer connectivity (via AdminClient), PostgreSQL connection pool status, ClickHouse availability, disk space remaining for audit logs, overall status=UP only if all dependencies healthy. Metrics: Micrometer @Timed on controller methods, custom gauges for audit queue depth (pending in Kafka), consumer lag gauge (current offset vs end offset), histogram for processing latency distribution, export format compatible with Prometheus scraping. Depends on: Task 10.3 Output (AuditEngine for query execution), Task 10.4 Output (repositories for data access).

1-5. **[Implementation details: REST controllers, OpenAPI documentation, health checks, metrics endpoints, comprehensive API testing]**

---

## Phase 11: Compatibility & Migration Strategy - Agent_Core_Engine_Foundation

**Phase Overview:** Ensure zero-breaking-changes migration path from existing sql-guard codebase (Phases 1-7) to expanded audit platform, maintaining 100% backward compatibility while introducing new audit capabilities, providing clear deprecation markers and migration guides, and validating existing tests continue passing with new architecture.

### Task 11.1 – Compatibility Layer Maintenance │ Agent_Core_Engine_Foundation

- **Objective:** Maintain existing sql-guard-core validator APIs in fully functional state while introducing parallel audit-specific implementations, marking legacy single-purpose code paths with @Deprecated annotations and migration guidance, ensuring all existing runtime interceptors (MyBatis, MyBatis-Plus, Druid, P6Spy) continue working unchanged, and validating 100% existing test suite passes without modification.
- **Output:**
  - Existing SqlSafetyValidator interface unchanged and fully functional
  - Legacy RuleChecker implementations (NoWhereClauseChecker, etc.) marked @Deprecated with migration notes
  - Compatibility shim layer: existing validators delegate to appropriate runtime/audit checkers based on execution context
  - All existing runtime interceptors work without code changes
  - Validation: 500+ existing tests from Phases 1-7 pass at 100% rate
  - Migration guide: docs/migration/audit-platform-migration.md
  - **配置诊断端点 (Medium Fix M3 新增):** /actuator/sql-guard/config端点，输出最终生效配置及来源
  - **配置自动迁移适配器 (Medium Fix M11 新增):** ConfigMigrationAdapter自动转换1.x配置格式
  - **迁移集成测试套件 (Low Fix L1 新增):** MigrationIntegrationTestSuite验证升级场景
- **Guidance:** Zero breaking changes principle: existing code continues functioning exactly as before, new audit capabilities are additive, migration is opt-in gradual process. **Medium Fix M3 - 配置诊断端点:** 实现SqlGuardConfigEndpoint暴露/actuator/sql-guard/config端点，返回JSON包含: effectiveConfig(最终生效配置), configSources(各配置项来源: default/yaml/database/dynamic), layerStatus(runtime/audit各层启用状态), checkerRegistry(已注册checker列表及状态)，帮助用户调试三级配置继承链。**Medium Fix M11 - 配置自动迁移:** 实现ConfigMigrationAdapter检测1.x配置格式，自动转换为2.0多层配置，输出迁移建议日志，支持配置验证模式(dry-run)。Deprecation strategy: mark legacy implementations with `@Deprecated(since = "2.0", forRemoval = false)` indicating not removed but superseded, JavaDoc includes `@see` references to new implementations with migration examples. Compatibility shim pattern: existing DefaultSqlSafetyValidator now composes RuntimeCheckerOrchestrator (for pre-execution), maintains existing API contract, existing validator configuration maps to new multi-layer config with defaults preserving behavior. Interceptor compatibility: MyBatis/MyBatis-Plus/Druid/P6Spy interceptors from Phases 4-5 unchanged, audit logging is optional layer enabled via separate configuration, runtime validation behavior identical to existing. Test validation: run existing test suite from sql-guard-core, sql-guard-mybatis, sql-guard-mybatis-plus, sql-guard-jdbc modules, verify 100% pass rate (500+ tests), fix any regressions immediately (regression = breaking change), continuous integration enforces test pass rate. Depends on: Phases 1-7 Output (existing codebase), Phase 8-9 Output (new audit layer to coexist with).

1-5. **[Implementation details: deprecation markers, compatibility shims, interceptor validation, test suite execution, migration documentation]**

6. **配置诊断端点实现 (Medium Fix M3):** 创建SqlGuardConfigEndpoint类使用@Endpoint(id="sql-guard-config")注解，实现@ReadOperation返回配置诊断信息: effectiveConfig包含所有最终生效的配置值，configSources映射表记录每个配置项的来源(application.yml第X行、@Value注入、数据库动态配置等)，layerStatus记录runtime层和audit层的启用状态及各层的checker启用情况，checkerRegistry列出所有注册的checker及其当前配置。测试: 验证端点在/actuator/sql-guard/config可访问，验证配置来源追踪准确，验证安全控制(需要ACTUATOR_ADMIN角色)。

7. **配置自动迁移适配器 (Medium Fix M11):** 创建ConfigMigrationAdapter在应用启动时检测配置版本: 识别1.x格式配置(扁平结构如sql-guard.no-where-clause.enabled)，自动转换为2.0格式(嵌套结构如sql-guard.runtime.checkers.no-where-clause.enabled)，输出INFO日志记录迁移操作，支持dry-run模式仅输出迁移建议不实际应用，保留原配置备份供回滚。测试: 验证1.x配置自动识别，验证转换后行为等价，验证迁移日志输出。

8. **迁移集成测试套件 (Low Fix L1):** 创建MigrationIntegrationTestSuite使用@SpringBootTest验证完整升级场景: 测试从1.x配置启动成功，测试新旧配置混用场景，测试配置热更新(动态配置中心)，测试降级回滚场景，使用Testcontainers模拟完整环境。验收标准: 覆盖Top 10迁移场景，零回归确认。

### Task 11.2 – Migration Documentation & Examples │ Agent_Core_Engine_Foundation

- **Objective:** Create comprehensive migration guide explaining upgrade path from sql-guard 1.x (pre-execution only) to sql-guard 2.0 (dual-layer with audit), providing step-by-step instructions for enabling audit logging, deploying audit service, and migrating configuration, including working code examples demonstrating gradual migration scenarios, and documenting rollback procedures for risk mitigation.
- **Output:**
  - Migration guide: docs/migration/audit-platform-migration.md (100+ lines)
  - Configuration migration examples: 1.x YAML → 2.0 multi-layer YAML
  - Deployment guide: adding audit service to existing infrastructure
  - Gradual rollout strategy: LOG-only mode → statistics review → enforcement consideration
  - Rollback procedures: disabling audit service, reverting configuration
  - FAQ: common migration questions and troubleshooting
  - Example project: sql-guard-migration-demo showing before/after configurations
- **Guidance:** Migration guide structure: **Overview** - explains dual-layer architecture benefits, clarifies existing runtime behavior unchanged, outlines gradual adoption path; **Prerequisites** - Java 8 for existing interceptors, Java 21 for audit service, Kafka + ClickHouse infrastructure; **Step-by-Step Migration** - (1) upgrade sql-guard libraries to 2.0 (backward compatible drop-in), (2) optionally enable audit logging in interceptors (add audit.enabled=true), (3) deploy audit service + dependencies, (4) review audit findings in read-only mode, (5) tune checker thresholds based on findings, (6) enable enforcement if desired (via runtime checkers already present); **Configuration Mapping** - shows 1.x config translates directly to 2.0 runtime layer, audit layer is additional optional config; **Deployment Patterns** - production rollout: staging first → production read-only → production enforcement, single service vs distributed, cloud-native Kubernetes deployment examples; **Rollback** - disable audit logging (remove audit.enabled), stop audit service (existing runtime validation unaffected), revert library version if necessary (full backward compatibility). Example project: sql-guard-migration-demo with branches: v1-baseline (existing setup), v2-audit-logging (audit logs enabled), v2-audit-service (full audit platform), developers can compare branches to see exact changes needed. Depends on: Task 11.1 Output (compatibility validation), Phase 8-10 Output (new audit components to document).

1-3. **[Implementation details: migration guide writing, configuration examples, deployment patterns, example project creation]**

---

## Phase 12: Audit Platform Examples & Documentation - Agent_Documentation

**Phase Overview:** Create comprehensive examples and documentation for SQL Audit Platform showcasing audit-specific features, providing production deployment guides, documenting best practices for audit analysis and remediation, and ensuring users can effectively leverage dual-layer architecture for both prevention and discovery.

### Task 12.1 – Audit-Enhanced Demo Application │ Agent_Documentation

- **Objective:** Extend existing sql-guard-demo application with audit platform integration demonstrating complete dual-layer protection, showing audit log generation from interceptors, audit service consumption and analysis, REST API usage for querying audit results, and visualization of audit findings via sample dashboards.
- **Output:**
  - Extended sql-guard-demo with audit logging enabled across all interceptors
  - Docker Compose: demo app + Kafka + audit service + PostgreSQL + ClickHouse + Grafana
  - Sample audit scenarios: slow query detection, high-impact UPDATE without WHERE, error rate analysis
  - Grafana dashboards: top risky SQL, slow query trends, error distribution
  - Demo scripts: load generator creating diverse SQL patterns for audit analysis
  - README with step-by-step demo walkthrough
- **Guidance:** Demo architecture: existing Spring Boot demo app with MyBatis/MyBatis-Plus/Druid integrations, add audit logging configuration enabling all Task 8 interceptors, Docker Compose orchestrates full stack (demo app → Kafka ← audit service → databases), Grafana connects to audit service REST API and ClickHouse for visualization. Audit scenarios: (1) slow query - simulate 5-second SELECT showing SlowQueryChecker detection and recommendations, (2) missing WHERE UPDATE - execute UPDATE without WHERE affecting 1000 rows showing ActualImpactNoWhereChecker with CRITICAL severity, (3) frequent errors - cause intentional SQL errors showing ErrorRateChecker aggregation, (4) pagination abuse - deep offset queries showing DeepPaginationChecker from Phase 2. Load generator: JMeter or custom Spring Boot script generating realistic SQL workload (80% fast queries, 15% slow, 5% errors), runs for 5 minutes creating sufficient data for audit analysis, demonstrates audit service throughput handling production-like volume. Grafana dashboards: (1) Risk Overview - pie chart of severity distribution, table of top 10 risky SQL with risk scores, (2) Performance - line chart of p95/p99 query latency over time, bar chart of slowest queries, (3) Errors - error rate by category, error frequency timeline, top error messages. Demo walkthrough: start stack with docker-compose up, run load generator, open Grafana dashboards, query audit service REST API with curl examples, show audit findings in ClickHouse, demonstrate configuration updates via API. Depends on: Phase 8-10 Output (full audit platform), existing sql-guard-demo from Phase 7.

1-5. **[Implementation details: demo app configuration, Docker Compose stack, load generator, Grafana dashboards, demo scripts and README]**

### Task 12.2 – Production Deployment Guide │ Agent_Documentation

- **Objective:** Create production deployment guide documenting infrastructure requirements, scaling strategies, high-availability configuration, security considerations, and operational runbooks for sql-audit-service, providing deployment templates for common platforms (Kubernetes, Docker Swarm, VM-based), and documenting monitoring, backup, and disaster recovery procedures.
- **Output:**
  - Production deployment guide: docs/deployment/production-deployment.md (200+ lines)
  - Infrastructure requirements: CPU/memory/storage sizing for different scales
  - Kubernetes deployment YAML: StatefulSet for audit service, ConfigMaps, Secrets
  - High availability: Kafka consumer groups, database replication, failover procedures
  - Security: authentication, authorization, encryption in transit/at rest
  - Monitoring: Prometheus + Grafana dashboard templates, alerting rules
  - Backup and recovery: PostgreSQL backup strategy, ClickHouse snapshots, disaster recovery runbook
  - **运维手册 (Low Fix L2 新增):** docs/operations/troubleshooting-guide.md，故障排查与常见问题处理
- **Guidance:** Sizing guide: small scale (<10k SQL/day) → 2 CPU / 4GB RAM / 100GB storage, medium scale (<100k SQL/day) → 4 CPU / 8GB RAM / 500GB storage, large scale (<1M SQL/day) → 8 CPU / 16GB RAM / 2TB storage, very large (>1M SQL/day) → horizontal scaling with multiple audit service instances. Kubernetes deployment: StatefulSet for audit service (stable network identity for Kafka consumer), deployment for multiple replicas (consumer group coordination), ConfigMap for application.yml (non-sensitive config), Secret for database credentials, PersistentVolumeClaim for local cache, Service for REST API, Ingress for external access. HA configuration: Kafka consumer group with multiple service instances (partition assignment handles failover), PostgreSQL with streaming replication (primary/replica), ClickHouse with replicated tables (ReplicatedMergeTree), load balancer for REST API (any instance can serve queries), health checks trigger pod restart on failure. Security: API authentication via JWT (Spring Security configuration), RBAC for audit result access (admin vs read-only), database credentials via Secrets, encryption in transit (TLS for Kafka/PostgreSQL/ClickHouse), encryption at rest (database-level encryption), audit log sensitivity (parameter sanitization for PII). Monitoring: Prometheus scrapes /actuator/prometheus, key metrics (consumer lag <1000 messages, processing latency p99 <200ms, error rate <1%), Grafana dashboards (audit service health, Kafka consumer stats, database performance), alerting rules (consumer lag >10000, processing latency >500ms, error rate >5%, disk space <10%). Backup: PostgreSQL daily full backup + WAL archiving (point-in-time recovery), ClickHouse daily snapshots (clickhouse-backup tool), retention 30 days, disaster recovery runbook (restore procedures, RTO/RPO targets). Depends on: Phase 10 Output (audit service deployable artifact).

1-4. **[Implementation details: deployment guide writing, Kubernetes YAML templates, HA configuration, security hardening, monitoring dashboards, backup procedures]**

5. **运维手册编写 (Low Fix L2):** 创建docs/operations/troubleshooting-guide.md，覆盖: **常见问题** - Kafka消费积压(增加消费者实例、检查checker性能)、ClickHouse写入超时(检查网络、调整batch size)、审计服务OOM(增加堆内存、检查内存泄漏)、配置不生效(使用配置诊断端点)；**故障诊断流程** - 症状识别、日志分析(关键日志模式)、指标检查(哪些指标异常表示哪种问题)、根因定位；**应急处理** - 快速降级(禁用审计层保持runtime正常)、数据恢复(从备份恢复)、回滚操作；**性能调优** - 常见性能瓶颈及解决方案、JVM参数优化、数据库连接池调优。测试: 验证文档步骤可操作。

### Task 12.3 – Audit Analysis Best Practices & Remediation Guide │ Agent_Documentation

- **Objective:** Document best practices for interpreting audit findings, prioritizing remediation efforts, tuning checker thresholds for environment-specific baselines, and measuring improvement over time, providing decision frameworks for addressing different risk levels and checker findings, and including real-world case studies demonstrating audit value.
- **Output:**
  - Audit analysis guide: docs/user-guide/audit-analysis-best-practices.md (150+ lines)
  - Risk prioritization matrix: severity + confidence + impact → action priority
  - Remediation playbooks: specific actions for each checker finding type
  - Threshold tuning guide: establishing baselines, adjusting for false positives
  - Metrics for success: tracking improvement in slow query rate, error rate reduction, high-risk SQL elimination
  - Case studies: 3-5 real-world scenarios with audit findings and resolutions
- **Guidance:** Risk prioritization: CRITICAL + high confidence (>80%) + high impact (>1000 rows or >5s) → immediate action (P0), HIGH + medium confidence (60-80%) + medium impact → scheduled fix (P1), MEDIUM/LOW → backlog or accept as known issue; false positive handling → whitelist in checker config, tune thresholds, document rationale. Remediation playbooks: **SlowQueryChecker findings** → (1) analyze execution plan, (2) check index usage, (3) add missing indexes, (4) rewrite query if necessary, (5) consider caching for frequent queries; **ActualImpactNoWhereChecker** → (1) determine if bulk operation intentional, (2) if unintended add WHERE conditions, (3) if batch operation consider chunking, (4) review application logic; **ErrorRateChecker** → (1) categorize error type, (2) syntax errors → code review, (3) constraint violations → data validation, (4) deadlocks → transaction scope analysis, (5) infrastructure errors → escalate to ops. Threshold tuning: baseline establishment → collect 7 days data in production, calculate p95/p99 for latency metrics, set thresholds at p99 + 20% margin, review monthly and adjust; false positive reduction → identify recurring false positives (e.g., known slow reporting queries), whitelist by SQL hash or mapper ID, document whitelist rationale. Success metrics: slow query reduction (p95 latency improvement month-over-month), error rate trends (decrease in error percentage), high-risk SQL elimination (count of CRITICAL findings), audit coverage (% of SQL statements audited). Case studies: (1) E-commerce: slow product search query optimized via index recommendation, latency reduced from 8s to 200ms; (2) Financial: UPDATE without WHERE detected affecting 50k accounts, prevented data corruption; (3) SaaS: error rate spike identified during deployment, rollback triggered before customer impact; (4) Analytics: frequent zero-impact queries identified, application logic bug found causing unnecessary DB calls; (5) Compliance: sensitive data access patterns revealed unauthorized PII queries, security investigation initiated. Depends on: Phase 9 Output (checker documentation), Task 12.1 Output (demo examples).

1-3. **[Implementation details: best practices guide, playbooks, case studies, threshold tuning procedures]**

### Task 12.4 – API Reference & Developer Documentation │ Agent_Documentation

- **Objective:** Generate comprehensive API reference documentation for audit platform public APIs, documenting audit checker extension points for custom checker development, providing API usage examples (Low Fix L3: 明确为API使用示例而非完整SDK) for programmatic audit result access, and creating developer tutorials for common integration scenarios.
- **Output:**
  - Javadoc API reference: complete coverage of audit platform public APIs
  - Checker extension guide: docs/developer-guide/custom-audit-checker.md with tutorial
  - REST API reference: OpenAPI spec with code examples in multiple languages
  - **API使用示例 (Low Fix L3 澄清):** Java/Python/JavaScript代码片段演示REST API调用，非独立SDK包
  - Integration tutorials: embedding audit service in CI/CD, custom alerting integrations
  - Developer quickstart: 5-minute guide to running audit service locally
- **Guidance:** **Low Fix L3 - 范围澄清:** 本任务提供的是REST API使用示例(代码片段)，而非完整封装的SDK包(如需SDK需另行规划)。示例使用各语言原生HTTP客户端(Java RestTemplate/WebClient, Python requests, JavaScript fetch)演示API调用，不提供独立发布的client library。Javadoc coverage: all public classes in audit modules (AbstractAuditChecker, ExecutionResult, RiskScore, AuditResult), audit service public APIs (AuditEngine, repositories, controllers), extension points (custom checkers, custom storage adapters), code examples in class-level Javadoc, @since 2.0 tags for new audit APIs. Custom checker tutorial: step-by-step guide (1) extend AbstractAuditChecker, (2) implement performAudit() logic, (3) calculate RiskScore with appropriate confidence, (4) write comprehensive tests (30+ test matrix), (5) register as Spring bean in audit service, (6) configure thresholds, (7) deploy and validate, include complete working example (TableLockChecker detecting queries holding locks >1s). REST API reference: generated from OpenAPI annotations, code examples in curl, Java (RestTemplate, WebClient), Python (requests), JavaScript (fetch, axios), pagination examples, error handling, authentication headers. API使用示例: Java代码片段使用RestTemplate/WebClient调用audit service API, Python代码片段使用requests库, JavaScript代码片段使用fetch/axios, 演示常见用例(查询最近CRITICAL发现、获取仪表板统计数据、更新checker配置), 示例放在docs/api-examples/目录下便于复制使用。Integration tutorials: (1) CI/CD integration → query audit API in pipeline, fail build if critical findings in PR, (2) custom alerting → poll audit API, send Slack notifications for CRITICAL risks, (3) metrics export → fetch statistics, export to custom monitoring, (4) compliance reporting → scheduled queries, generate PDF reports. Developer quickstart: `git clone`, `docker-compose up`, `mvn spring-boot:run`, access Swagger UI, run sample queries, 5 minutes to full local environment. Depends on: Phase 10 Output (audit service with APIs), Phase 9 Output (checker extension points).

1-4. **[Implementation details: Javadoc generation, checker extension tutorial, API reference generation, SDK examples, integration tutorials, quickstart guide]**

